{
  "django__django-11790": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11790",
    "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..90ab22ad19 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -62,11 +62,17 @@ class UsernameField(forms.CharField):\n         return unicodedata.normalize('NFKC', super().to_python(value))\n \n     def widget_attrs(self, widget):\n-        return {\n-            **super().widget_attrs(widget),\n+        attrs = {**super().widget_attrs(widget)}\n+        # Ensure maxlength/minlength HTML attributes are present like CharField.widget_attrs\n+        if getattr(self, 'max_length', None) is not None and not getattr(widget, 'is_hidden', False):\n+            attrs['maxlength'] = str(self.max_length)\n+        if getattr(self, 'min_length', None) is not None and not getattr(widget, 'is_hidden', False):\n+            attrs['minlength'] = str(self.min_length)\n+        attrs.update({\n             'autocapitalize': 'none',\n             'autocomplete': 'username',\n-        }\n+        })\n+        return attrs\n \n \n class UserCreationForm(forms.ModelForm):\n"
  },
  "django__django-11815": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11815",
    "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..e7c4d00c27 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,6 +120,13 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n+        # Prefer serializing by enum member name (EnumClass['NAME']) so that\n+        # translatable enum values don't break older migrations. Fall back to\n+        # value-based construction if no name is available.\n+        name = getattr(self.value, 'name', None)\n+        if isinstance(name, str):\n+            imports = {'import %s' % module}\n+            return \"%s.%s[%s]\" % (module, enum_class.__name__, repr(name)), imports\n         v_string, v_imports = serializer_factory(self.value.value).serialize()\n         imports = {'import %s' % module, *v_imports}\n         return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n"
  },
  "django__django-11848": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11848",
    "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..0f28d8c031 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,17 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n+            # RFC 7231: two-digit years (RFC850) must be interpreted so that\n+            # timestamps that appear to be more than 50 years in the future\n+            # are treated as the most recent past year with the same last two\n+            # digits. Prefer 2000+year unless that is >50 years in the future\n+            # relative to the current year, in which case use 1900+year.\n+            now_year = datetime.datetime.utcnow().year\n+            y2000 = 2000 + year\n+            if y2000 - now_year > 50:\n                 year += 1900\n+            else:\n+                year = y2000\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n"
  },
  "django__django-11880": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11880",
    "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..b7bce63e4d 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -200,9 +200,10 @@ class Field:\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        # Ensure error_messages dict is deep-copied so field copies do not share the same dict\n+        result.error_messages = copy.deepcopy(self.error_messages, memo)\n         return result\n \n-\n class CharField(Field):\n     def __init__(self, *, max_length=None, min_length=None, strip=True, empty_value='', **kwargs):\n         self.max_length = max_length\n"
  },
  "django__django-11885": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11885",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..08e20d9f82 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -309,10 +309,21 @@ class Collector:\n                         sender=model, instance=obj, using=self.using\n                     )\n \n-            # fast deletes\n+            # fast deletes - combine fast delete querysets by model to reduce DB roundtrips\n+            # Collect primary keys per model from fast querysets and perform one delete per model.\n+            model_pks = {}\n             for qs in self.fast_deletes:\n-                count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                model = qs.model\n+                # Evaluate the primary keys represented by this queryset-like.\n+                pks = list(qs.values_list(model._meta.pk.attname, flat=True))\n+                model_pks.setdefault(model, []).extend(pks)\n+            for model, pks in model_pks.items():\n+                # Deduplicate and convert to list\n+                pk_list = list(dict.fromkeys(pks))\n+                query = sql.DeleteQuery(model)\n+                # delete_batch handles batching for DB parameter limits\n+                count = query.delete_batch(pk_list, self.using)\n+                deleted_counter[model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n"
  },
  "django__django-11951": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11951",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..92349cd0c5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,8 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+        max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n+        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n"
  },
  "django__django-11964": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11964",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..bf96a2ea15 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,7 +60,10 @@ class ChoicesMeta(enum.EnumMeta):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n-    pass\n+\n+    def __str__(self):\n+        \"\"\"Return the value of the enum member as its string representation.\"\"\"\n+        return str(self.value)\n \n \n class IntegerChoices(int, Choices):\n"
  },
  "django__django-11999": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11999",
    "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..2f4172a32b 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            # Only set get_<field>_display if not already defined on the model class,\n+            # so user-defined methods can override the default implementation.\n+            if not hasattr(cls, 'get_%s_display' % self.name):\n+                setattr(cls, 'get_%s_display' % self.name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n"
  },
  "django__django-12039": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12039",
    "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..1606ed6dc0 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -110,14 +110,22 @@ class IndexColumns(Columns):\n \n     def __str__(self):\n         def col_str(column, idx):\n+            parts = [self.quote_name(column)]\n             # Index.__init__() guarantees that self.opclasses is the same\n             # length as self.columns.\n-            col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n             try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n+                opc = self.opclasses[idx]\n             except IndexError:\n-                pass\n-            return col\n+                opc = None\n+            if opc:\n+                parts.append(opc)\n+            try:\n+                cs = self.col_suffixes[idx]\n+            except IndexError:\n+                cs = None\n+            if cs:\n+                parts.append(cs)\n+            return ' '.join(parts)\n \n         return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n"
  },
  "django__django-12050": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12050",
    "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..90475d6fb9 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1073,7 +1073,7 @@ class Query(BaseExpression):\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n-            value = tuple(resolved_values)\n+            value = type(value)(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n"
  },
  "django__django-12143": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12143",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..a100f1c499 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1631,7 +1631,7 @@ class ModelAdmin(BaseModelAdmin):\n \n     def _get_edited_object_pks(self, request, prefix):\n         \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name))\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\n"
  },
  "django__django-12155": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12155",
    "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..63576f5b80 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,7 +34,13 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n+    # Compute minimum indentation from the second line onwards to avoid\n+    # treating the first-line's (often zero) indentation as representative.\n+    if len(lines) > 1:\n+        indented_lines = [line for line in lines[1:] if line.lstrip()]\n+        indent = min((len(line) - len(line.lstrip()) for line in indented_lines), default=0)\n+    else:\n+        indent = 0\n     trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n     return \"\\n\".join(trimmed).strip()\n \n"
  },
  "django__django-12193": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12193",
    "model_patch": "diff --git a/django/contrib/postgres/forms/array.py b/django/contrib/postgres/forms/array.py\nindex 2e19cd574a..18cfccf39c 100644\n--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -147,7 +147,7 @@ class SplitArrayWidget(forms.Widget):\n             if id_:\n                 final_attrs = {**final_attrs, 'id': '%s_%s' % (id_, i)}\n             context['widget']['subwidgets'].append(\n-                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs)['widget']\n+                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs.copy())['widget']\n             )\n         return context\n \n"
  },
  "django__django-12209": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12209",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..007861a3fb 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -850,7 +850,7 @@ class Model(metaclass=ModelBase):\n         # Skip an UPDATE when adding an instance and primary key has a default.\n         if (\n             not force_insert and\n-            self._state.adding and\n+            self._state.adding and not pk_set and\n             self._meta.pk.default and\n             self._meta.pk.default is not NOT_PROVIDED\n         ):\n"
  },
  "django__django-12262": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12262",
    "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..2f74556268 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -261,7 +261,7 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if kwarg:\n             # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n+            if param not in params and param not in kwonly and varkw is None:\n                 # An unexpected keyword argument was supplied\n                 raise TemplateSyntaxError(\n                     \"'%s' received unexpected keyword argument '%s'\" %\n"
  },
  "django__django-12273": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12273",
    "model_patch": ""
  },
  "django__django-12276": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12276",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..dfa1d99e8b 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -384,13 +384,15 @@ class FileInput(Input):\n         \"File widgets take data from FILES, not POST\"\n         return files.get(name)\n \n-    def value_omitted_from_data(self, data, files, name):\n-        return name not in files\n-\n+    \n+    def use_required_attribute(self, initial):\n+        return super().use_required_attribute(initial) and not initial\n \n FILE_INPUT_CONTRADICTION = object()\n \n \n+\n+\n class ClearableFileInput(FileInput):\n     clear_checkbox_label = _('Clear')\n     initial_text = _('Currently')\n@@ -451,9 +453,6 @@ class ClearableFileInput(FileInput):\n             return False\n         return upload\n \n-    def use_required_attribute(self, initial):\n-        return super().use_required_attribute(initial) and not initial\n-\n     def value_omitted_from_data(self, data, files, name):\n         return (\n             super().value_omitted_from_data(data, files, name) and\n"
  },
  "django__django-12304": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12304",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex f48143ddaf..07a09b90b6 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -31,6 +31,8 @@ class ChoicesMeta(enum.EnumMeta):\n         # that is passed in as \"self\" as the value to use when looking up the\n         # label in the choices.\n         cls.label = property(lambda self: cls._value2label_map_.get(self.value))\n+\t\t# Prevent Django templates from calling enum classes without arguments\n+\t\tcls.do_not_call_in_templates = True\n         return enum.unique(cls)\n \n     def __contains__(cls, member):\n"
  },
  "django__django-12308": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12308",
    "model_patch": ""
  },
  "django__django-12325": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12325",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..7802d61c6d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -204,7 +204,17 @@ class ModelBase(type):\n             for field in base._meta.local_fields:\n                 if isinstance(field, OneToOneField):\n                     related = resolve_relation(new_class, field.remote_field.model)\n-                    parent_links[make_model_tuple(related)] = field\n+                    key = make_model_tuple(related)\n+                    existing = parent_links.get(key)\n+                    # Prefer an explicit parent_link=True field. If there's no\n+                    # existing entry, or the new field has parent_link=True while\n+                    # the existing one does not, use the new field. This avoids\n+                    # depending on field declaration order when multiple\n+                    # OneToOneFields reference the same parent model.\n+                    if (existing is None or\n+                        (getattr(field.remote_field, 'parent_link', False) and\n+                         not getattr(existing.remote_field, 'parent_link', False))):\n+                        parent_links[key] = field\n \n         # Track fields inherited from base models.\n         inherited_attributes = set()\n"
  },
  "django__django-12406": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..6d9831e292 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1185,10 +1185,16 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n-            self.empty_label = None\n+        # Don't present an empty choice for RadioSelect when the field is required (blank=False).\n+        from .widgets import RadioSelect\n+        is_radio = widget is not None and (isinstance(widget, RadioSelect) or (isinstance(widget, type) and issubclass(widget, RadioSelect)))\n+        if is_radio:\n+            self.empty_label = None if required else empty_label\n         else:\n-            self.empty_label = empty_label\n+            if required and (initial is not None):\n+                self.empty_label = None\n+            else:\n+                self.empty_label = empty_label\n \n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n"
  },
  "django__django-12708": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12708",
    "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..797722a6b8 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -403,9 +403,18 @@ class BaseDatabaseSchemaEditor:\n         meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n         columns = [model._meta.get_field(field).column for field in fields]\n+        # Prevent matching both a UNIQUE constraint and a separate INDEX on the same\n+        # columns by explicitly excluding the opposite type when deleting one.\n+        kwargs = dict(constraint_kwargs)\n+        if kwargs.get('index'):\n+            # We're deleting an index, make sure UNIQUE constraints are excluded.\n+            kwargs.setdefault('unique', False)\n+        if kwargs.get('unique'):\n+            # We're deleting a unique constraint, make sure plain indexes are excluded.\n+            kwargs.setdefault('index', False)\n         constraint_names = self._constraint_names(\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n-            **constraint_kwargs\n+            **kwargs\n         )\n         if len(constraint_names) != 1:\n             raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n"
  },
  "django__django-12713": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12713",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..b3c4020f39 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -250,15 +250,16 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n         db = kwargs.get('using')\n \n         autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n-            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n-            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n-            kwargs['widget'] = widgets.FilteredSelectMultiple(\n-                db_field.verbose_name,\n-                db_field.name in self.filter_vertical\n-            )\n+        if 'widget' not in kwargs:\n+            if db_field.name in autocomplete_fields:\n+                kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in self.raw_id_fields:\n+                kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+                kwargs['widget'] = widgets.FilteredSelectMultiple(\n+                    db_field.verbose_name,\n+                    db_field.name in self.filter_vertical\n+                )\n \n         if 'queryset' not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\n"
  },
  "django__django-12774": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12774",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..98b1e1bcbc 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -21,6 +21,7 @@ from django.db.models.deletion import Collector\n from django.db.models.expressions import Case, Expression, F, Value, When\n from django.db.models.functions import Cast, Trunc\n from django.db.models.query_utils import FilteredRelation, Q\n+from django.db.models.constraints import UniqueConstraint\n from django.db.models.sql.constants import CURSOR, GET_ITERATOR_CHUNK_SIZE\n from django.db.models.utils import resolve_callables\n from django.utils import timezone\n@@ -689,8 +690,14 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+        if field_name != 'pk':\n+            field = self.model._meta.get_field(field_name)\n+            is_unique = getattr(field, 'unique', False) or any(\n+                isinstance(constraint, UniqueConstraint) and field_name in constraint.fields\n+                for constraint in getattr(self.model._meta, 'constraints', [])\n+            )\n+            if not is_unique:\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n         if id_list is not None:\n             if not id_list:\n                 return {}\n"
  },
  "django__django-9296": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-9296",
    "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..896535d89a 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -106,6 +106,10 @@ class Paginator:\n         \"\"\"\n         return range(1, self.num_pages + 1)\n \n+    def __iter__(self):\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n     def _check_object_list_is_ordered(self):\n         \"\"\"\n         Warn if self.object_list is unordered (typically a QuerySet).\n"
  },
  "sphinx-doc__sphinx-10323": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10323",
    "model_patch": "diff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..9437fe9a5 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -224,9 +224,9 @@ class LiteralIncludeReader:\n                        self.start_filter,\n                        self.end_filter,\n                        self.lines_filter,\n+                       self.dedent_filter,\n                        self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+                       self.append_filter]\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\ndiff --git a/test_pom.xml b/test_pom.xml\nnew file mode 100644\nindex 000000000..9d60fc60d\n--- /dev/null\n+++ b/test_pom.xml\n@@ -0,0 +1,10 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project>\n+  <build>\n+    <plugins>\n+      <plugin>\n+        <groupId>com.github.ekryd.sortpom</groupId>\n+      </plugin>\n+    </plugins>\n+  </build>\n+</project>\n"
  },
  "sphinx-doc__sphinx-10435": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10435",
    "model_patch": ""
  },
  "sphinx-doc__sphinx-10466": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10466",
    "model_patch": "diff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..1b35802ed 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -29,12 +29,18 @@ logger = logging.getLogger(__name__)\n \n \n class Message:\n-    \"\"\"An entry of translatable message.\"\"\"\n-    def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n-        self.text = text\n-        self.locations = locations\n-        self.uuids = uuids\n-\n+\t\"\"\"An entry of translatable message.\"\"\"\n+\tdef __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n+\t\tself.text = text\n+\t\t# remove duplicate locations while preserving order\n+\t\tseen = set()\n+\t\tunique_locs = []\n+\t\tfor loc in locations:\n+\t\t\tif loc not in seen:\n+\t\t\t\tseen.add(loc)\n+\t\t\t\tunique_locs.append(loc)\n+\t\tself.locations = unique_locs\n+\t\tself.uuids = uuids\n \n class Catalog:\n     \"\"\"Catalog of translatable messages.\"\"\"\n"
  },
  "sphinx-doc__sphinx-10673": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10673",
    "model_patch": "diff --git a/sphinx/environment/adapters/toctree.py b/sphinx/environment/adapters/toctree.py\nindex 9678e3c7c..329d6db7a 100644\n--- a/sphinx/environment/adapters/toctree.py\n+++ b/sphinx/environment/adapters/toctree.py\n@@ -164,17 +164,19 @@ class TocTree:\n                                           'doesn\\'t have a title: no link will be generated'),\n                                        ref, location=toctreenode)\n                 except KeyError:\n+                    # allow references to special generated indices\n+                    if ref in (\"genindex\", \"modindex\", \"search\"):\n+                        # these are generated later, so treat them as existing\n+                        continue\n                     # this is raised if the included file does not exist\n                     if excluded(self.env.doc2path(ref, False)):\n-                        message = __('toctree contains reference to excluded document %r')\n+                        message = __(\"toctree contains reference to excluded document %r\")\n                     elif not included(self.env.doc2path(ref, False)):\n-                        message = __('toctree contains reference to non-included document %r')\n+                        message = __(\"toctree contains reference to non-included document %r\")\n                     else:\n-                        message = __('toctree contains reference to nonexisting document %r')\n+                        message = __(\"toctree contains reference to nonexisting document %r\")\n \n                     logger.warning(message, ref, location=toctreenode)\n-                else:\n-                    # if titles_only is given, only keep the main title and\n                     # sub-toctrees\n                     if titles_only:\n                         # children of toc are:\n"
  },
  "sphinx-doc__sphinx-11510": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-11510",
    "model_patch": "diff --git a/demo/conf.py b/demo/conf.py\nnew file mode 100644\nindex 000000000..c38587248\n--- /dev/null\n+++ b/demo/conf.py\n@@ -0,0 +1,3 @@\n+import sys, os\n+sys.path.insert(0, os.path.abspath('.'))\n+extensions = ['my_extension']\ndiff --git a/demo/index.rst b/demo/index.rst\nnew file mode 100644\nindex 000000000..f2dec1395\n--- /dev/null\n+++ b/demo/index.rst\n@@ -0,0 +1,6 @@\n+This is a test\n+==============\n+\n+.. include:: something-to-include.rst\n+\n+&REPLACE_ME;\ndiff --git a/demo/my_extension.py b/demo/my_extension.py\nnew file mode 100644\nindex 000000000..83e8aeddc\n--- /dev/null\n+++ b/demo/my_extension.py\n@@ -0,0 +1,10 @@\n+from sphinx.application import Sphinx\n+\n+def subst_vars_replace(app: Sphinx, docname, source):\n+    result = source[0]\n+    result = result.replace(\"&REPLACE_ME;\", \"REPLACED\")\n+    source[0] = result\n+\n+def setup(app: Sphinx):\n+    app.connect('source-read', subst_vars_replace)\n+    return dict(version='1.0', parallel_read_safe=True, parallel_write_safe=True)\ndiff --git a/demo/something-to-include.rst b/demo/something-to-include.rst\nnew file mode 100644\nindex 000000000..e63253568\n--- /dev/null\n+++ b/demo/something-to-include.rst\n@@ -0,0 +1,4 @@\n+Testing\n+=======\n+\n+&REPLACE_ME;\ndiff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 19f7c0a8d..097958705 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -369,14 +369,61 @@ class Include(BaseInclude, SphinxDirective):\n     \"\"\"\n \n     def run(self) -> list[Node]:\n-        if self.arguments[0].startswith('<') and \\\n-           self.arguments[0].endswith('>'):\n-            # docutils \"standard\" includes, do not do path processing\n+        # Handle standard <> includes by delegating to docutils\n+        if self.arguments[0].startswith('<') and self.arguments[0].endswith('>'):\n             return super().run()\n+        # Resolve filename relative to the current document\n         rel_filename, filename = self.env.relfn2path(self.arguments[0])\n         self.arguments[0] = filename\n         self.env.note_included(filename)\n-        return super().run()\n+        # Read the file so that we can emit the \"source-read\" event\n+        from docutils import io as _io\n+        from docutils import statemachine as _statemachine\n+        current_source = self.state.document.current_source\n+        encoding = getattr(self.state.document.settings, 'input_encoding', None)\n+        e_handler = getattr(self.state.document.settings, 'input_encoding_error_handler', 'strict')\n+        try:\n+            include_file = _io.FileInput(source_path=filename, encoding=encoding, error_handler=e_handler)\n+            rawtext = include_file.read()\n+        except Exception:\n+            # Fallback to docutils default behavior on error\n+            return super().run()\n+        # Allow Sphinx extensions to modify the included source via source-read\n+        try:\n+            arg = [rawtext]\n+            self.env.events.emit('source-read', self.env.docname, arg)\n+            rawtext = arg[0]\n+        except Exception:\n+            # ignore extension errors to preserve include behavior\n+            pass\n+        # Handle literal/code options by delegating when needed\n+        if 'literal' in self.options:\n+            # Don't convert tabs to spaces, if `tab_width` is negative.\n+            tab_width = self.options.get('tab-width', self.state.document.settings.tab_width)\n+            if tab_width >= 0:\n+                text = rawtext.expandtabs(tab_width)\n+            else:\n+                text = rawtext\n+            literal_block = nodes.literal_block(rawtext, source=filename, classes=self.options.get('class', []))\n+            literal_block.line = 1\n+            self.add_name(literal_block)\n+            literal_block += nodes.Text(text)\n+            return [literal_block]\n+        if 'code' in self.options:\n+            # Let docutils handle code block creation to preserve behavior\n+            return super().run()\n+        # Default: include as reST source into the state machine\n+        include_lines = _statemachine.string2lines(rawtext, self.options.get('tab-width', self.state.document.settings.tab_width), convert_whitespace=True)\n+        # mark end as docutils does\n+        include_lines += ['', '.. end of inclusion from \"%s\"' % filename]\n+        self.state_machine.insert_input(include_lines, filename)\n+        # record the include in the document's include_log\n+        clip_options = (self.options.get('start-line', None), self.options.get('end-line', None), self.options.get('end-before', None), self.options.get('start-after', None))\n+        include_log = self.state.document.include_log\n+        if not include_log:\n+            include_log.append((filename, (None, None, None, None)))\n+        include_log.append((filename, clip_options))\n+        return []\n \n \n def setup(app: Sphinx) -> dict[str, Any]:\n@@ -402,4 +449,4 @@ def setup(app: Sphinx) -> dict[str, Any]:\n         'version': 'builtin',\n         'parallel_read_safe': True,\n         'parallel_write_safe': True,\n-    }\n+    }\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": ""
  },
  "sphinx-doc__sphinx-7748": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7748",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex f8e4be999..98e243e79 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1062,9 +1062,24 @@ class DocstringSignatureMixin:\n                     valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n             if base not in valid_names:\n                 continue\n-            # re-prepare docstring to ignore more leading indentation\n+            # re-prepare docstring to ignore more leading indentation.\n+            # If the docstring contains multiple leading signature lines (e.g.\n+            # overloaded methods emitted by SWIG), strip all of them so they\n+            # don't appear in the rendered docstring. Keep using the first\n+            # matched signature for extracting args/retann.\n             tab_width = self.directive.state.document.settings.tab_width  # type: ignore\n-            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[1:]),\n+            # consume all consecutive leading signature lines that match and\n+            # whose base name is valid for this object.\n+            sig_start = 0\n+            for j, line in enumerate(doclines):\n+                m2 = py_ext_sig_re.match(line)\n+                if not m2:\n+                    break\n+                _exmod, _path, base2, _args2, _retann2 = m2.groups()\n+                if base2 not in valid_names:\n+                    break\n+                sig_start = j + 1\n+            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[sig_start:]),\n                                                         tabsize=tab_width)\n             result = args, retann\n             # don't look any further\n"
  },
  "sphinx-doc__sphinx-7757": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7757",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex 9bafff11c..88f50d321 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -84,7 +84,7 @@ class _UnparseVisitor(ast.NodeVisitor):\n     def _visit_arg_with_default(self, arg: ast.arg, default: Optional[ast.AST]) -> str:\n         \"\"\"Unparse a single argument to a string.\"\"\"\n         name = self.visit(arg)\n-        if default:\n+        if default is not None:\n             if arg.annotation:\n                 name += \" = %s\" % self.visit(default)\n             else:\n"
  },
  "sphinx-doc__sphinx-7985": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7985",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..baf5e177c 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -213,7 +213,31 @@ class CheckExternalLinksBuilder(Builder):\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n             elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+                # treat local/internal links: check against known documents\n+                # split anchor if present\n+                if '#' in uri:\n+                    target, anchor = uri.split('#', 1)\n+                else:\n+                    target, anchor = uri, None\n+                # empty target means same-document anchor -> consider unchecked\n+                if target == '':\n+                    return 'unchecked', '', 0\n+                # normalize possible file extensions and paths\n+                docname = target\n+                # strip common file extensions\n+                for ext in ('.html', '.htm', '.rst'):\n+                    if docname.endswith(ext):\n+                        docname = docname[:-len(ext)]\n+                # strip leading ./ or /\n+                docname = docname.lstrip('./')\n+                docname = docname.lstrip('/')\n+                if docname in getattr(self.env, 'found_docs', set()):\n+                    # Document exists; if anchor checking is enabled we'd need\n+                    # to verify the anchor in the generated output which is\n+                    # out of scope for this simple check, so consider working.\n+                    return 'working', '', 0\n+                else:\n+                    return 'broken', \"local target '%s' not found\" % target, 0\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n"
  },
  "sphinx-doc__sphinx-8035": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8035",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 8c3509c3b..b984bd4ff 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -859,7 +859,7 @@ class ModuleDocumenter(Documenter):\n         'show-inheritance': bool_option, 'synopsis': identity,\n         'platform': identity, 'deprecated': bool_option,\n         'member-order': member_order_option, 'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n         'imported-members': bool_option, 'ignore-module-all': bool_option\n     }  # type: Dict[str, Callable]\n \n@@ -1279,7 +1279,7 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         'noindex': bool_option, 'inherited-members': inherited_members_option,\n         'show-inheritance': bool_option, 'member-order': member_order_option,\n         'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n     }  # type: Dict[str, Callable]\n \n     _signature_class = None  # type: Any\n"
  },
  "sphinx-doc__sphinx-8056": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8056",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..c3d86ebb4 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -439,14 +439,30 @@ class GoogleDocstring:\n         multi = len(fields) > 1\n         lines = []  # type: List[str]\n         for _name, _type, _desc in fields:\n-            field = self._format_field(_name, _type, _desc)\n-            if multi:\n-                if lines:\n-                    lines.extend(self._format_block(padding + ' * ', field))\n-                else:\n-                    lines.extend(self._format_block(field_type + ' * ', field))\n+            # support multiple names separated by commas sharing the same type/desc\n+            if _name and ',' in _name:\n+                names = [n.strip() for n in _name.split(',') if n.strip()]\n             else:\n-                lines.extend(self._format_block(field_type + ' ', field))\n+                names = [_name] if _name else ['']\n+            first = True\n+            for name in names:\n+                field = self._format_field(name, _type, _desc)\n+                if multi:\n+                    if lines:\n+                        lines.extend(self._format_block(padding + ' * ', field))\n+                    else:\n+                        # for the very first field in the whole block use the field_type\n+                        if first:\n+                            lines.extend(self._format_block(field_type + ' * ', field))\n+                        else:\n+                            lines.extend(self._format_block(padding + ' * ', field))\n+                else:\n+                    # single field case: only emit field_type once for the first name\n+                    if first:\n+                        lines.extend(self._format_block(field_type + ' ', field))\n+                    else:\n+                        lines.extend(self._format_block(padding + ' ', field))\n+                first = False\n         if lines and lines[-1]:\n             lines.append('')\n         return lines\n"
  },
  "sphinx-doc__sphinx-8265": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8265",
    "model_patch": ""
  },
  "sphinx-doc__sphinx-8269": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8269",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..1083e82ec 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -166,6 +166,7 @@ class CheckExternalLinksBuilder(Builder):\n                     # Read the whole document and see if #anchor exists\n                     response = requests.get(req_url, stream=True, config=self.app.config,\n                                             auth=auth_info, **kwargs)\n+                    response.raise_for_status()\n                     found = check_anchor(response, unquote(anchor))\n \n                     if not found:\n"
  },
  "sphinx-doc__sphinx-8475": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8475",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..4104fe658 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -20,7 +20,7 @@ from urllib.parse import unquote, urlparse\n \n from docutils import nodes\n from docutils.nodes import Node\n-from requests.exceptions import HTTPError\n+from requests.exceptions import HTTPError, TooManyRedirects\n \n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -172,7 +172,7 @@ class CheckExternalLinksBuilder(Builder):\n                                                  config=self.app.config, auth=auth_info,\n                                                  **kwargs)\n                         response.raise_for_status()\n-                    except HTTPError:\n+                    except (HTTPError, TooManyRedirects):\n                         # retry with GET request if that fails, some servers\n                         # don't like HEAD requests.\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n"
  },
  "sphinx-doc__sphinx-8548": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8548",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex ddfd2b365..14c4457d0 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -746,7 +746,26 @@ class Documenter:\n                         keep = has_doc or self.options.undoc_members\n                 else:\n                     keep = False\n-            elif (namespace, membername) in attr_docs:\n+            # check for documented attributes in this namespace or any base class namespace\n+            found = False\n+            if (namespace, membername) in attr_docs:\n+                found = True\n+            else:\n+                # try base classes' qualnames if documenting a class\n+                try:\n+                    obj_for_mro = self.object if inspect.isclass(self.object) else None\n+                except Exception:\n+                    obj_for_mro = None\n+                if obj_for_mro:\n+                    for cls in getattr(obj_for_mro, '__mro__', ())[1:]:\n+                        try:\n+                            qualname = safe_getattr(cls, '__qualname__')\n+                            if qualname and (qualname, membername) in attr_docs:\n+                                found = True\n+                                break\n+                        except Exception:\n+                            continue\n+            if found:\n                 if want_all and isprivate:\n                     if self.options.private_members is None:\n                         keep = False\n@@ -2496,4 +2515,4 @@ def setup(app: Sphinx) -> Dict[str, Any]:\n     app.setup_extension('sphinx.ext.autodoc.type_comment')\n     app.setup_extension('sphinx.ext.autodoc.typehints')\n \n-    return {'version': sphinx.__display_version__, 'parallel_read_safe': True}\n+    return {'version': sphinx.__display_version__, 'parallel_read_safe': True}\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-8551": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8551",
    "model_patch": ""
  },
  "sphinx-doc__sphinx-8638": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8638",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 000e2e8d3..ce2dd4200 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1149,9 +1149,19 @@ class PythonDomain(Domain):\n                     if fullname in self.objects and self.objects[fullname].objtype in objtypes:\n                         newname = fullname\n                 if not newname:\n-                    if modname and modname + '.' + name in self.objects and \\\n+                    # Prefer class-qualified name (classname.name) if available\n+                    if classname and classname + '.' + name in self.objects and \\\n+                       self.objects[classname + '.' + name].objtype in objtypes:\n+                        newname = classname + '.' + name\n+                    # then try module.classname.name\n+                    elif modname and classname and modname + '.' + classname + '.' + name in self.objects and \\\n+                         self.objects[modname + '.' + classname + '.' + name].objtype in objtypes:\n+                        newname = modname + '.' + classname + '.' + name\n+                    # then module-level name\n+                    elif modname and modname + '.' + name in self.objects and \\\n                        self.objects[modname + '.' + name].objtype in objtypes:\n                         newname = modname + '.' + name\n+                    # then unqualified name\n                     elif name in self.objects and self.objects[name].objtype in objtypes:\n                         newname = name\n                     else:\n@@ -1162,18 +1172,21 @@ class PythonDomain(Domain):\n                                    self.objects[oname].objtype in objtypes]\n         else:\n             # NOTE: searching for exact match, object type is not considered\n-            if name in self.objects:\n-                newname = name\n-            elif type == 'mod':\n+            if type == 'mod':\n                 # only exact matches allowed for modules\n                 return []\n+            # Try classname.name first (most specific)\n             elif classname and classname + '.' + name in self.objects:\n                 newname = classname + '.' + name\n+            # Then try module.classname.name\n+            elif modname and classname and modname + '.' + classname + '.' + name in self.objects:\n+                newname = modname + '.' + classname + '.' + name\n+            # Then module.name\n             elif modname and modname + '.' + name in self.objects:\n                 newname = modname + '.' + name\n-            elif modname and classname and \\\n-                    modname + '.' + classname + '.' + name in self.objects:\n-                newname = modname + '.' + classname + '.' + name\n+            # Finally unqualified name\n+            elif name in self.objects:\n+                newname = name\n         if newname is not None:\n             matches.append((newname, self.objects[newname]))\n         return matches\n"
  },
  "sphinx-doc__sphinx-8721": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8721",
    "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..7c15e91a9 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -180,6 +180,9 @@ def should_generate_module_page(app: Sphinx, modname: str) -> bool:\n \n def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], None, None]:\n     env = app.builder.env\n+    # Do not generate viewcode pages for epub builders unless explicitly enabled\n+    if app.builder.name.startswith('epub') and not env.config.viewcode_enable_epub:\n+        return\n     if not hasattr(env, '_viewcode_modules'):\n         return\n     highlighter = app.builder.highlighter  # type: ignore\n"
  },
  "sphinx-doc__sphinx-9229": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9229",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 1f4c98284..71d20633e 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1725,7 +1725,12 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n                     ) -> None:\n         if self.doc_as_attr:\n             try:\n-                more_content = StringList([_('alias of %s') % restify(self.object)], source='')\n+                alias_line = StringList([_('alias of %s') % restify(self.object)], source='')\n+                if more_content:\n+                    # prepend alias info but keep existing more_content (docstrings)\n+                    more_content = alias_line + more_content\n+                else:\n+                    more_content = alias_line\n             except AttributeError:\n                 pass  # Invalid class object is passed.\n \n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..250a8f572 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -266,8 +266,19 @@ class GoogleDocstring:\n         if parse_type:\n             match = _google_typed_arg_regex.match(before)\n             if match:\n-                _name = match.group(1).strip()\n-                _type = match.group(2)\n+                # Handle both \"name(type)\" and \"type name\" forms.\n+                # e.g. \"arg(int)\" -> name=\"arg\", type=\"int\"\n+                # and \"dict(str, str) opc_meta\" -> name=\"opc_meta\", type=\"dict(str, str)\"\n+                full_match = match.group(0).strip()\n+                trailing = before[match.end():].strip()\n+                if trailing:\n+                    # pattern is \"type name\": use trailing as name and full match as type\n+                    _name = trailing\n+                    _type = full_match\n+                else:\n+                    # pattern is \"name(type)\": use groups accordingly\n+                    _name = match.group(1).strip()\n+                    _type = match.group(2)\n \n         _name = self._escape_args_and_kwargs(_name)\n \n"
  },
  "sphinx-doc__sphinx-9281": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9281",
    "model_patch": ""
  },
  "sphinx-doc__sphinx-9320": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9320",
    "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..296429693 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -146,6 +146,8 @@ def do_prompt(text: str, default: str = None, validator: Callable[[str], Any] =\n         else:\n             prompt = colorize(COLOR_QUESTION, prompt, input_mode=False)\n         x = term_input(prompt).strip()\n+        if default == '' and not x:\n+            return x\n         if default and not x:\n             x = default\n         try:\n"
  },
  "sphinx-doc__sphinx-9367": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9367",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..58abdcac7 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -214,10 +214,12 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n+            # Preserve trailing comma for single-element tuples\n+            if len(node.elts) == 1:\n+                return \"(\" + self.visit(node.elts[0]) + \",)\"\n             return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n-\n     if sys.version_info < (3, 8):\n         # these ast nodes were deprecated in python 3.8\n         def visit_Bytes(self, node: ast.Bytes) -> str:\n"
  },
  "sphinx-doc__sphinx-9461": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9461",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 23dd9e930..fb64406bf 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -384,7 +384,20 @@ def iscoroutinefunction(obj: Any) -> bool:\n \n \n def isproperty(obj: Any) -> bool:\n-    \"\"\"Check if the object is property.\"\"\"\n+    \"\"\"Check if the object is property.\n+\n+    This handles descriptors wrapped by classmethod/staticmethod by\n+    unwrapping them (using their __func__) before the isinstance check.\n+    \"\"\"\n+    # Unwrap classmethod/staticmethod that may wrap a property (PEP changes since py3.9)\n+    try:\n+        # classmethod and staticmethod have __func__ attribute referencing the wrapped object\n+        if isinstance(obj, (classmethod, staticmethod)):\n+            obj = obj.__func__\n+    except Exception:\n+        # be conservative if any unexpected error occurs, fall back to original object\n+        pass\n+\n     if sys.version_info >= (3, 8):\n         from functools import cached_property  # cached_property is available since py3.8\n         if isinstance(obj, cached_property):\n"
  },
  "sphinx-doc__sphinx-9698": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9698",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..1a3bd60c7 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -796,7 +796,7 @@ class PyMethod(PyObject):\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n+            return _('%s (%s property)') % (methname, clsname)\n         elif 'staticmethod' in self.options:\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\n"
  }
}