{
  "django__django-11790": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11790",
    "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..90ab22ad19 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -62,11 +62,17 @@ class UsernameField(forms.CharField):\n         return unicodedata.normalize('NFKC', super().to_python(value))\n \n     def widget_attrs(self, widget):\n-        return {\n-            **super().widget_attrs(widget),\n+        attrs = {**super().widget_attrs(widget)}\n+        # Ensure maxlength/minlength HTML attributes are present like CharField.widget_attrs\n+        if getattr(self, 'max_length', None) is not None and not getattr(widget, 'is_hidden', False):\n+            attrs['maxlength'] = str(self.max_length)\n+        if getattr(self, 'min_length', None) is not None and not getattr(widget, 'is_hidden', False):\n+            attrs['minlength'] = str(self.min_length)\n+        attrs.update({\n             'autocapitalize': 'none',\n             'autocomplete': 'username',\n-        }\n+        })\n+        return attrs\n \n \n class UserCreationForm(forms.ModelForm):\n"
  },
  "django__django-11815": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11815",
    "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..e7c4d00c27 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,6 +120,13 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n+        # Prefer serializing by enum member name (EnumClass['NAME']) so that\n+        # translatable enum values don't break older migrations. Fall back to\n+        # value-based construction if no name is available.\n+        name = getattr(self.value, 'name', None)\n+        if isinstance(name, str):\n+            imports = {'import %s' % module}\n+            return \"%s.%s[%s]\" % (module, enum_class.__name__, repr(name)), imports\n         v_string, v_imports = serializer_factory(self.value.value).serialize()\n         imports = {'import %s' % module, *v_imports}\n         return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n"
  },
  "django__django-11848": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11848",
    "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..0f28d8c031 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,17 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n+            # RFC 7231: two-digit years (RFC850) must be interpreted so that\n+            # timestamps that appear to be more than 50 years in the future\n+            # are treated as the most recent past year with the same last two\n+            # digits. Prefer 2000+year unless that is >50 years in the future\n+            # relative to the current year, in which case use 1900+year.\n+            now_year = datetime.datetime.utcnow().year\n+            y2000 = 2000 + year\n+            if y2000 - now_year > 50:\n                 year += 1900\n+            else:\n+                year = y2000\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n"
  },
  "django__django-11880": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11880",
    "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..b7bce63e4d 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -200,9 +200,10 @@ class Field:\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        # Ensure error_messages dict is deep-copied so field copies do not share the same dict\n+        result.error_messages = copy.deepcopy(self.error_messages, memo)\n         return result\n \n-\n class CharField(Field):\n     def __init__(self, *, max_length=None, min_length=None, strip=True, empty_value='', **kwargs):\n         self.max_length = max_length\n"
  },
  "django__django-11885": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11885",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..08e20d9f82 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -309,10 +309,21 @@ class Collector:\n                         sender=model, instance=obj, using=self.using\n                     )\n \n-            # fast deletes\n+            # fast deletes - combine fast delete querysets by model to reduce DB roundtrips\n+            # Collect primary keys per model from fast querysets and perform one delete per model.\n+            model_pks = {}\n             for qs in self.fast_deletes:\n-                count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                model = qs.model\n+                # Evaluate the primary keys represented by this queryset-like.\n+                pks = list(qs.values_list(model._meta.pk.attname, flat=True))\n+                model_pks.setdefault(model, []).extend(pks)\n+            for model, pks in model_pks.items():\n+                # Deduplicate and convert to list\n+                pk_list = list(dict.fromkeys(pks))\n+                query = sql.DeleteQuery(model)\n+                # delete_batch handles batching for DB parameter limits\n+                count = query.delete_batch(pk_list, self.using)\n+                deleted_counter[model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n"
  },
  "django__django-11951": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11951",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..92349cd0c5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,8 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+        max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n+        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n"
  },
  "django__django-11964": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11964",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..bf96a2ea15 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,7 +60,10 @@ class ChoicesMeta(enum.EnumMeta):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n-    pass\n+\n+    def __str__(self):\n+        \"\"\"Return the value of the enum member as its string representation.\"\"\"\n+        return str(self.value)\n \n \n class IntegerChoices(int, Choices):\n"
  },
  "django__django-11999": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11999",
    "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..2f4172a32b 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            # Only set get_<field>_display if not already defined on the model class,\n+            # so user-defined methods can override the default implementation.\n+            if not hasattr(cls, 'get_%s_display' % self.name):\n+                setattr(cls, 'get_%s_display' % self.name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n"
  },
  "django__django-12050": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12050",
    "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..90475d6fb9 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1073,7 +1073,7 @@ class Query(BaseExpression):\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n-            value = tuple(resolved_values)\n+            value = type(value)(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n"
  },
  "django__django-12143": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12143",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..a100f1c499 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1631,7 +1631,7 @@ class ModelAdmin(BaseModelAdmin):\n \n     def _get_edited_object_pks(self, request, prefix):\n         \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name))\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\n"
  },
  "django__django-12155": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12155",
    "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..63576f5b80 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,7 +34,13 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n+    # Compute minimum indentation from the second line onwards to avoid\n+    # treating the first-line's (often zero) indentation as representative.\n+    if len(lines) > 1:\n+        indented_lines = [line for line in lines[1:] if line.lstrip()]\n+        indent = min((len(line) - len(line.lstrip()) for line in indented_lines), default=0)\n+    else:\n+        indent = 0\n     trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n     return \"\\n\".join(trimmed).strip()\n \n"
  },
  "django__django-12209": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12209",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..007861a3fb 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -850,7 +850,7 @@ class Model(metaclass=ModelBase):\n         # Skip an UPDATE when adding an instance and primary key has a default.\n         if (\n             not force_insert and\n-            self._state.adding and\n+            self._state.adding and not pk_set and\n             self._meta.pk.default and\n             self._meta.pk.default is not NOT_PROVIDED\n         ):\n"
  },
  "django__django-12262": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12262",
    "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..2f74556268 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -261,7 +261,7 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if kwarg:\n             # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n+            if param not in params and param not in kwonly and varkw is None:\n                 # An unexpected keyword argument was supplied\n                 raise TemplateSyntaxError(\n                     \"'%s' received unexpected keyword argument '%s'\" %\n"
  },
  "django__django-12325": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12325",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..7802d61c6d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -204,7 +204,17 @@ class ModelBase(type):\n             for field in base._meta.local_fields:\n                 if isinstance(field, OneToOneField):\n                     related = resolve_relation(new_class, field.remote_field.model)\n-                    parent_links[make_model_tuple(related)] = field\n+                    key = make_model_tuple(related)\n+                    existing = parent_links.get(key)\n+                    # Prefer an explicit parent_link=True field. If there's no\n+                    # existing entry, or the new field has parent_link=True while\n+                    # the existing one does not, use the new field. This avoids\n+                    # depending on field declaration order when multiple\n+                    # OneToOneFields reference the same parent model.\n+                    if (existing is None or\n+                        (getattr(field.remote_field, 'parent_link', False) and\n+                         not getattr(existing.remote_field, 'parent_link', False))):\n+                        parent_links[key] = field\n \n         # Track fields inherited from base models.\n         inherited_attributes = set()\n"
  },
  "django__django-12406": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..6d9831e292 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1185,10 +1185,16 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n-            self.empty_label = None\n+        # Don't present an empty choice for RadioSelect when the field is required (blank=False).\n+        from .widgets import RadioSelect\n+        is_radio = widget is not None and (isinstance(widget, RadioSelect) or (isinstance(widget, type) and issubclass(widget, RadioSelect)))\n+        if is_radio:\n+            self.empty_label = None if required else empty_label\n         else:\n-            self.empty_label = empty_label\n+            if required and (initial is not None):\n+                self.empty_label = None\n+            else:\n+                self.empty_label = empty_label\n \n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n"
  },
  "django__django-12713": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12713",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..b3c4020f39 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -250,15 +250,16 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n         db = kwargs.get('using')\n \n         autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n-            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n-            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n-            kwargs['widget'] = widgets.FilteredSelectMultiple(\n-                db_field.verbose_name,\n-                db_field.name in self.filter_vertical\n-            )\n+        if 'widget' not in kwargs:\n+            if db_field.name in autocomplete_fields:\n+                kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in self.raw_id_fields:\n+                kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+                kwargs['widget'] = widgets.FilteredSelectMultiple(\n+                    db_field.verbose_name,\n+                    db_field.name in self.filter_vertical\n+                )\n \n         if 'queryset' not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\n"
  },
  "django__django-9296": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-9296",
    "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..896535d89a 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -106,6 +106,10 @@ class Paginator:\n         \"\"\"\n         return range(1, self.num_pages + 1)\n \n+    def __iter__(self):\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n     def _check_object_list_is_ordered(self):\n         \"\"\"\n         Warn if self.object_list is unordered (typically a QuerySet).\n"
  },
  "sphinx-doc__sphinx-10323": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10323",
    "model_patch": "diff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..9437fe9a5 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -224,9 +224,9 @@ class LiteralIncludeReader:\n                        self.start_filter,\n                        self.end_filter,\n                        self.lines_filter,\n+                       self.dedent_filter,\n                        self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+                       self.append_filter]\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\ndiff --git a/test_pom.xml b/test_pom.xml\nnew file mode 100644\nindex 000000000..9d60fc60d\n--- /dev/null\n+++ b/test_pom.xml\n@@ -0,0 +1,10 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project>\n+  <build>\n+    <plugins>\n+      <plugin>\n+        <groupId>com.github.ekryd.sortpom</groupId>\n+      </plugin>\n+    </plugins>\n+  </build>\n+</project>\n"
  },
  "sphinx-doc__sphinx-10466": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10466",
    "model_patch": "diff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..1b35802ed 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -29,12 +29,18 @@ logger = logging.getLogger(__name__)\n \n \n class Message:\n-    \"\"\"An entry of translatable message.\"\"\"\n-    def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n-        self.text = text\n-        self.locations = locations\n-        self.uuids = uuids\n-\n+\t\"\"\"An entry of translatable message.\"\"\"\n+\tdef __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n+\t\tself.text = text\n+\t\t# remove duplicate locations while preserving order\n+\t\tseen = set()\n+\t\tunique_locs = []\n+\t\tfor loc in locations:\n+\t\t\tif loc not in seen:\n+\t\t\t\tseen.add(loc)\n+\t\t\t\tunique_locs.append(loc)\n+\t\tself.locations = unique_locs\n+\t\tself.uuids = uuids\n \n class Catalog:\n     \"\"\"Catalog of translatable messages.\"\"\"\n"
  },
  "sphinx-doc__sphinx-11510": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-11510",
    "model_patch": "diff --git a/demo/conf.py b/demo/conf.py\nnew file mode 100644\nindex 000000000..c38587248\n--- /dev/null\n+++ b/demo/conf.py\n@@ -0,0 +1,3 @@\n+import sys, os\n+sys.path.insert(0, os.path.abspath('.'))\n+extensions = ['my_extension']\ndiff --git a/demo/index.rst b/demo/index.rst\nnew file mode 100644\nindex 000000000..f2dec1395\n--- /dev/null\n+++ b/demo/index.rst\n@@ -0,0 +1,6 @@\n+This is a test\n+==============\n+\n+.. include:: something-to-include.rst\n+\n+&REPLACE_ME;\ndiff --git a/demo/my_extension.py b/demo/my_extension.py\nnew file mode 100644\nindex 000000000..83e8aeddc\n--- /dev/null\n+++ b/demo/my_extension.py\n@@ -0,0 +1,10 @@\n+from sphinx.application import Sphinx\n+\n+def subst_vars_replace(app: Sphinx, docname, source):\n+    result = source[0]\n+    result = result.replace(\"&REPLACE_ME;\", \"REPLACED\")\n+    source[0] = result\n+\n+def setup(app: Sphinx):\n+    app.connect('source-read', subst_vars_replace)\n+    return dict(version='1.0', parallel_read_safe=True, parallel_write_safe=True)\ndiff --git a/demo/something-to-include.rst b/demo/something-to-include.rst\nnew file mode 100644\nindex 000000000..e63253568\n--- /dev/null\n+++ b/demo/something-to-include.rst\n@@ -0,0 +1,4 @@\n+Testing\n+=======\n+\n+&REPLACE_ME;\ndiff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 19f7c0a8d..097958705 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -369,14 +369,61 @@ class Include(BaseInclude, SphinxDirective):\n     \"\"\"\n \n     def run(self) -> list[Node]:\n-        if self.arguments[0].startswith('<') and \\\n-           self.arguments[0].endswith('>'):\n-            # docutils \"standard\" includes, do not do path processing\n+        # Handle standard <> includes by delegating to docutils\n+        if self.arguments[0].startswith('<') and self.arguments[0].endswith('>'):\n             return super().run()\n+        # Resolve filename relative to the current document\n         rel_filename, filename = self.env.relfn2path(self.arguments[0])\n         self.arguments[0] = filename\n         self.env.note_included(filename)\n-        return super().run()\n+        # Read the file so that we can emit the \"source-read\" event\n+        from docutils import io as _io\n+        from docutils import statemachine as _statemachine\n+        current_source = self.state.document.current_source\n+        encoding = getattr(self.state.document.settings, 'input_encoding', None)\n+        e_handler = getattr(self.state.document.settings, 'input_encoding_error_handler', 'strict')\n+        try:\n+            include_file = _io.FileInput(source_path=filename, encoding=encoding, error_handler=e_handler)\n+            rawtext = include_file.read()\n+        except Exception:\n+            # Fallback to docutils default behavior on error\n+            return super().run()\n+        # Allow Sphinx extensions to modify the included source via source-read\n+        try:\n+            arg = [rawtext]\n+            self.env.events.emit('source-read', self.env.docname, arg)\n+            rawtext = arg[0]\n+        except Exception:\n+            # ignore extension errors to preserve include behavior\n+            pass\n+        # Handle literal/code options by delegating when needed\n+        if 'literal' in self.options:\n+            # Don't convert tabs to spaces, if `tab_width` is negative.\n+            tab_width = self.options.get('tab-width', self.state.document.settings.tab_width)\n+            if tab_width >= 0:\n+                text = rawtext.expandtabs(tab_width)\n+            else:\n+                text = rawtext\n+            literal_block = nodes.literal_block(rawtext, source=filename, classes=self.options.get('class', []))\n+            literal_block.line = 1\n+            self.add_name(literal_block)\n+            literal_block += nodes.Text(text)\n+            return [literal_block]\n+        if 'code' in self.options:\n+            # Let docutils handle code block creation to preserve behavior\n+            return super().run()\n+        # Default: include as reST source into the state machine\n+        include_lines = _statemachine.string2lines(rawtext, self.options.get('tab-width', self.state.document.settings.tab_width), convert_whitespace=True)\n+        # mark end as docutils does\n+        include_lines += ['', '.. end of inclusion from \"%s\"' % filename]\n+        self.state_machine.insert_input(include_lines, filename)\n+        # record the include in the document's include_log\n+        clip_options = (self.options.get('start-line', None), self.options.get('end-line', None), self.options.get('end-before', None), self.options.get('start-after', None))\n+        include_log = self.state.document.include_log\n+        if not include_log:\n+            include_log.append((filename, (None, None, None, None)))\n+        include_log.append((filename, clip_options))\n+        return []\n \n \n def setup(app: Sphinx) -> dict[str, Any]:\n@@ -402,4 +449,4 @@ def setup(app: Sphinx) -> dict[str, Any]:\n         'version': 'builtin',\n         'parallel_read_safe': True,\n         'parallel_write_safe': True,\n-    }\n+    }\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-7748": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7748",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex f8e4be999..98e243e79 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1062,9 +1062,24 @@ class DocstringSignatureMixin:\n                     valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n             if base not in valid_names:\n                 continue\n-            # re-prepare docstring to ignore more leading indentation\n+            # re-prepare docstring to ignore more leading indentation.\n+            # If the docstring contains multiple leading signature lines (e.g.\n+            # overloaded methods emitted by SWIG), strip all of them so they\n+            # don't appear in the rendered docstring. Keep using the first\n+            # matched signature for extracting args/retann.\n             tab_width = self.directive.state.document.settings.tab_width  # type: ignore\n-            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[1:]),\n+            # consume all consecutive leading signature lines that match and\n+            # whose base name is valid for this object.\n+            sig_start = 0\n+            for j, line in enumerate(doclines):\n+                m2 = py_ext_sig_re.match(line)\n+                if not m2:\n+                    break\n+                _exmod, _path, base2, _args2, _retann2 = m2.groups()\n+                if base2 not in valid_names:\n+                    break\n+                sig_start = j + 1\n+            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[sig_start:]),\n                                                         tabsize=tab_width)\n             result = args, retann\n             # don't look any further\n"
  },
  "sphinx-doc__sphinx-7757": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7757",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex 9bafff11c..88f50d321 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -84,7 +84,7 @@ class _UnparseVisitor(ast.NodeVisitor):\n     def _visit_arg_with_default(self, arg: ast.arg, default: Optional[ast.AST]) -> str:\n         \"\"\"Unparse a single argument to a string.\"\"\"\n         name = self.visit(arg)\n-        if default:\n+        if default is not None:\n             if arg.annotation:\n                 name += \" = %s\" % self.visit(default)\n             else:\n"
  },
  "sphinx-doc__sphinx-7985": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7985",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..baf5e177c 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -213,7 +213,31 @@ class CheckExternalLinksBuilder(Builder):\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n             elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+                # treat local/internal links: check against known documents\n+                # split anchor if present\n+                if '#' in uri:\n+                    target, anchor = uri.split('#', 1)\n+                else:\n+                    target, anchor = uri, None\n+                # empty target means same-document anchor -> consider unchecked\n+                if target == '':\n+                    return 'unchecked', '', 0\n+                # normalize possible file extensions and paths\n+                docname = target\n+                # strip common file extensions\n+                for ext in ('.html', '.htm', '.rst'):\n+                    if docname.endswith(ext):\n+                        docname = docname[:-len(ext)]\n+                # strip leading ./ or /\n+                docname = docname.lstrip('./')\n+                docname = docname.lstrip('/')\n+                if docname in getattr(self.env, 'found_docs', set()):\n+                    # Document exists; if anchor checking is enabled we'd need\n+                    # to verify the anchor in the generated output which is\n+                    # out of scope for this simple check, so consider working.\n+                    return 'working', '', 0\n+                else:\n+                    return 'broken', \"local target '%s' not found\" % target, 0\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n"
  },
  "sphinx-doc__sphinx-8035": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8035",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 8c3509c3b..b984bd4ff 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -859,7 +859,7 @@ class ModuleDocumenter(Documenter):\n         'show-inheritance': bool_option, 'synopsis': identity,\n         'platform': identity, 'deprecated': bool_option,\n         'member-order': member_order_option, 'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n         'imported-members': bool_option, 'ignore-module-all': bool_option\n     }  # type: Dict[str, Callable]\n \n@@ -1279,7 +1279,7 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         'noindex': bool_option, 'inherited-members': inherited_members_option,\n         'show-inheritance': bool_option, 'member-order': member_order_option,\n         'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n     }  # type: Dict[str, Callable]\n \n     _signature_class = None  # type: Any\n"
  },
  "sphinx-doc__sphinx-8056": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8056",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..c3d86ebb4 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -439,14 +439,30 @@ class GoogleDocstring:\n         multi = len(fields) > 1\n         lines = []  # type: List[str]\n         for _name, _type, _desc in fields:\n-            field = self._format_field(_name, _type, _desc)\n-            if multi:\n-                if lines:\n-                    lines.extend(self._format_block(padding + ' * ', field))\n-                else:\n-                    lines.extend(self._format_block(field_type + ' * ', field))\n+            # support multiple names separated by commas sharing the same type/desc\n+            if _name and ',' in _name:\n+                names = [n.strip() for n in _name.split(',') if n.strip()]\n             else:\n-                lines.extend(self._format_block(field_type + ' ', field))\n+                names = [_name] if _name else ['']\n+            first = True\n+            for name in names:\n+                field = self._format_field(name, _type, _desc)\n+                if multi:\n+                    if lines:\n+                        lines.extend(self._format_block(padding + ' * ', field))\n+                    else:\n+                        # for the very first field in the whole block use the field_type\n+                        if first:\n+                            lines.extend(self._format_block(field_type + ' * ', field))\n+                        else:\n+                            lines.extend(self._format_block(padding + ' * ', field))\n+                else:\n+                    # single field case: only emit field_type once for the first name\n+                    if first:\n+                        lines.extend(self._format_block(field_type + ' ', field))\n+                    else:\n+                        lines.extend(self._format_block(padding + ' ', field))\n+                first = False\n         if lines and lines[-1]:\n             lines.append('')\n         return lines\n"
  },
  "sphinx-doc__sphinx-8269": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8269",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..1083e82ec 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -166,6 +166,7 @@ class CheckExternalLinksBuilder(Builder):\n                     # Read the whole document and see if #anchor exists\n                     response = requests.get(req_url, stream=True, config=self.app.config,\n                                             auth=auth_info, **kwargs)\n+                    response.raise_for_status()\n                     found = check_anchor(response, unquote(anchor))\n \n                     if not found:\n"
  },
  "sphinx-doc__sphinx-8475": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8475",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..4104fe658 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -20,7 +20,7 @@ from urllib.parse import unquote, urlparse\n \n from docutils import nodes\n from docutils.nodes import Node\n-from requests.exceptions import HTTPError\n+from requests.exceptions import HTTPError, TooManyRedirects\n \n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -172,7 +172,7 @@ class CheckExternalLinksBuilder(Builder):\n                                                  config=self.app.config, auth=auth_info,\n                                                  **kwargs)\n                         response.raise_for_status()\n-                    except HTTPError:\n+                    except (HTTPError, TooManyRedirects):\n                         # retry with GET request if that fails, some servers\n                         # don't like HEAD requests.\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n"
  },
  "sphinx-doc__sphinx-8548": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8548",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex ddfd2b365..14c4457d0 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -746,7 +746,26 @@ class Documenter:\n                         keep = has_doc or self.options.undoc_members\n                 else:\n                     keep = False\n-            elif (namespace, membername) in attr_docs:\n+            # check for documented attributes in this namespace or any base class namespace\n+            found = False\n+            if (namespace, membername) in attr_docs:\n+                found = True\n+            else:\n+                # try base classes' qualnames if documenting a class\n+                try:\n+                    obj_for_mro = self.object if inspect.isclass(self.object) else None\n+                except Exception:\n+                    obj_for_mro = None\n+                if obj_for_mro:\n+                    for cls in getattr(obj_for_mro, '__mro__', ())[1:]:\n+                        try:\n+                            qualname = safe_getattr(cls, '__qualname__')\n+                            if qualname and (qualname, membername) in attr_docs:\n+                                found = True\n+                                break\n+                        except Exception:\n+                            continue\n+            if found:\n                 if want_all and isprivate:\n                     if self.options.private_members is None:\n                         keep = False\n@@ -2496,4 +2515,4 @@ def setup(app: Sphinx) -> Dict[str, Any]:\n     app.setup_extension('sphinx.ext.autodoc.type_comment')\n     app.setup_extension('sphinx.ext.autodoc.typehints')\n \n-    return {'version': sphinx.__display_version__, 'parallel_read_safe': True}\n+    return {'version': sphinx.__display_version__, 'parallel_read_safe': True}\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-8638": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8638",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 000e2e8d3..ce2dd4200 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1149,9 +1149,19 @@ class PythonDomain(Domain):\n                     if fullname in self.objects and self.objects[fullname].objtype in objtypes:\n                         newname = fullname\n                 if not newname:\n-                    if modname and modname + '.' + name in self.objects and \\\n+                    # Prefer class-qualified name (classname.name) if available\n+                    if classname and classname + '.' + name in self.objects and \\\n+                       self.objects[classname + '.' + name].objtype in objtypes:\n+                        newname = classname + '.' + name\n+                    # then try module.classname.name\n+                    elif modname and classname and modname + '.' + classname + '.' + name in self.objects and \\\n+                         self.objects[modname + '.' + classname + '.' + name].objtype in objtypes:\n+                        newname = modname + '.' + classname + '.' + name\n+                    # then module-level name\n+                    elif modname and modname + '.' + name in self.objects and \\\n                        self.objects[modname + '.' + name].objtype in objtypes:\n                         newname = modname + '.' + name\n+                    # then unqualified name\n                     elif name in self.objects and self.objects[name].objtype in objtypes:\n                         newname = name\n                     else:\n@@ -1162,18 +1172,21 @@ class PythonDomain(Domain):\n                                    self.objects[oname].objtype in objtypes]\n         else:\n             # NOTE: searching for exact match, object type is not considered\n-            if name in self.objects:\n-                newname = name\n-            elif type == 'mod':\n+            if type == 'mod':\n                 # only exact matches allowed for modules\n                 return []\n+            # Try classname.name first (most specific)\n             elif classname and classname + '.' + name in self.objects:\n                 newname = classname + '.' + name\n+            # Then try module.classname.name\n+            elif modname and classname and modname + '.' + classname + '.' + name in self.objects:\n+                newname = modname + '.' + classname + '.' + name\n+            # Then module.name\n             elif modname and modname + '.' + name in self.objects:\n                 newname = modname + '.' + name\n-            elif modname and classname and \\\n-                    modname + '.' + classname + '.' + name in self.objects:\n-                newname = modname + '.' + classname + '.' + name\n+            # Finally unqualified name\n+            elif name in self.objects:\n+                newname = name\n         if newname is not None:\n             matches.append((newname, self.objects[newname]))\n         return matches\n"
  },
  "sphinx-doc__sphinx-8721": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8721",
    "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..7c15e91a9 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -180,6 +180,9 @@ def should_generate_module_page(app: Sphinx, modname: str) -> bool:\n \n def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], None, None]:\n     env = app.builder.env\n+    # Do not generate viewcode pages for epub builders unless explicitly enabled\n+    if app.builder.name.startswith('epub') and not env.config.viewcode_enable_epub:\n+        return\n     if not hasattr(env, '_viewcode_modules'):\n         return\n     highlighter = app.builder.highlighter  # type: ignore\n"
  },
  "sphinx-doc__sphinx-9229": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9229",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 1f4c98284..71d20633e 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1725,7 +1725,12 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n                     ) -> None:\n         if self.doc_as_attr:\n             try:\n-                more_content = StringList([_('alias of %s') % restify(self.object)], source='')\n+                alias_line = StringList([_('alias of %s') % restify(self.object)], source='')\n+                if more_content:\n+                    # prepend alias info but keep existing more_content (docstrings)\n+                    more_content = alias_line + more_content\n+                else:\n+                    more_content = alias_line\n             except AttributeError:\n                 pass  # Invalid class object is passed.\n \n"
  },
  "sphinx-doc__sphinx-9320": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9320",
    "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..296429693 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -146,6 +146,8 @@ def do_prompt(text: str, default: str = None, validator: Callable[[str], Any] =\n         else:\n             prompt = colorize(COLOR_QUESTION, prompt, input_mode=False)\n         x = term_input(prompt).strip()\n+        if default == '' and not x:\n+            return x\n         if default and not x:\n             x = default\n         try:\n"
  },
  "sphinx-doc__sphinx-9367": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9367",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..58abdcac7 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -214,10 +214,12 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n+            # Preserve trailing comma for single-element tuples\n+            if len(node.elts) == 1:\n+                return \"(\" + self.visit(node.elts[0]) + \",)\"\n             return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n-\n     if sys.version_info < (3, 8):\n         # these ast nodes were deprecated in python 3.8\n         def visit_Bytes(self, node: ast.Bytes) -> str:\n"
  },
  "sphinx-doc__sphinx-9461": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9461",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 23dd9e930..fb64406bf 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -384,7 +384,20 @@ def iscoroutinefunction(obj: Any) -> bool:\n \n \n def isproperty(obj: Any) -> bool:\n-    \"\"\"Check if the object is property.\"\"\"\n+    \"\"\"Check if the object is property.\n+\n+    This handles descriptors wrapped by classmethod/staticmethod by\n+    unwrapping them (using their __func__) before the isinstance check.\n+    \"\"\"\n+    # Unwrap classmethod/staticmethod that may wrap a property (PEP changes since py3.9)\n+    try:\n+        # classmethod and staticmethod have __func__ attribute referencing the wrapped object\n+        if isinstance(obj, (classmethod, staticmethod)):\n+            obj = obj.__func__\n+    except Exception:\n+        # be conservative if any unexpected error occurs, fall back to original object\n+        pass\n+\n     if sys.version_info >= (3, 8):\n         from functools import cached_property  # cached_property is available since py3.8\n         if isinstance(obj, cached_property):\n"
  },
  "sphinx-doc__sphinx-9698": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9698",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..1a3bd60c7 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -796,7 +796,7 @@ class PyMethod(PyObject):\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n+            return _('%s (%s property)') % (methname, clsname)\n         elif 'staticmethod' in self.options:\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\n"
  },
  "django__django-12273": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12273",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 844c01e95e..092ab570f5 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -743,6 +743,10 @@ class Model(metaclass=ModelBase):\n             if loaded_fields:\n                 update_fields = frozenset(loaded_fields)\n \n+        # If the primary key has been reset to None, treat the instance as new\n+        if self.pk is None:\n+            # Ensure an INSERT is performed instead of UPDATE\n+            self._state.adding = True\n         self.save_base(using=using, force_insert=force_insert,\n                        force_update=force_update, update_fields=update_fields)\n     save.alters_data = True\n"
  },
  "django__django-12308": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12308",
    "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..22b224ecae 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,15 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    # Special-case JSONField to display valid JSON when readonly in the admin.\n+    elif isinstance(field, models.JSONField):\n+        try:\n+            form_field = field.formfield()\n+            # Use the form field's prepare_value to get proper JSON (handles invalid input cases).\n+            return form_field.prepare_value(value)\n+        except Exception:\n+            # Fallback to the generic display for value.\n+            return display_for_value(value, empty_value_display)\n     else:\n         return display_for_value(value, empty_value_display)\n \n"
  },
  "sphinx-doc__sphinx-10435": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10435",
    "model_patch": "diff --git a/sphinx/writers/latex.py b/sphinx/writers/latex.py\nindex e0c7d56f8..ec2174a26 100644\n--- a/sphinx/writers/latex.py\n+++ b/sphinx/writers/latex.py\n@@ -721,10 +721,10 @@ class LaTeXTranslator(SphinxTranslator):\n         pass\n \n     def visit_desc_inline(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n \n     def depart_desc_inline(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     # Nodes for high-level structure in signatures\n     ##############################################\n@@ -734,15 +734,15 @@ class LaTeXTranslator(SphinxTranslator):\n         self.literal_whitespace += 1\n \n     def depart_desc_name(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n         self.literal_whitespace -= 1\n \n     def visit_desc_addname(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n         self.literal_whitespace += 1\n \n     def depart_desc_addname(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n         self.literal_whitespace -= 1\n \n     def visit_desc_type(self, node: Element) -> None:\n@@ -788,7 +788,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxbfcode{\\sphinxupquote{')\n \n     def depart_desc_annotation(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     ##############################################\n \n@@ -1621,7 +1621,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxstyleliteralemphasis{\\sphinxupquote{')\n \n     def depart_literal_emphasis(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     def visit_strong(self, node: Element) -> None:\n         self.body.append(r'\\sphinxstylestrong{')\n@@ -1633,7 +1633,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxstyleliteralstrong{\\sphinxupquote{')\n \n     def depart_literal_strong(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     def visit_abbreviation(self, node: Element) -> None:\n         abbr = node.astext()\n@@ -1701,7 +1701,7 @@ class LaTeXTranslator(SphinxTranslator):\n             return\n         lang = node.get(\"language\", None)\n         if 'code' not in node['classes'] or not lang:\n-            self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+            self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n             return\n \n         opts = self.config.highlight_options.get(lang, {})\n@@ -1710,15 +1710,15 @@ class LaTeXTranslator(SphinxTranslator):\n         # TODO: Use nowrap option once LaTeX formatter supports it\n         # https://github.com/pygments/pygments/pull/1343\n         hlcode = hlcode.replace(r'\\begin{Verbatim}[commandchars=\\\\\\{\\}]',\n-                                r'\\sphinxcode{\\sphinxupquote{')\n+                                r'\\sphinxcode{\\sphinxupquote{%')\n         # get consistent trailer\n         hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n         self.body.append(hlcode)\n-        self.body.append('}}')\n+        self.body.append('%}}')\n         raise nodes.SkipNode\n \n     def depart_literal(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     def visit_footnote_reference(self, node: Element) -> None:\n         raise nodes.SkipNode\ndiff --git a/sphinx/writers/latex.py.bak b/sphinx/writers/latex.py.bak\nnew file mode 100644\nindex 000000000..a290641ad\n--- /dev/null\n+++ b/sphinx/writers/latex.py.bak\n@@ -0,0 +1,2061 @@\n+\"\"\"Custom docutils writer for LaTeX.\n+\n+Much of this code is adapted from Dave Kuhlman's \"docpy\" writer from his\n+docutils sandbox.\n+\"\"\"\n+\n+import re\n+import warnings\n+from collections import defaultdict\n+from os import path\n+from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Set, Tuple, cast\n+\n+from docutils import nodes, writers\n+from docutils.nodes import Element, Node, Text\n+\n+from sphinx import addnodes, highlighting\n+from sphinx.deprecation import RemovedInSphinx70Warning\n+from sphinx.domains import IndexEntry\n+from sphinx.domains.std import StandardDomain\n+from sphinx.errors import SphinxError\n+from sphinx.locale import _, __, admonitionlabels\n+from sphinx.util import logging, split_into, texescape\n+from sphinx.util.docutils import SphinxTranslator\n+from sphinx.util.nodes import clean_astext, get_prev_node\n+from sphinx.util.template import LaTeXRenderer\n+from sphinx.util.texescape import tex_replace_map\n+\n+try:\n+    from docutils.utils.roman import toRoman\n+except ImportError:\n+    # In Debian/Ubuntu, roman package is provided as roman, not as docutils.utils.roman\n+    from roman import toRoman  # type: ignore\n+\n+if TYPE_CHECKING:\n+    from sphinx.builders.latex import LaTeXBuilder\n+    from sphinx.builders.latex.theming import Theme\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+MAX_CITATION_LABEL_LENGTH = 8\n+LATEXSECTIONNAMES = [\"part\", \"chapter\", \"section\", \"subsection\",\n+                     \"subsubsection\", \"paragraph\", \"subparagraph\"]\n+ENUMERATE_LIST_STYLE = defaultdict(lambda: r'\\arabic',\n+                                   {\n+                                       'arabic': r'\\arabic',\n+                                       'loweralpha': r'\\alph',\n+                                       'upperalpha': r'\\Alph',\n+                                       'lowerroman': r'\\roman',\n+                                       'upperroman': r'\\Roman',\n+                                   })\n+\n+CR = '\\n'\n+BLANKLINE = '\\n\\n'\n+EXTRA_RE = re.compile(r'^(.*\\S)\\s+\\(([^()]*)\\)\\s*$')\n+\n+\n+class collected_footnote(nodes.footnote):\n+    \"\"\"Footnotes that are collected are assigned this class.\"\"\"\n+\n+\n+class UnsupportedError(SphinxError):\n+    category = 'Markup is unsupported in LaTeX'\n+\n+\n+class LaTeXWriter(writers.Writer):\n+\n+    supported = ('sphinxlatex',)\n+\n+    settings_spec = ('LaTeX writer options', '', (\n+        ('Document name', ['--docname'], {'default': ''}),\n+        ('Document class', ['--docclass'], {'default': 'manual'}),\n+        ('Author', ['--author'], {'default': ''}),\n+    ))\n+    settings_defaults: Dict = {}\n+\n+    output = None\n+\n+    def __init__(self, builder: \"LaTeXBuilder\") -> None:\n+        super().__init__()\n+        self.builder = builder\n+        self.theme: Theme = None\n+\n+    def translate(self) -> None:\n+        visitor = self.builder.create_translator(self.document, self.builder, self.theme)\n+        self.document.walkabout(visitor)\n+        self.output = cast(LaTeXTranslator, visitor).astext()\n+\n+\n+# Helper classes\n+\n+class Table:\n+    \"\"\"A table data\"\"\"\n+\n+    def __init__(self, node: Element) -> None:\n+        self.header: List[str] = []\n+        self.body: List[str] = []\n+        self.align = node.get('align', 'default')\n+        self.classes: List[str] = node.get('classes', [])\n+        self.colcount = 0\n+        self.colspec: str = None\n+        self.colwidths: List[int] = []\n+        self.has_problematic = False\n+        self.has_oldproblematic = False\n+        self.has_verbatim = False\n+        self.caption: List[str] = None\n+        self.stubs: List[int] = []\n+\n+        # current position\n+        self.col = 0\n+        self.row = 0\n+\n+        # A dict mapping a table location to a cell_id (cell = rectangular area)\n+        self.cells: Dict[Tuple[int, int], int] = defaultdict(int)\n+        self.cell_id = 0  # last assigned cell_id\n+\n+    def is_longtable(self) -> bool:\n+        \"\"\"True if and only if table uses longtable environment.\"\"\"\n+        return self.row > 30 or 'longtable' in self.classes\n+\n+    def get_table_type(self) -> str:\n+        \"\"\"Returns the LaTeX environment name for the table.\n+\n+        The class currently supports:\n+\n+        * longtable\n+        * tabular\n+        * tabulary\n+        \"\"\"\n+        if self.is_longtable():\n+            return 'longtable'\n+        elif self.has_verbatim:\n+            return 'tabular'\n+        elif self.colspec:\n+            return 'tabulary'\n+        elif self.has_problematic or (self.colwidths and 'colwidths-given' in self.classes):\n+            return 'tabular'\n+        else:\n+            return 'tabulary'\n+\n+    def get_colspec(self) -> str:\n+        \"\"\"Returns a column spec of table.\n+\n+        This is what LaTeX calls the 'preamble argument' of the used table environment.\n+\n+        .. note:: the ``\\\\X`` and ``T`` column type specifiers are defined in ``sphinx.sty``.\n+        \"\"\"\n+        if self.colspec:\n+            return self.colspec\n+        elif self.colwidths and 'colwidths-given' in self.classes:\n+            total = sum(self.colwidths)\n+            colspecs = [r'\\X{%d}{%d}' % (width, total) for width in self.colwidths]\n+            return '{|%s|}' % '|'.join(colspecs) + CR\n+        elif self.has_problematic:\n+            return r'{|*{%d}{\\X{1}{%d}|}}' % (self.colcount, self.colcount) + CR\n+        elif self.get_table_type() == 'tabulary':\n+            # sphinx.sty sets T to be J by default.\n+            return '{|' + ('T|' * self.colcount) + '}' + CR\n+        elif self.has_oldproblematic:\n+            return r'{|*{%d}{\\X{1}{%d}|}}' % (self.colcount, self.colcount) + CR\n+        else:\n+            return '{|' + ('l|' * self.colcount) + '}' + CR\n+\n+    def add_cell(self, height: int, width: int) -> None:\n+        \"\"\"Adds a new cell to a table.\n+\n+        It will be located at current position: (``self.row``, ``self.col``).\n+        \"\"\"\n+        self.cell_id += 1\n+        for col in range(width):\n+            for row in range(height):\n+                assert self.cells[(self.row + row, self.col + col)] == 0\n+                self.cells[(self.row + row, self.col + col)] = self.cell_id\n+\n+    def cell(self, row: int = None, col: int = None) -> \"TableCell\":\n+        \"\"\"Returns a cell object (i.e. rectangular area) containing given position.\n+\n+        If no option arguments: ``row`` or ``col`` are given, the current position;\n+        ``self.row`` and ``self.col`` are used to get a cell object by default.\n+        \"\"\"\n+        try:\n+            if row is None:\n+                row = self.row\n+            if col is None:\n+                col = self.col\n+            return TableCell(self, row, col)\n+        except IndexError:\n+            return None\n+\n+\n+class TableCell:\n+    \"\"\"Data of a cell in a table.\"\"\"\n+\n+    def __init__(self, table: Table, row: int, col: int) -> None:\n+        if table.cells[(row, col)] == 0:\n+            raise IndexError\n+\n+        self.table = table\n+        self.cell_id = table.cells[(row, col)]\n+        self.row = row\n+        self.col = col\n+\n+        # adjust position for multirow/multicol cell\n+        while table.cells[(self.row - 1, self.col)] == self.cell_id:\n+            self.row -= 1\n+        while table.cells[(self.row, self.col - 1)] == self.cell_id:\n+            self.col -= 1\n+\n+    @property\n+    def width(self) -> int:\n+        \"\"\"Returns the cell width.\"\"\"\n+        width = 0\n+        while self.table.cells[(self.row, self.col + width)] == self.cell_id:\n+            width += 1\n+        return width\n+\n+    @property\n+    def height(self) -> int:\n+        \"\"\"Returns the cell height.\"\"\"\n+        height = 0\n+        while self.table.cells[(self.row + height, self.col)] == self.cell_id:\n+            height += 1\n+        return height\n+\n+\n+def escape_abbr(text: str) -> str:\n+    \"\"\"Adjust spacing after abbreviations.\"\"\"\n+    return re.sub(r'\\.(?=\\s|$)', r'.\\@', text)\n+\n+\n+def rstdim_to_latexdim(width_str: str, scale: int = 100) -> str:\n+    \"\"\"Convert `width_str` with rst length to LaTeX length.\"\"\"\n+    match = re.match(r'^(\\d*\\.?\\d*)\\s*(\\S*)$', width_str)\n+    if not match:\n+        raise ValueError\n+    res = width_str\n+    amount, unit = match.groups()[:2]\n+    if scale == 100:\n+        float(amount)  # validate amount is float\n+        if unit in ('', \"px\"):\n+            res = r\"%s\\sphinxpxdimen\" % amount\n+        elif unit == 'pt':\n+            res = '%sbp' % amount  # convert to 'bp'\n+        elif unit == \"%\":\n+            res = r\"%.3f\\linewidth\" % (float(amount) / 100.0)\n+    else:\n+        amount_float = float(amount) * scale / 100.0\n+        if unit in ('', \"px\"):\n+            res = r\"%.5f\\sphinxpxdimen\" % amount_float\n+        elif unit == 'pt':\n+            res = '%.5fbp' % amount_float\n+        elif unit == \"%\":\n+            res = r\"%.5f\\linewidth\" % (amount_float / 100.0)\n+        else:\n+            res = \"%.5f%s\" % (amount_float, unit)\n+    return res\n+\n+\n+class LaTeXTranslator(SphinxTranslator):\n+    builder: \"LaTeXBuilder\" = None\n+\n+    secnumdepth = 2  # legacy sphinxhowto.cls uses this, whereas article.cls\n+    # default is originally 3. For book/report, 2 is already LaTeX default.\n+    ignore_missing_images = False\n+\n+    def __init__(self, document: nodes.document, builder: \"LaTeXBuilder\",\n+                 theme: \"Theme\") -> None:\n+        super().__init__(document, builder)\n+        self.body: List[str] = []\n+        self.theme = theme\n+\n+        # flags\n+        self.in_title = 0\n+        self.in_production_list = 0\n+        self.in_footnote = 0\n+        self.in_caption = 0\n+        self.in_term = 0\n+        self.needs_linetrimming = 0\n+        self.in_minipage = 0\n+        self.no_latex_floats = 0\n+        self.first_document = 1\n+        self.this_is_the_title = 1\n+        self.literal_whitespace = 0\n+        self.in_parsed_literal = 0\n+        self.compact_list = 0\n+        self.first_param = 0\n+        self.in_desc_signature = False\n+\n+        sphinxpkgoptions = []\n+\n+        # sort out some elements\n+        self.elements = self.builder.context.copy()\n+\n+        # initial section names\n+        self.sectionnames = LATEXSECTIONNAMES[:]\n+        if self.theme.toplevel_sectioning == 'section':\n+            self.sectionnames.remove('chapter')\n+\n+        # determine top section level\n+        self.top_sectionlevel = 1\n+        if self.config.latex_toplevel_sectioning:\n+            try:\n+                self.top_sectionlevel = \\\n+                    self.sectionnames.index(self.config.latex_toplevel_sectioning)\n+            except ValueError:\n+                logger.warning(__('unknown %r toplevel_sectioning for class %r') %\n+                               (self.config.latex_toplevel_sectioning, self.theme.docclass))\n+\n+        if self.config.numfig:\n+            self.numfig_secnum_depth = self.config.numfig_secnum_depth\n+            if self.numfig_secnum_depth > 0:  # default is 1\n+                # numfig_secnum_depth as passed to sphinx.sty indices same names as in\n+                # LATEXSECTIONNAMES but with -1 for part, 0 for chapter, 1 for section...\n+                if len(self.sectionnames) < len(LATEXSECTIONNAMES) and \\\n+                   self.top_sectionlevel > 0:\n+                    self.numfig_secnum_depth += self.top_sectionlevel\n+                else:\n+                    self.numfig_secnum_depth += self.top_sectionlevel - 1\n+                # this (minus one) will serve as minimum to LaTeX's secnumdepth\n+                self.numfig_secnum_depth = min(self.numfig_secnum_depth,\n+                                               len(LATEXSECTIONNAMES) - 1)\n+                # if passed key value is < 1 LaTeX will act as if 0; see sphinx.sty\n+                sphinxpkgoptions.append('numfigreset=%s' % self.numfig_secnum_depth)\n+            else:\n+                sphinxpkgoptions.append('nonumfigreset')\n+\n+        if self.config.numfig and self.config.math_numfig:\n+            sphinxpkgoptions.append('mathnumfig')\n+\n+        if (self.config.language not in {'en', 'ja'} and\n+                'fncychap' not in self.config.latex_elements):\n+            # use Sonny style if any language specified (except English)\n+            self.elements['fncychap'] = (r'\\usepackage[Sonny]{fncychap}' + CR +\n+                                         r'\\ChNameVar{\\Large\\normalfont\\sffamily}' + CR +\n+                                         r'\\ChTitleVar{\\Large\\normalfont\\sffamily}')\n+\n+        self.babel = self.builder.babel\n+        if not self.babel.is_supported_language():\n+            # emit warning if specified language is invalid\n+            # (only emitting, nothing changed to processing)\n+            logger.warning(__('no Babel option known for language %r'),\n+                           self.config.language)\n+\n+        minsecnumdepth = self.secnumdepth  # 2 from legacy sphinx manual/howto\n+        if self.document.get('tocdepth'):\n+            # reduce tocdepth if `part` or `chapter` is used for top_sectionlevel\n+            #   tocdepth = -1: show only parts\n+            #   tocdepth =  0: show parts and chapters\n+            #   tocdepth =  1: show parts, chapters and sections\n+            #   tocdepth =  2: show parts, chapters, sections and subsections\n+            #   ...\n+            tocdepth = self.document.get('tocdepth', 999) + self.top_sectionlevel - 2\n+            if len(self.sectionnames) < len(LATEXSECTIONNAMES) and \\\n+               self.top_sectionlevel > 0:\n+                tocdepth += 1  # because top_sectionlevel is shifted by -1\n+            if tocdepth > len(LATEXSECTIONNAMES) - 2:  # default is 5 <-> subparagraph\n+                logger.warning(__('too large :maxdepth:, ignored.'))\n+                tocdepth = len(LATEXSECTIONNAMES) - 2\n+\n+            self.elements['tocdepth'] = r'\\setcounter{tocdepth}{%d}' % tocdepth\n+            minsecnumdepth = max(minsecnumdepth, tocdepth)\n+\n+        if self.config.numfig and (self.config.numfig_secnum_depth > 0):\n+            minsecnumdepth = max(minsecnumdepth, self.numfig_secnum_depth - 1)\n+\n+        if minsecnumdepth > self.secnumdepth:\n+            self.elements['secnumdepth'] = r'\\setcounter{secnumdepth}{%d}' %\\\n+                                           minsecnumdepth\n+\n+        contentsname = document.get('contentsname')\n+        if contentsname:\n+            self.elements['contentsname'] = self.babel_renewcommand(r'\\contentsname',\n+                                                                    contentsname)\n+\n+        if self.elements['maxlistdepth']:\n+            sphinxpkgoptions.append('maxlistdepth=%s' % self.elements['maxlistdepth'])\n+        if sphinxpkgoptions:\n+            self.elements['sphinxpkgoptions'] = '[,%s]' % ','.join(sphinxpkgoptions)\n+        if self.elements['sphinxsetup']:\n+            self.elements['sphinxsetup'] = (r'\\sphinxsetup{%s}' % self.elements['sphinxsetup'])\n+        if self.elements['extraclassoptions']:\n+            self.elements['classoptions'] += ',' + \\\n+                                             self.elements['extraclassoptions']\n+\n+        self.highlighter = highlighting.PygmentsBridge('latex', self.config.pygments_style,\n+                                                       latex_engine=self.config.latex_engine)\n+        self.context: List[Any] = []\n+        self.descstack: List[str] = []\n+        self.tables: List[Table] = []\n+        self.next_table_colspec: str = None\n+        self.bodystack: List[List[str]] = []\n+        self.footnote_restricted: Element = None\n+        self.pending_footnotes: List[nodes.footnote_reference] = []\n+        self.curfilestack: List[str] = []\n+        self.handled_abbrs: Set[str] = set()\n+\n+    def pushbody(self, newbody: List[str]) -> None:\n+        self.bodystack.append(self.body)\n+        self.body = newbody\n+\n+    def popbody(self) -> List[str]:\n+        body = self.body\n+        self.body = self.bodystack.pop()\n+        return body\n+\n+    def astext(self) -> str:\n+        self.elements.update({\n+            'body': ''.join(self.body),\n+            'indices': self.generate_indices()\n+        })\n+        return self.render('latex.tex_t', self.elements)\n+\n+    def hypertarget(self, id: str, withdoc: bool = True, anchor: bool = True) -> str:\n+        if withdoc:\n+            id = self.curfilestack[-1] + ':' + id\n+        return (r'\\phantomsection' if anchor else '') + r'\\label{%s}' % self.idescape(id)\n+\n+    def hypertarget_to(self, node: Element, anchor: bool = False) -> str:\n+        labels = ''.join(self.hypertarget(node_id, anchor=False) for node_id in node['ids'])\n+        if anchor:\n+            return r'\\phantomsection' + labels\n+        else:\n+            return labels\n+\n+    def hyperlink(self, id: str) -> str:\n+        return r'{\\hyperref[%s]{' % self.idescape(id)\n+\n+    def hyperpageref(self, id: str) -> str:\n+        return r'\\autopageref*{%s}' % self.idescape(id)\n+\n+    def escape(self, s: str) -> str:\n+        return texescape.escape(s, self.config.latex_engine)\n+\n+    def idescape(self, id: str) -> str:\n+        return r'\\detokenize{%s}' % str(id).translate(tex_replace_map).\\\n+            encode('ascii', 'backslashreplace').decode('ascii').\\\n+            replace('\\\\', '_')\n+\n+    def babel_renewcommand(self, command: str, definition: str) -> str:\n+        if self.elements['multilingual']:\n+            prefix = r'\\addto\\captions%s{' % self.babel.get_language()\n+            suffix = '}'\n+        else:  # babel is disabled (mainly for Japanese environment)\n+            prefix = ''\n+            suffix = ''\n+\n+        return r'%s\\renewcommand{%s}{%s}%s' % (prefix, command, definition, suffix) + CR\n+\n+    def generate_indices(self) -> str:\n+        def generate(content: List[Tuple[str, List[IndexEntry]]], collapsed: bool) -> None:\n+            ret.append(r'\\begin{sphinxtheindex}' + CR)\n+            ret.append(r'\\let\\bigletter\\sphinxstyleindexlettergroup' + CR)\n+            for i, (letter, entries) in enumerate(content):\n+                if i > 0:\n+                    ret.append(r'\\indexspace' + CR)\n+                ret.append(r'\\bigletter{%s}' % self.escape(letter) + CR)\n+                for entry in entries:\n+                    if not entry[3]:\n+                        continue\n+                    ret.append(r'\\item\\relax\\sphinxstyleindexentry{%s}' %\n+                               self.encode(entry[0]))\n+                    if entry[4]:\n+                        # add \"extra\" info\n+                        ret.append(r'\\sphinxstyleindexextra{%s}' % self.encode(entry[4]))\n+                    ret.append(r'\\sphinxstyleindexpageref{%s:%s}' %\n+                               (entry[2], self.idescape(entry[3])) + CR)\n+            ret.append(r'\\end{sphinxtheindex}' + CR)\n+\n+        ret = []\n+        # latex_domain_indices can be False/True or a list of index names\n+        indices_config = self.config.latex_domain_indices\n+        if indices_config:\n+            for domain in self.builder.env.domains.values():\n+                for indexcls in domain.indices:\n+                    indexname = '%s-%s' % (domain.name, indexcls.name)\n+                    if isinstance(indices_config, list):\n+                        if indexname not in indices_config:\n+                            continue\n+                    content, collapsed = indexcls(domain).generate(\n+                        self.builder.docnames)\n+                    if not content:\n+                        continue\n+                    ret.append(r'\\renewcommand{\\indexname}{%s}' % indexcls.localname + CR)\n+                    generate(content, collapsed)\n+\n+        return ''.join(ret)\n+\n+    def render(self, template_name: str, variables: Dict) -> str:\n+        renderer = LaTeXRenderer(latex_engine=self.config.latex_engine)\n+        for template_dir in self.config.templates_path:\n+            template = path.join(self.builder.confdir, template_dir,\n+                                 template_name)\n+            if path.exists(template):\n+                return renderer.render(template, variables)\n+\n+        return renderer.render(template_name, variables)\n+\n+    @property\n+    def table(self) -> Table:\n+        \"\"\"Get current table.\"\"\"\n+        if self.tables:\n+            return self.tables[-1]\n+        else:\n+            return None\n+\n+    def visit_document(self, node: Element) -> None:\n+        self.curfilestack.append(node.get('docname', ''))\n+        if self.first_document == 1:\n+            # the first document is all the regular content ...\n+            self.first_document = 0\n+        elif self.first_document == 0:\n+            # ... and all others are the appendices\n+            self.body.append(CR + r'\\appendix' + CR)\n+            self.first_document = -1\n+        if 'docname' in node:\n+            self.body.append(self.hypertarget(':doc'))\n+        # \"- 1\" because the level is increased before the title is visited\n+        self.sectionlevel = self.top_sectionlevel - 1\n+\n+    def depart_document(self, node: Element) -> None:\n+        pass\n+\n+    def visit_start_of_file(self, node: Element) -> None:\n+        self.curfilestack.append(node['docname'])\n+        self.body.append(CR + r'\\sphinxstepscope' + CR)\n+\n+    def depart_start_of_file(self, node: Element) -> None:\n+        self.curfilestack.pop()\n+\n+    def visit_section(self, node: Element) -> None:\n+        if not self.this_is_the_title:\n+            self.sectionlevel += 1\n+        self.body.append(BLANKLINE)\n+\n+    def depart_section(self, node: Element) -> None:\n+        self.sectionlevel = max(self.sectionlevel - 1,\n+                                self.top_sectionlevel - 1)\n+\n+    def visit_problematic(self, node: Element) -> None:\n+        self.body.append(r'{\\color{red}\\bfseries{}')\n+\n+    def depart_problematic(self, node: Element) -> None:\n+        self.body.append('}')\n+\n+    def visit_topic(self, node: Element) -> None:\n+        self.in_minipage = 1\n+        self.body.append(CR + r'\\begin{sphinxShadowBox}' + CR)\n+\n+    def depart_topic(self, node: Element) -> None:\n+        self.in_minipage = 0\n+        self.body.append(r'\\end{sphinxShadowBox}' + CR)\n+    visit_sidebar = visit_topic\n+    depart_sidebar = depart_topic\n+\n+    def visit_glossary(self, node: Element) -> None:\n+        pass\n+\n+    def depart_glossary(self, node: Element) -> None:\n+        pass\n+\n+    def visit_productionlist(self, node: Element) -> None:\n+        self.body.append(BLANKLINE)\n+        self.body.append(r'\\begin{productionlist}' + CR)\n+        self.in_production_list = 1\n+\n+    def depart_productionlist(self, node: Element) -> None:\n+        self.body.append(r'\\end{productionlist}' + BLANKLINE)\n+        self.in_production_list = 0\n+\n+    def visit_production(self, node: Element) -> None:\n+        if node['tokenname']:\n+            tn = node['tokenname']\n+            self.body.append(self.hypertarget('grammar-token-' + tn))\n+            self.body.append(r'\\production{%s}{' % self.encode(tn))\n+        else:\n+            self.body.append(r'\\productioncont{')\n+\n+    def depart_production(self, node: Element) -> None:\n+        self.body.append('}' + CR)\n+\n+    def visit_transition(self, node: Element) -> None:\n+        self.body.append(self.elements['transition'])\n+\n+    def depart_transition(self, node: Element) -> None:\n+        pass\n+\n+    def visit_title(self, node: Element) -> None:\n+        parent = node.parent\n+        if isinstance(parent, addnodes.seealso):\n+            # the environment already handles this\n+            raise nodes.SkipNode\n+        elif isinstance(parent, nodes.section):\n+            if self.this_is_the_title:\n+                if len(node.children) != 1 and not isinstance(node.children[0],\n+                                                              nodes.Text):\n+                    logger.warning(__('document title is not a single Text node'),\n+                                   location=node)\n+                if not self.elements['title']:\n+                    # text needs to be escaped since it is inserted into\n+                    # the output literally\n+                    self.elements['title'] = self.escape(node.astext())\n+                self.this_is_the_title = 0\n+                raise nodes.SkipNode\n+            else:\n+                short = ''\n+                if any(node.findall(nodes.image)):\n+                    short = ('[%s]' % self.escape(' '.join(clean_astext(node).split())))\n+\n+                try:\n+                    self.body.append(r'\\%s%s{' % (self.sectionnames[self.sectionlevel], short))\n+                except IndexError:\n+                    # just use \"subparagraph\", it's not numbered anyway\n+                    self.body.append(r'\\%s%s{' % (self.sectionnames[-1], short))\n+                self.context.append('}' + CR + self.hypertarget_to(node.parent))\n+        elif isinstance(parent, nodes.topic):\n+            self.body.append(r'\\sphinxstyletopictitle{')\n+            self.context.append('}' + CR)\n+        elif isinstance(parent, nodes.sidebar):\n+            self.body.append(r'\\sphinxstylesidebartitle{')\n+            self.context.append('}' + CR)\n+        elif isinstance(parent, nodes.Admonition):\n+            self.body.append('{')\n+            self.context.append('}' + CR)\n+        elif isinstance(parent, nodes.table):\n+            # Redirect body output until title is finished.\n+            self.pushbody([])\n+        else:\n+            logger.warning(__('encountered title node not in section, topic, table, '\n+                              'admonition or sidebar'),\n+                           location=node)\n+            self.body.append(r'\\sphinxstyleothertitle{')\n+            self.context.append('}' + CR)\n+        self.in_title = 1\n+\n+    def depart_title(self, node: Element) -> None:\n+        self.in_title = 0\n+        if isinstance(node.parent, nodes.table):\n+            self.table.caption = self.popbody()\n+        else:\n+            self.body.append(self.context.pop())\n+\n+    def visit_subtitle(self, node: Element) -> None:\n+        if isinstance(node.parent, nodes.sidebar):\n+            self.body.append(r'\\sphinxstylesidebarsubtitle{')\n+            self.context.append('}' + CR)\n+        else:\n+            self.context.append('')\n+\n+    def depart_subtitle(self, node: Element) -> None:\n+        self.body.append(self.context.pop())\n+\n+    #############################################################\n+    # Domain-specific object descriptions\n+    #############################################################\n+\n+    # Top-level nodes for descriptions\n+    ##################################\n+\n+    def visit_desc(self, node: Element) -> None:\n+        if self.config.latex_show_urls == 'footnote':\n+            self.body.append(BLANKLINE)\n+            self.body.append(r'\\begin{savenotes}\\begin{fulllineitems}' + CR)\n+        else:\n+            self.body.append(BLANKLINE)\n+            self.body.append(r'\\begin{fulllineitems}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_desc(self, node: Element) -> None:\n+        if self.in_desc_signature:\n+            self.body.append(CR + r'\\pysigstopsignatures')\n+            self.in_desc_signature = False\n+        if self.config.latex_show_urls == 'footnote':\n+            self.body.append(CR + r'\\end{fulllineitems}\\end{savenotes}' + BLANKLINE)\n+        else:\n+            self.body.append(CR + r'\\end{fulllineitems}' + BLANKLINE)\n+\n+    def _visit_signature_line(self, node: Element) -> None:\n+        for child in node:\n+            if isinstance(child, addnodes.desc_parameterlist):\n+                self.body.append(CR + r'\\pysiglinewithargsret{')\n+                break\n+        else:\n+            self.body.append(CR + r'\\pysigline{')\n+\n+    def _depart_signature_line(self, node: Element) -> None:\n+        self.body.append('}')\n+\n+    def visit_desc_signature(self, node: Element) -> None:\n+        if node.parent['objtype'] != 'describe' and node['ids']:\n+            hyper = self.hypertarget(node['ids'][0])\n+        else:\n+            hyper = ''\n+        self.body.append(hyper)\n+        if not self.in_desc_signature:\n+            self.in_desc_signature = True\n+            self.body.append(CR + r'\\pysigstartsignatures')\n+        if not node.get('is_multiline'):\n+            self._visit_signature_line(node)\n+        else:\n+            self.body.append(CR + r'\\pysigstartmultiline')\n+\n+    def depart_desc_signature(self, node: Element) -> None:\n+        if not node.get('is_multiline'):\n+            self._depart_signature_line(node)\n+        else:\n+            self.body.append(CR + r'\\pysigstopmultiline')\n+\n+    def visit_desc_signature_line(self, node: Element) -> None:\n+        self._visit_signature_line(node)\n+\n+    def depart_desc_signature_line(self, node: Element) -> None:\n+        self._depart_signature_line(node)\n+\n+    def visit_desc_content(self, node: Element) -> None:\n+        assert self.in_desc_signature\n+        self.body.append(CR + r'\\pysigstopsignatures')\n+        self.in_desc_signature = False\n+\n+    def depart_desc_content(self, node: Element) -> None:\n+        pass\n+\n+    def visit_desc_inline(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n+\n+    def depart_desc_inline(self, node: Element) -> None:\n+        self.body.append('%}}')\n+\n+    # Nodes for high-level structure in signatures\n+    ##############################################\n+\n+    def visit_desc_name(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxbfcode{\\sphinxupquote{')\n+        self.literal_whitespace += 1\n+\n+    def depart_desc_name(self, node: Element) -> None:\n+        self.body.append('}}')\n+        self.literal_whitespace -= 1\n+\n+    def visit_desc_addname(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n+        self.literal_whitespace += 1\n+\n+    def depart_desc_addname(self, node: Element) -> None:\n+        self.body.append('}}')\n+        self.literal_whitespace -= 1\n+\n+    def visit_desc_type(self, node: Element) -> None:\n+        pass\n+\n+    def depart_desc_type(self, node: Element) -> None:\n+        pass\n+\n+    def visit_desc_returns(self, node: Element) -> None:\n+        self.body.append(r'{ $\\rightarrow$ ')\n+\n+    def depart_desc_returns(self, node: Element) -> None:\n+        self.body.append(r'}')\n+\n+    def visit_desc_parameterlist(self, node: Element) -> None:\n+        # close name, open parameterlist\n+        self.body.append('}{')\n+        self.first_param = 1\n+\n+    def depart_desc_parameterlist(self, node: Element) -> None:\n+        # close parameterlist, open return annotation\n+        self.body.append('}{')\n+\n+    def visit_desc_parameter(self, node: Element) -> None:\n+        if not self.first_param:\n+            self.body.append(', ')\n+        else:\n+            self.first_param = 0\n+        if not node.hasattr('noemph'):\n+            self.body.append(r'\\emph{')\n+\n+    def depart_desc_parameter(self, node: Element) -> None:\n+        if not node.hasattr('noemph'):\n+            self.body.append('}')\n+\n+    def visit_desc_optional(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxoptional{')\n+\n+    def depart_desc_optional(self, node: Element) -> None:\n+        self.body.append('}')\n+\n+    def visit_desc_annotation(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxbfcode{\\sphinxupquote{')\n+\n+    def depart_desc_annotation(self, node: Element) -> None:\n+        self.body.append('}}')\n+\n+    ##############################################\n+\n+    def visit_seealso(self, node: Element) -> None:\n+        self.body.append(BLANKLINE)\n+        self.body.append(r'\\sphinxstrong{%s:}' % admonitionlabels['seealso'] + CR)\n+        self.body.append(r'\\nopagebreak' + BLANKLINE)\n+\n+    def depart_seealso(self, node: Element) -> None:\n+        self.body.append(BLANKLINE)\n+\n+    def visit_rubric(self, node: Element) -> None:\n+        if len(node) == 1 and node.astext() in ('Footnotes', _('Footnotes')):\n+            raise nodes.SkipNode\n+        self.body.append(r'\\subsubsection*{')\n+        self.context.append('}' + CR)\n+        self.in_title = 1\n+\n+    def depart_rubric(self, node: Element) -> None:\n+        self.in_title = 0\n+        self.body.append(self.context.pop())\n+\n+    def visit_footnote(self, node: Element) -> None:\n+        self.in_footnote += 1\n+        label = cast(nodes.label, node[0])\n+        if self.in_parsed_literal:\n+            self.body.append(r'\\begin{footnote}[%s]' % label.astext())\n+        else:\n+            self.body.append('%' + CR)\n+            self.body.append(r'\\begin{footnote}[%s]' % label.astext())\n+        if 'referred' in node:\n+            # TODO: in future maybe output a latex macro with backrefs here\n+            pass\n+        self.body.append(r'\\sphinxAtStartFootnote' + CR)\n+\n+    def depart_footnote(self, node: Element) -> None:\n+        if self.in_parsed_literal:\n+            self.body.append(r'\\end{footnote}')\n+        else:\n+            self.body.append('%' + CR)\n+            self.body.append(r'\\end{footnote}')\n+        self.in_footnote -= 1\n+\n+    def visit_label(self, node: Element) -> None:\n+        raise nodes.SkipNode\n+\n+    def visit_tabular_col_spec(self, node: Element) -> None:\n+        self.next_table_colspec = node['spec']\n+        raise nodes.SkipNode\n+\n+    def visit_table(self, node: Element) -> None:\n+        if len(self.tables) == 1:\n+            if self.table.get_table_type() == 'longtable':\n+                raise UnsupportedError(\n+                    '%s:%s: longtable does not support nesting a table.' %\n+                    (self.curfilestack[-1], node.line or ''))\n+            else:\n+                # change type of parent table to tabular\n+                # see https://groups.google.com/d/msg/sphinx-users/7m3NeOBixeo/9LKP2B4WBQAJ\n+                self.table.has_problematic = True\n+        elif len(self.tables) > 2:\n+            raise UnsupportedError(\n+                '%s:%s: deeply nested tables are not implemented.' %\n+                (self.curfilestack[-1], node.line or ''))\n+\n+        self.tables.append(Table(node))\n+        if self.next_table_colspec:\n+            self.table.colspec = '{%s}' % self.next_table_colspec + CR\n+            if 'colwidths-given' in node.get('classes', []):\n+                logger.info(__('both tabularcolumns and :widths: option are given. '\n+                               ':widths: is ignored.'), location=node)\n+        self.next_table_colspec = None\n+\n+    def depart_table(self, node: Element) -> None:\n+        labels = self.hypertarget_to(node)\n+        table_type = self.table.get_table_type()\n+        table = self.render(table_type + '.tex_t',\n+                            dict(table=self.table, labels=labels))\n+        self.body.append(BLANKLINE)\n+        self.body.append(table)\n+        self.body.append(CR)\n+\n+        self.tables.pop()\n+\n+    def visit_colspec(self, node: Element) -> None:\n+        self.table.colcount += 1\n+        if 'colwidth' in node:\n+            self.table.colwidths.append(node['colwidth'])\n+        if 'stub' in node:\n+            self.table.stubs.append(self.table.colcount - 1)\n+\n+    def depart_colspec(self, node: Element) -> None:\n+        pass\n+\n+    def visit_tgroup(self, node: Element) -> None:\n+        pass\n+\n+    def depart_tgroup(self, node: Element) -> None:\n+        pass\n+\n+    def visit_thead(self, node: Element) -> None:\n+        # Redirect head output until header is finished.\n+        self.pushbody(self.table.header)\n+\n+    def depart_thead(self, node: Element) -> None:\n+        self.popbody()\n+\n+    def visit_tbody(self, node: Element) -> None:\n+        # Redirect body output until table is finished.\n+        self.pushbody(self.table.body)\n+\n+    def depart_tbody(self, node: Element) -> None:\n+        self.popbody()\n+\n+    def visit_row(self, node: Element) -> None:\n+        self.table.col = 0\n+\n+        # fill columns if the row starts with the bottom of multirow cell\n+        while True:\n+            cell = self.table.cell(self.table.row, self.table.col)\n+            if cell is None:  # not a bottom of multirow cell\n+                break\n+            else:  # a bottom of multirow cell\n+                self.table.col += cell.width\n+                if cell.col:\n+                    self.body.append('&')\n+                if cell.width == 1:\n+                    # insert suitable strut for equalizing row heights in given multirow\n+                    self.body.append(r'\\sphinxtablestrut{%d}' % cell.cell_id)\n+                else:  # use \\multicolumn for wide multirow cell\n+                    self.body.append(r'\\multicolumn{%d}{|l|}{\\sphinxtablestrut{%d}}' %\n+                                     (cell.width, cell.cell_id))\n+\n+    def depart_row(self, node: Element) -> None:\n+        self.body.append(r'\\\\' + CR)\n+        cells = [self.table.cell(self.table.row, i) for i in range(self.table.colcount)]\n+        underlined = [cell.row + cell.height == self.table.row + 1 for cell in cells]\n+        if all(underlined):\n+            self.body.append(r'\\hline')\n+        else:\n+            i = 0\n+            underlined.extend([False])  # sentinel\n+            while i < len(underlined):\n+                if underlined[i] is True:\n+                    j = underlined[i:].index(False)\n+                    self.body.append(r'\\cline{%d-%d}' % (i + 1, i + j))\n+                    i += j\n+                i += 1\n+        self.table.row += 1\n+\n+    def visit_entry(self, node: Element) -> None:\n+        if self.table.col > 0:\n+            self.body.append('&')\n+        self.table.add_cell(node.get('morerows', 0) + 1, node.get('morecols', 0) + 1)\n+        cell = self.table.cell()\n+        context = ''\n+        if cell.width > 1:\n+            if self.config.latex_use_latex_multicolumn:\n+                if self.table.col == 0:\n+                    self.body.append(r'\\multicolumn{%d}{|l|}{%%' % cell.width + CR)\n+                else:\n+                    self.body.append(r'\\multicolumn{%d}{l|}{%%' % cell.width + CR)\n+                context = '}%' + CR\n+            else:\n+                self.body.append(r'\\sphinxstartmulticolumn{%d}%%' % cell.width + CR)\n+                context = r'\\sphinxstopmulticolumn' + CR\n+        if cell.height > 1:\n+            # \\sphinxmultirow 2nd arg \"cell_id\" will serve as id for LaTeX macros as well\n+            self.body.append(r'\\sphinxmultirow{%d}{%d}{%%' % (cell.height, cell.cell_id) + CR)\n+            context = '}%' + CR + context\n+        if cell.width > 1 or cell.height > 1:\n+            self.body.append(r'\\begin{varwidth}[t]{\\sphinxcolwidth{%d}{%d}}'\n+                             % (cell.width, self.table.colcount) + CR)\n+            context = (r'\\par' + CR + r'\\vskip-\\baselineskip'\n+                       r'\\vbox{\\hbox{\\strut}}\\end{varwidth}%' + CR + context)\n+            self.needs_linetrimming = 1\n+        if len(list(node.findall(nodes.paragraph))) >= 2:\n+            self.table.has_oldproblematic = True\n+        if isinstance(node.parent.parent, nodes.thead) or (cell.col in self.table.stubs):\n+            if len(node) == 1 and isinstance(node[0], nodes.paragraph) and node.astext() == '':\n+                pass\n+            else:\n+                self.body.append(r'\\sphinxstyletheadfamily ')\n+        if self.needs_linetrimming:\n+            self.pushbody([])\n+        self.context.append(context)\n+\n+    def depart_entry(self, node: Element) -> None:\n+        if self.needs_linetrimming:\n+            self.needs_linetrimming = 0\n+            body = self.popbody()\n+\n+            # Remove empty lines from top of merged cell\n+            while body and body[0] == CR:\n+                body.pop(0)\n+            self.body.extend(body)\n+\n+        self.body.append(self.context.pop())\n+\n+        cell = self.table.cell()\n+        self.table.col += cell.width\n+\n+        # fill columns if next ones are a bottom of wide-multirow cell\n+        while True:\n+            nextcell = self.table.cell()\n+            if nextcell is None:  # not a bottom of multirow cell\n+                break\n+            else:  # a bottom part of multirow cell\n+                self.table.col += nextcell.width\n+                self.body.append('&')\n+                if nextcell.width == 1:\n+                    # insert suitable strut for equalizing row heights in multirow\n+                    # they also serve to clear colour panels which would hide the text\n+                    self.body.append(r'\\sphinxtablestrut{%d}' % nextcell.cell_id)\n+                else:\n+                    # use \\multicolumn for wide multirow cell\n+                    self.body.append(r'\\multicolumn{%d}{l|}{\\sphinxtablestrut{%d}}' %\n+                                     (nextcell.width, nextcell.cell_id))\n+\n+    def visit_acks(self, node: Element) -> None:\n+        # this is a list in the source, but should be rendered as a\n+        # comma-separated list here\n+        bullet_list = cast(nodes.bullet_list, node[0])\n+        list_items = cast(Iterable[nodes.list_item], bullet_list)\n+        self.body.append(BLANKLINE)\n+        self.body.append(', '.join(n.astext() for n in list_items) + '.')\n+        self.body.append(BLANKLINE)\n+        raise nodes.SkipNode\n+\n+    def visit_bullet_list(self, node: Element) -> None:\n+        if not self.compact_list:\n+            self.body.append(r'\\begin{itemize}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_bullet_list(self, node: Element) -> None:\n+        if not self.compact_list:\n+            self.body.append(r'\\end{itemize}' + CR)\n+\n+    def visit_enumerated_list(self, node: Element) -> None:\n+        def get_enumtype(node: Element) -> str:\n+            enumtype = node.get('enumtype', 'arabic')\n+            if 'alpha' in enumtype and 26 < node.get('start', 0) + len(node):\n+                # fallback to arabic if alphabet counter overflows\n+                enumtype = 'arabic'\n+\n+            return enumtype\n+\n+        def get_nested_level(node: Element) -> int:\n+            if node is None:\n+                return 0\n+            elif isinstance(node, nodes.enumerated_list):\n+                return get_nested_level(node.parent) + 1\n+            else:\n+                return get_nested_level(node.parent)\n+\n+        enum = \"enum%s\" % toRoman(get_nested_level(node)).lower()\n+        enumnext = \"enum%s\" % toRoman(get_nested_level(node) + 1).lower()\n+        style = ENUMERATE_LIST_STYLE.get(get_enumtype(node))\n+        prefix = node.get('prefix', '')\n+        suffix = node.get('suffix', '.')\n+\n+        self.body.append(r'\\begin{enumerate}' + CR)\n+        self.body.append(r'\\sphinxsetlistlabels{%s}{%s}{%s}{%s}{%s}%%' %\n+                         (style, enum, enumnext, prefix, suffix) + CR)\n+        if 'start' in node:\n+            self.body.append(r'\\setcounter{%s}{%d}' % (enum, node['start'] - 1) + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_enumerated_list(self, node: Element) -> None:\n+        self.body.append(r'\\end{enumerate}' + CR)\n+\n+    def visit_list_item(self, node: Element) -> None:\n+        # Append \"{}\" in case the next character is \"[\", which would break\n+        # LaTeX's list environment (no numbering and the \"[\" is not printed).\n+        self.body.append(r'\\item {} ')\n+\n+    def depart_list_item(self, node: Element) -> None:\n+        self.body.append(CR)\n+\n+    def visit_definition_list(self, node: Element) -> None:\n+        self.body.append(r'\\begin{description}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_definition_list(self, node: Element) -> None:\n+        self.body.append(r'\\end{description}' + CR)\n+\n+    def visit_definition_list_item(self, node: Element) -> None:\n+        pass\n+\n+    def depart_definition_list_item(self, node: Element) -> None:\n+        pass\n+\n+    def visit_term(self, node: Element) -> None:\n+        self.in_term += 1\n+        ctx = ''\n+        if node.get('ids'):\n+            ctx = r'\\phantomsection'\n+            for node_id in node['ids']:\n+                ctx += self.hypertarget(node_id, anchor=False)\n+        ctx += r'}'\n+        self.body.append(r'\\sphinxlineitem{')\n+        self.context.append(ctx)\n+\n+    def depart_term(self, node: Element) -> None:\n+        self.body.append(self.context.pop())\n+        self.in_term -= 1\n+\n+    def visit_classifier(self, node: Element) -> None:\n+        self.body.append('{[}')\n+\n+    def depart_classifier(self, node: Element) -> None:\n+        self.body.append('{]}')\n+\n+    def visit_definition(self, node: Element) -> None:\n+        pass\n+\n+    def depart_definition(self, node: Element) -> None:\n+        self.body.append(CR)\n+\n+    def visit_field_list(self, node: Element) -> None:\n+        self.body.append(r'\\begin{quote}\\begin{description}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_field_list(self, node: Element) -> None:\n+        self.body.append(r'\\end{description}\\end{quote}' + CR)\n+\n+    def visit_field(self, node: Element) -> None:\n+        pass\n+\n+    def depart_field(self, node: Element) -> None:\n+        pass\n+\n+    visit_field_name = visit_term\n+    depart_field_name = depart_term\n+\n+    visit_field_body = visit_definition\n+    depart_field_body = depart_definition\n+\n+    def visit_paragraph(self, node: Element) -> None:\n+        index = node.parent.index(node)\n+        if (index > 0 and isinstance(node.parent, nodes.compound) and\n+                not isinstance(node.parent[index - 1], nodes.paragraph) and\n+                not isinstance(node.parent[index - 1], nodes.compound)):\n+            # insert blank line, if the paragraph follows a non-paragraph node in a compound\n+            self.body.append(r'\\noindent' + CR)\n+        elif index == 1 and isinstance(node.parent, (nodes.footnote, footnotetext)):\n+            # don't insert blank line, if the paragraph is second child of a footnote\n+            # (first one is label node)\n+            pass\n+        else:\n+            # the \\sphinxAtStartPar is to allow hyphenation of first word of\n+            # a paragraph in narrow contexts such as in a table cell\n+            # added as two items (cf. line trimming in depart_entry())\n+            self.body.extend([CR, r'\\sphinxAtStartPar' + CR])\n+\n+    def depart_paragraph(self, node: Element) -> None:\n+        self.body.append(CR)\n+\n+    def visit_centered(self, node: Element) -> None:\n+        self.body.append(CR + r'\\begin{center}')\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_centered(self, node: Element) -> None:\n+        self.body.append(CR + r'\\end{center}')\n+\n+    def visit_hlist(self, node: Element) -> None:\n+        self.compact_list += 1\n+        ncolumns = node['ncolumns']\n+        if self.compact_list > 1:\n+            self.body.append(r'\\setlength{\\multicolsep}{0pt}' + CR)\n+        self.body.append(r'\\begin{multicols}{' + ncolumns + r'}\\raggedright' + CR)\n+        self.body.append(r'\\begin{itemize}\\setlength{\\itemsep}{0pt}'\n+                         r'\\setlength{\\parskip}{0pt}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_hlist(self, node: Element) -> None:\n+        self.compact_list -= 1\n+        self.body.append(r'\\end{itemize}\\raggedcolumns\\end{multicols}' + CR)\n+\n+    def visit_hlistcol(self, node: Element) -> None:\n+        pass\n+\n+    def depart_hlistcol(self, node: Element) -> None:\n+        # \\columnbreak would guarantee same columns as in html output.  But\n+        # some testing with long items showed that columns may be too uneven.\n+        # And in case only of short items, the automatic column breaks should\n+        # match the ones pre-computed by the hlist() directive.\n+        # self.body.append(r'\\columnbreak\\n')\n+        pass\n+\n+    def latex_image_length(self, width_str: str, scale: int = 100) -> str:\n+        try:\n+            return rstdim_to_latexdim(width_str, scale)\n+        except ValueError:\n+            logger.warning(__('dimension unit %s is invalid. Ignored.'), width_str)\n+            return None\n+\n+    def is_inline(self, node: Element) -> bool:\n+        \"\"\"Check whether a node represents an inline element.\"\"\"\n+        return isinstance(node.parent, nodes.TextElement)\n+\n+    def visit_image(self, node: Element) -> None:\n+        pre: List[str] = []  # in reverse order\n+        post: List[str] = []\n+        include_graphics_options = []\n+        has_hyperlink = isinstance(node.parent, nodes.reference)\n+        if has_hyperlink:\n+            is_inline = self.is_inline(node.parent)\n+        else:\n+            is_inline = self.is_inline(node)\n+        if 'width' in node:\n+            if 'scale' in node:\n+                w = self.latex_image_length(node['width'], node['scale'])\n+            else:\n+                w = self.latex_image_length(node['width'])\n+            if w:\n+                include_graphics_options.append('width=%s' % w)\n+        if 'height' in node:\n+            if 'scale' in node:\n+                h = self.latex_image_length(node['height'], node['scale'])\n+            else:\n+                h = self.latex_image_length(node['height'])\n+            if h:\n+                include_graphics_options.append('height=%s' % h)\n+        if 'scale' in node:\n+            if not include_graphics_options:\n+                # if no \"width\" nor \"height\", \\sphinxincludegraphics will fit\n+                # to the available text width if oversized after rescaling.\n+                include_graphics_options.append('scale=%s'\n+                                                % (float(node['scale']) / 100.0))\n+        if 'align' in node:\n+            align_prepost = {\n+                # By default latex aligns the top of an image.\n+                (1, 'top'): ('', ''),\n+                (1, 'middle'): (r'\\raisebox{-0.5\\height}{', '}'),\n+                (1, 'bottom'): (r'\\raisebox{-\\height}{', '}'),\n+                (0, 'center'): (r'{\\hspace*{\\fill}', r'\\hspace*{\\fill}}'),\n+                # These 2 don't exactly do the right thing.  The image should\n+                # be floated alongside the paragraph.  See\n+                # https://www.w3.org/TR/html4/struct/objects.html#adef-align-IMG\n+                (0, 'left'): ('{', r'\\hspace*{\\fill}}'),\n+                (0, 'right'): (r'{\\hspace*{\\fill}', '}'),\n+            }\n+            try:\n+                pre.append(align_prepost[is_inline, node['align']][0])\n+                post.append(align_prepost[is_inline, node['align']][1])\n+            except KeyError:\n+                pass\n+        if self.in_parsed_literal:\n+            pre.append(r'{\\sphinxunactivateextrasandspace ')\n+            post.append('}')\n+        if not is_inline and not has_hyperlink:\n+            pre.append(CR + r'\\noindent')\n+            post.append(CR)\n+        pre.reverse()\n+        if node['uri'] in self.builder.images:\n+            uri = self.builder.images[node['uri']]\n+        else:\n+            # missing image!\n+            if self.ignore_missing_images:\n+                return\n+            uri = node['uri']\n+        if uri.find('://') != -1:\n+            # ignore remote images\n+            return\n+        self.body.extend(pre)\n+        options = ''\n+        if include_graphics_options:\n+            options = '[%s]' % ','.join(include_graphics_options)\n+        base, ext = path.splitext(uri)\n+        if self.in_title and base:\n+            # Lowercase tokens forcely because some fncychap themes capitalize\n+            # the options of \\sphinxincludegraphics unexpectedly (ex. WIDTH=...).\n+            self.body.append(r'\\lowercase{\\sphinxincludegraphics%s}{{%s}%s}' %\n+                             (options, base, ext))\n+        else:\n+            self.body.append(r'\\sphinxincludegraphics%s{{%s}%s}' %\n+                             (options, base, ext))\n+        self.body.extend(post)\n+\n+    def depart_image(self, node: Element) -> None:\n+        pass\n+\n+    def visit_figure(self, node: Element) -> None:\n+        align = self.elements['figure_align']\n+        if self.no_latex_floats:\n+            align = \"H\"\n+        if self.table:\n+            # TODO: support align option\n+            if 'width' in node:\n+                length = self.latex_image_length(node['width'])\n+                if length:\n+                    self.body.append(r'\\begin{sphinxfigure-in-table}[%s]' % length + CR)\n+                    self.body.append(r'\\centering' + CR)\n+            else:\n+                self.body.append(r'\\begin{sphinxfigure-in-table}' + CR)\n+                self.body.append(r'\\centering' + CR)\n+            if any(isinstance(child, nodes.caption) for child in node):\n+                self.body.append(r'\\capstart')\n+            self.context.append(r'\\end{sphinxfigure-in-table}\\relax' + CR)\n+        elif node.get('align', '') in ('left', 'right'):\n+            length = None\n+            if 'width' in node:\n+                length = self.latex_image_length(node['width'])\n+            elif isinstance(node[0], nodes.image) and 'width' in node[0]:\n+                length = self.latex_image_length(node[0]['width'])\n+            self.body.append(BLANKLINE)     # Insert a blank line to prevent infinite loop\n+                                            # https://github.com/sphinx-doc/sphinx/issues/7059\n+            self.body.append(r'\\begin{wrapfigure}{%s}{%s}' %\n+                             ('r' if node['align'] == 'right' else 'l', length or '0pt') + CR)\n+            self.body.append(r'\\centering')\n+            self.context.append(r'\\end{wrapfigure}' + CR)\n+        elif self.in_minipage:\n+            self.body.append(CR + r'\\begin{center}')\n+            self.context.append(r'\\end{center}' + CR)\n+        else:\n+            self.body.append(CR + r'\\begin{figure}[%s]' % align + CR)\n+            self.body.append(r'\\centering' + CR)\n+            if any(isinstance(child, nodes.caption) for child in node):\n+                self.body.append(r'\\capstart' + CR)\n+            self.context.append(r'\\end{figure}' + CR)\n+\n+    def depart_figure(self, node: Element) -> None:\n+        self.body.append(self.context.pop())\n+\n+    def visit_caption(self, node: Element) -> None:\n+        self.in_caption += 1\n+        if isinstance(node.parent, captioned_literal_block):\n+            self.body.append(r'\\sphinxSetupCaptionForVerbatim{')\n+        elif self.in_minipage and isinstance(node.parent, nodes.figure):\n+            self.body.append(r'\\captionof{figure}{')\n+        elif self.table and node.parent.tagname == 'figure':\n+            self.body.append(r'\\sphinxfigcaption{')\n+        else:\n+            self.body.append(r'\\caption{')\n+\n+    def depart_caption(self, node: Element) -> None:\n+        self.body.append('}')\n+        if isinstance(node.parent, nodes.figure):\n+            labels = self.hypertarget_to(node.parent)\n+            self.body.append(labels)\n+        self.in_caption -= 1\n+\n+    def visit_legend(self, node: Element) -> None:\n+        self.body.append(CR + r'\\begin{sphinxlegend}')\n+\n+    def depart_legend(self, node: Element) -> None:\n+        self.body.append(r'\\end{sphinxlegend}' + CR)\n+\n+    def visit_admonition(self, node: Element) -> None:\n+        self.body.append(CR + r'\\begin{sphinxadmonition}{note}')\n+        self.no_latex_floats += 1\n+\n+    def depart_admonition(self, node: Element) -> None:\n+        self.body.append(r'\\end{sphinxadmonition}' + CR)\n+        self.no_latex_floats -= 1\n+\n+    def _visit_named_admonition(self, node: Element) -> None:\n+        label = admonitionlabels[node.tagname]\n+        self.body.append(CR + r'\\begin{sphinxadmonition}{%s}{%s:}' %\n+                         (node.tagname, label))\n+        self.no_latex_floats += 1\n+\n+    def _depart_named_admonition(self, node: Element) -> None:\n+        self.body.append(r'\\end{sphinxadmonition}' + CR)\n+        self.no_latex_floats -= 1\n+\n+    visit_attention = _visit_named_admonition\n+    depart_attention = _depart_named_admonition\n+    visit_caution = _visit_named_admonition\n+    depart_caution = _depart_named_admonition\n+    visit_danger = _visit_named_admonition\n+    depart_danger = _depart_named_admonition\n+    visit_error = _visit_named_admonition\n+    depart_error = _depart_named_admonition\n+    visit_hint = _visit_named_admonition\n+    depart_hint = _depart_named_admonition\n+    visit_important = _visit_named_admonition\n+    depart_important = _depart_named_admonition\n+    visit_note = _visit_named_admonition\n+    depart_note = _depart_named_admonition\n+    visit_tip = _visit_named_admonition\n+    depart_tip = _depart_named_admonition\n+    visit_warning = _visit_named_admonition\n+    depart_warning = _depart_named_admonition\n+\n+    def visit_versionmodified(self, node: Element) -> None:\n+        pass\n+\n+    def depart_versionmodified(self, node: Element) -> None:\n+        pass\n+\n+    def visit_target(self, node: Element) -> None:\n+        def add_target(id: str) -> None:\n+            # indexing uses standard LaTeX index markup, so the targets\n+            # will be generated differently\n+            if id.startswith('index-'):\n+                return\n+\n+            # equations also need no extra blank line nor hypertarget\n+            # TODO: fix this dependency on mathbase extension internals\n+            if id.startswith('equation-'):\n+                return\n+\n+            # insert blank line, if the target follows a paragraph node\n+            index = node.parent.index(node)\n+            if index > 0 and isinstance(node.parent[index - 1], nodes.paragraph):\n+                self.body.append(CR)\n+\n+            # do not generate \\phantomsection in \\section{}\n+            anchor = not self.in_title\n+            self.body.append(self.hypertarget(id, anchor=anchor))\n+\n+        # skip if visitor for next node supports hyperlink\n+        next_node: Node = node\n+        while isinstance(next_node, nodes.target):\n+            next_node = next_node.next_node(ascend=True)\n+\n+        domain = cast(StandardDomain, self.builder.env.get_domain('std'))\n+        if isinstance(next_node, HYPERLINK_SUPPORT_NODES):\n+            return\n+        elif domain.get_enumerable_node_type(next_node) and domain.get_numfig_title(next_node):\n+            return\n+\n+        if 'refuri' in node:\n+            return\n+        if 'anonymous' in node:\n+            return\n+        if node.get('refid'):\n+            prev_node = get_prev_node(node)\n+            if isinstance(prev_node, nodes.reference) and node['refid'] == prev_node['refid']:\n+                # a target for a hyperlink reference having alias\n+                pass\n+            else:\n+                add_target(node['refid'])\n+        for id in node['ids']:\n+            add_target(id)\n+\n+    def depart_target(self, node: Element) -> None:\n+        pass\n+\n+    def visit_attribution(self, node: Element) -> None:\n+        self.body.append(CR + r'\\begin{flushright}' + CR)\n+        self.body.append('---')\n+\n+    def depart_attribution(self, node: Element) -> None:\n+        self.body.append(CR + r'\\end{flushright}' + CR)\n+\n+    def visit_index(self, node: Element) -> None:\n+        def escape(value: str) -> str:\n+            value = self.encode(value)\n+            value = value.replace(r'\\{', r'\\sphinxleftcurlybrace{}')\n+            value = value.replace(r'\\}', r'\\sphinxrightcurlybrace{}')\n+            value = value.replace('\"', '\"\"')\n+            value = value.replace('@', '\"@')\n+            value = value.replace('!', '\"!')\n+            value = value.replace('|', r'\\textbar{}')\n+            return value\n+\n+        def style(string: str) -> str:\n+            match = EXTRA_RE.match(string)\n+            if match:\n+                return match.expand(r'\\\\spxentry{\\1}\\\\spxextra{\\2}')\n+            else:\n+                return r'\\spxentry{%s}' % string\n+\n+        if not node.get('inline', True):\n+            self.body.append(CR)\n+        entries = node['entries']\n+        for type, string, _tid, ismain, _key in entries:\n+            m = ''\n+            if ismain:\n+                m = '|spxpagem'\n+            try:\n+                if type == 'single':\n+                    try:\n+                        p1, p2 = [escape(x) for x in split_into(2, 'single', string)]\n+                        P1, P2 = style(p1), style(p2)\n+                        self.body.append(r'\\index{%s@%s!%s@%s%s}' % (p1, P1, p2, P2, m))\n+                    except ValueError:\n+                        p = escape(split_into(1, 'single', string)[0])\n+                        P = style(p)\n+                        self.body.append(r'\\index{%s@%s%s}' % (p, P, m))\n+                elif type == 'pair':\n+                    p1, p2 = [escape(x) for x in split_into(2, 'pair', string)]\n+                    P1, P2 = style(p1), style(p2)\n+                    self.body.append(r'\\index{%s@%s!%s@%s%s}\\index{%s@%s!%s@%s%s}' %\n+                                     (p1, P1, p2, P2, m, p2, P2, p1, P1, m))\n+                elif type == 'triple':\n+                    p1, p2, p3 = [escape(x) for x in split_into(3, 'triple', string)]\n+                    P1, P2, P3 = style(p1), style(p2), style(p3)\n+                    self.body.append(\n+                        r'\\index{%s@%s!%s %s@%s %s%s}'\n+                        r'\\index{%s@%s!%s, %s@%s, %s%s}'\n+                        r'\\index{%s@%s!%s %s@%s %s%s}' %\n+                        (p1, P1, p2, p3, P2, P3, m,\n+                         p2, P2, p3, p1, P3, P1, m,\n+                         p3, P3, p1, p2, P1, P2, m))\n+                elif type == 'see':\n+                    p1, p2 = [escape(x) for x in split_into(2, 'see', string)]\n+                    P1 = style(p1)\n+                    self.body.append(r'\\index{%s@%s|see{%s}}' % (p1, P1, p2))\n+                elif type == 'seealso':\n+                    p1, p2 = [escape(x) for x in split_into(2, 'seealso', string)]\n+                    P1 = style(p1)\n+                    self.body.append(r'\\index{%s@%s|see{%s}}' % (p1, P1, p2))\n+                else:\n+                    logger.warning(__('unknown index entry type %s found'), type)\n+            except ValueError as err:\n+                logger.warning(str(err))\n+        if not node.get('inline', True):\n+            self.body.append(r'\\ignorespaces ')\n+        raise nodes.SkipNode\n+\n+    def visit_raw(self, node: Element) -> None:\n+        if not self.is_inline(node):\n+            self.body.append(CR)\n+        if 'latex' in node.get('format', '').split():\n+            self.body.append(node.astext())\n+        if not self.is_inline(node):\n+            self.body.append(CR)\n+        raise nodes.SkipNode\n+\n+    def visit_reference(self, node: Element) -> None:\n+        if not self.in_title:\n+            for id in node.get('ids'):\n+                anchor = not self.in_caption\n+                self.body += self.hypertarget(id, anchor=anchor)\n+        if not self.is_inline(node):\n+            self.body.append(CR)\n+        uri = node.get('refuri', '')\n+        if not uri and node.get('refid'):\n+            uri = '%' + self.curfilestack[-1] + '#' + node['refid']\n+        if self.in_title or not uri:\n+            self.context.append('')\n+        elif uri.startswith('#'):\n+            # references to labels in the same document\n+            id = self.curfilestack[-1] + ':' + uri[1:]\n+            self.body.append(self.hyperlink(id))\n+            self.body.append(r'\\emph{')\n+            if self.config.latex_show_pagerefs and not \\\n+                    self.in_production_list:\n+                self.context.append('}}} (%s)' % self.hyperpageref(id))\n+            else:\n+                self.context.append('}}}')\n+        elif uri.startswith('%'):\n+            # references to documents or labels inside documents\n+            hashindex = uri.find('#')\n+            if hashindex == -1:\n+                # reference to the document\n+                id = uri[1:] + '::doc'\n+            else:\n+                # reference to a label\n+                id = uri[1:].replace('#', ':')\n+            self.body.append(self.hyperlink(id))\n+            if (len(node) and\n+                    isinstance(node[0], nodes.Element) and\n+                    'std-term' in node[0].get('classes', [])):\n+                # don't add a pageref for glossary terms\n+                self.context.append('}}}')\n+                # mark up as termreference\n+                self.body.append(r'\\sphinxtermref{')\n+            else:\n+                self.body.append(r'\\sphinxcrossref{')\n+                if self.config.latex_show_pagerefs and not self.in_production_list:\n+                    self.context.append('}}} (%s)' % self.hyperpageref(id))\n+                else:\n+                    self.context.append('}}}')\n+        else:\n+            if len(node) == 1 and uri == node[0]:\n+                if node.get('nolinkurl'):\n+                    self.body.append(r'\\sphinxnolinkurl{%s}' % self.encode_uri(uri))\n+                else:\n+                    self.body.append(r'\\sphinxurl{%s}' % self.encode_uri(uri))\n+                raise nodes.SkipNode\n+            else:\n+                self.body.append(r'\\sphinxhref{%s}{' % self.encode_uri(uri))\n+                self.context.append('}')\n+\n+    def depart_reference(self, node: Element) -> None:\n+        self.body.append(self.context.pop())\n+        if not self.is_inline(node):\n+            self.body.append(CR)\n+\n+    def visit_number_reference(self, node: Element) -> None:\n+        if node.get('refid'):\n+            id = self.curfilestack[-1] + ':' + node['refid']\n+        else:\n+            id = node.get('refuri', '')[1:].replace('#', ':')\n+\n+        title = self.escape(node.get('title', '%s')).replace(r'\\%s', '%s')\n+        if r'\\{name\\}' in title or r'\\{number\\}' in title:\n+            # new style format (cf. \"Fig.%{number}\")\n+            title = title.replace(r'\\{name\\}', '{name}').replace(r'\\{number\\}', '{number}')\n+            text = escape_abbr(title).format(name=r'\\nameref{%s}' % self.idescape(id),\n+                                             number=r'\\ref{%s}' % self.idescape(id))\n+        else:\n+            # old style format (cf. \"Fig.%{number}\")\n+            text = escape_abbr(title) % (r'\\ref{%s}' % self.idescape(id))\n+        hyperref = r'\\hyperref[%s]{%s}' % (self.idescape(id), text)\n+        self.body.append(hyperref)\n+\n+        raise nodes.SkipNode\n+\n+    def visit_download_reference(self, node: Element) -> None:\n+        pass\n+\n+    def depart_download_reference(self, node: Element) -> None:\n+        pass\n+\n+    def visit_pending_xref(self, node: Element) -> None:\n+        pass\n+\n+    def depart_pending_xref(self, node: Element) -> None:\n+        pass\n+\n+    def visit_emphasis(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxstyleemphasis{')\n+\n+    def depart_emphasis(self, node: Element) -> None:\n+        self.body.append('}')\n+\n+    def visit_literal_emphasis(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxstyleliteralemphasis{\\sphinxupquote{')\n+\n+    def depart_literal_emphasis(self, node: Element) -> None:\n+        self.body.append('}}')\n+\n+    def visit_strong(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxstylestrong{')\n+\n+    def depart_strong(self, node: Element) -> None:\n+        self.body.append('}')\n+\n+    def visit_literal_strong(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxstyleliteralstrong{\\sphinxupquote{')\n+\n+    def depart_literal_strong(self, node: Element) -> None:\n+        self.body.append('}}')\n+\n+    def visit_abbreviation(self, node: Element) -> None:\n+        abbr = node.astext()\n+        self.body.append(r'\\sphinxstyleabbreviation{')\n+        # spell out the explanation once\n+        if node.hasattr('explanation') and abbr not in self.handled_abbrs:\n+            self.context.append('} (%s)' % self.encode(node['explanation']))\n+            self.handled_abbrs.add(abbr)\n+        else:\n+            self.context.append('}')\n+\n+    def depart_abbreviation(self, node: Element) -> None:\n+        self.body.append(self.context.pop())\n+\n+    def visit_manpage(self, node: Element) -> None:\n+        return self.visit_literal_emphasis(node)\n+\n+    def depart_manpage(self, node: Element) -> None:\n+        return self.depart_literal_emphasis(node)\n+\n+    def visit_title_reference(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxtitleref{')\n+\n+    def depart_title_reference(self, node: Element) -> None:\n+        self.body.append('}')\n+\n+    def visit_thebibliography(self, node: Element) -> None:\n+        citations = cast(Iterable[nodes.citation], node)\n+        labels = (cast(nodes.label, citation[0]) for citation in citations)\n+        longest_label = max((label.astext() for label in labels), key=len)\n+        if len(longest_label) > MAX_CITATION_LABEL_LENGTH:\n+            # adjust max width of citation labels not to break the layout\n+            longest_label = longest_label[:MAX_CITATION_LABEL_LENGTH]\n+\n+        self.body.append(CR + r'\\begin{sphinxthebibliography}{%s}' %\n+                         self.encode(longest_label) + CR)\n+\n+    def depart_thebibliography(self, node: Element) -> None:\n+        self.body.append(r'\\end{sphinxthebibliography}' + CR)\n+\n+    def visit_citation(self, node: Element) -> None:\n+        label = cast(nodes.label, node[0])\n+        self.body.append(r'\\bibitem[%s]{%s:%s}' % (self.encode(label.astext()),\n+                                                   node['docname'], node['ids'][0]))\n+\n+    def depart_citation(self, node: Element) -> None:\n+        pass\n+\n+    def visit_citation_reference(self, node: Element) -> None:\n+        if self.in_title:\n+            pass\n+        else:\n+            self.body.append(r'\\sphinxcite{%s:%s}' % (node['docname'], node['refname']))\n+            raise nodes.SkipNode\n+\n+    def depart_citation_reference(self, node: Element) -> None:\n+        pass\n+\n+    def visit_literal(self, node: Element) -> None:\n+        if self.in_title:\n+            self.body.append(r'\\sphinxstyleliteralintitle{\\sphinxupquote{')\n+            return\n+        elif 'kbd' in node['classes']:\n+            self.body.append(r'\\sphinxkeyboard{\\sphinxupquote{')\n+            return\n+        lang = node.get(\"language\", None)\n+        if 'code' not in node['classes'] or not lang:\n+            self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n+            return\n+\n+        opts = self.config.highlight_options.get(lang, {})\n+        hlcode = self.highlighter.highlight_block(\n+            node.astext(), lang, opts=opts, location=node)\n+        # TODO: Use nowrap option once LaTeX formatter supports it\n+        # https://github.com/pygments/pygments/pull/1343\n+        hlcode = hlcode.replace(r'\\begin{Verbatim}[commandchars=\\\\\\{\\}]',\n+                                r'\\sphinxcode{\\sphinxupquote{%')\n+        # get consistent trailer\n+        hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n+        self.body.append(hlcode)\n+        self.body.append('}}')\n+        raise nodes.SkipNode\n+\n+    def depart_literal(self, node: Element) -> None:\n+        self.body.append('}}')\n+\n+    def visit_footnote_reference(self, node: Element) -> None:\n+        raise nodes.SkipNode\n+\n+    def visit_footnotemark(self, node: Element) -> None:\n+        self.body.append(r'\\sphinxfootnotemark[')\n+\n+    def depart_footnotemark(self, node: Element) -> None:\n+        self.body.append(']')\n+\n+    def visit_footnotetext(self, node: Element) -> None:\n+        label = cast(nodes.label, node[0])\n+        self.body.append('%' + CR)\n+        self.body.append(r'\\begin{footnotetext}[%s]' % label.astext())\n+        self.body.append(r'\\sphinxAtStartFootnote' + CR)\n+\n+    def depart_footnotetext(self, node: Element) -> None:\n+        # the \\ignorespaces in particular for after table header use\n+        self.body.append('%' + CR)\n+        self.body.append(r'\\end{footnotetext}\\ignorespaces ')\n+\n+    def visit_captioned_literal_block(self, node: Element) -> None:\n+        pass\n+\n+    def depart_captioned_literal_block(self, node: Element) -> None:\n+        pass\n+\n+    def visit_literal_block(self, node: Element) -> None:\n+        if node.rawsource != node.astext():\n+            # most probably a parsed-literal block -- don't highlight\n+            self.in_parsed_literal += 1\n+            self.body.append(r'\\begin{sphinxalltt}' + CR)\n+        else:\n+            labels = self.hypertarget_to(node)\n+            if isinstance(node.parent, captioned_literal_block):\n+                labels += self.hypertarget_to(node.parent)\n+            if labels and not self.in_footnote:\n+                self.body.append(CR + r'\\def\\sphinxLiteralBlockLabel{' + labels + '}')\n+\n+            lang = node.get('language', 'default')\n+            linenos = node.get('linenos', False)\n+            highlight_args = node.get('highlight_args', {})\n+            highlight_args['force'] = node.get('force', False)\n+            opts = self.config.highlight_options.get(lang, {})\n+\n+            hlcode = self.highlighter.highlight_block(\n+                node.rawsource, lang, opts=opts, linenos=linenos,\n+                location=node, **highlight_args\n+            )\n+            if self.in_footnote:\n+                self.body.append(CR + r'\\sphinxSetupCodeBlockInFootnote')\n+                hlcode = hlcode.replace(r'\\begin{Verbatim}',\n+                                        r'\\begin{sphinxVerbatim}')\n+            # if in table raise verbatim flag to avoid \"tabulary\" environment\n+            # and opt for sphinxVerbatimintable to handle caption & long lines\n+            elif self.table:\n+                self.table.has_problematic = True\n+                self.table.has_verbatim = True\n+                hlcode = hlcode.replace(r'\\begin{Verbatim}',\n+                                        r'\\begin{sphinxVerbatimintable}')\n+            else:\n+                hlcode = hlcode.replace(r'\\begin{Verbatim}',\n+                                        r'\\begin{sphinxVerbatim}')\n+            # get consistent trailer\n+            hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n+            if self.table and not self.in_footnote:\n+                hlcode += r'\\end{sphinxVerbatimintable}'\n+            else:\n+                hlcode += r'\\end{sphinxVerbatim}'\n+\n+            hllines = str(highlight_args.get('hl_lines', []))[1:-1]\n+            if hllines:\n+                self.body.append(CR + r'\\fvset{hllines={, %s,}}%%' % hllines)\n+            self.body.append(CR + hlcode + CR)\n+            if hllines:\n+                self.body.append(r'\\sphinxresetverbatimhllines' + CR)\n+            raise nodes.SkipNode\n+\n+    def depart_literal_block(self, node: Element) -> None:\n+        self.body.append(CR + r'\\end{sphinxalltt}' + CR)\n+        self.in_parsed_literal -= 1\n+    visit_doctest_block = visit_literal_block\n+    depart_doctest_block = depart_literal_block\n+\n+    def visit_line(self, node: Element) -> None:\n+        self.body.append(r'\\item[] ')\n+\n+    def depart_line(self, node: Element) -> None:\n+        self.body.append(CR)\n+\n+    def visit_line_block(self, node: Element) -> None:\n+        if isinstance(node.parent, nodes.line_block):\n+            self.body.append(r'\\item[]' + CR)\n+            self.body.append(r'\\begin{DUlineblock}{\\DUlineblockindent}' + CR)\n+        else:\n+            self.body.append(CR + r'\\begin{DUlineblock}{0em}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_line_block(self, node: Element) -> None:\n+        self.body.append(r'\\end{DUlineblock}' + CR)\n+\n+    def visit_block_quote(self, node: Element) -> None:\n+        # If the block quote contains a single object and that object\n+        # is a list, then generate a list not a block quote.\n+        # This lets us indent lists.\n+        done = 0\n+        if len(node.children) == 1:\n+            child = node.children[0]\n+            if isinstance(child, (nodes.bullet_list, nodes.enumerated_list)):\n+                done = 1\n+        if not done:\n+            self.body.append(r'\\begin{quote}' + CR)\n+            if self.table:\n+                self.table.has_problematic = True\n+\n+    def depart_block_quote(self, node: Element) -> None:\n+        done = 0\n+        if len(node.children) == 1:\n+            child = node.children[0]\n+            if isinstance(child, (nodes.bullet_list, nodes.enumerated_list)):\n+                done = 1\n+        if not done:\n+            self.body.append(r'\\end{quote}' + CR)\n+\n+    # option node handling copied from docutils' latex writer\n+\n+    def visit_option(self, node: Element) -> None:\n+        if self.context[-1]:\n+            # this is not the first option\n+            self.body.append(', ')\n+\n+    def depart_option(self, node: Element) -> None:\n+        # flag that the first option is done.\n+        self.context[-1] += 1\n+\n+    def visit_option_argument(self, node: Element) -> None:\n+        \"\"\"The delimiter between an option and its argument.\"\"\"\n+        self.body.append(node.get('delimiter', ' '))\n+\n+    def depart_option_argument(self, node: Element) -> None:\n+        pass\n+\n+    def visit_option_group(self, node: Element) -> None:\n+        self.body.append(r'\\item [')\n+        # flag for first option\n+        self.context.append(0)\n+\n+    def depart_option_group(self, node: Element) -> None:\n+        self.context.pop()  # the flag\n+        self.body.append('] ')\n+\n+    def visit_option_list(self, node: Element) -> None:\n+        self.body.append(r'\\begin{optionlist}{3cm}' + CR)\n+        if self.table:\n+            self.table.has_problematic = True\n+\n+    def depart_option_list(self, node: Element) -> None:\n+        self.body.append(r'\\end{optionlist}' + CR)\n+\n+    def visit_option_list_item(self, node: Element) -> None:\n+        pass\n+\n+    def depart_option_list_item(self, node: Element) -> None:\n+        pass\n+\n+    def visit_option_string(self, node: Element) -> None:\n+        ostring = node.astext()\n+        self.body.append(self.encode(ostring))\n+        raise nodes.SkipNode\n+\n+    def visit_description(self, node: Element) -> None:\n+        self.body.append(' ')\n+\n+    def depart_description(self, node: Element) -> None:\n+        pass\n+\n+    def visit_superscript(self, node: Element) -> None:\n+        self.body.append(r'$^{\\text{')\n+\n+    def depart_superscript(self, node: Element) -> None:\n+        self.body.append('}}$')\n+\n+    def visit_subscript(self, node: Element) -> None:\n+        self.body.append(r'$_{\\text{')\n+\n+    def depart_subscript(self, node: Element) -> None:\n+        self.body.append('}}$')\n+\n+    def visit_inline(self, node: Element) -> None:\n+        classes = node.get('classes', [])\n+        if classes in [['menuselection']]:\n+            self.body.append(r'\\sphinxmenuselection{')\n+            self.context.append('}')\n+        elif classes in [['guilabel']]:\n+            self.body.append(r'\\sphinxguilabel{')\n+            self.context.append('}')\n+        elif classes in [['accelerator']]:\n+            self.body.append(r'\\sphinxaccelerator{')\n+            self.context.append('}')\n+        elif classes and not self.in_title:\n+            self.body.append(r'\\DUrole{%s}{' % ','.join(classes))\n+            self.context.append('}')\n+        else:\n+            self.context.append('')\n+\n+    def depart_inline(self, node: Element) -> None:\n+        self.body.append(self.context.pop())\n+\n+    def visit_generated(self, node: Element) -> None:\n+        pass\n+\n+    def depart_generated(self, node: Element) -> None:\n+        pass\n+\n+    def visit_compound(self, node: Element) -> None:\n+        pass\n+\n+    def depart_compound(self, node: Element) -> None:\n+        pass\n+\n+    def visit_container(self, node: Element) -> None:\n+        classes = node.get('classes', [])\n+        for c in classes:\n+            self.body.append('\\n\\\\begin{sphinxuseclass}{%s}' % c)\n+\n+    def depart_container(self, node: Element) -> None:\n+        classes = node.get('classes', [])\n+        for _c in classes:\n+            self.body.append('\\n\\\\end{sphinxuseclass}')\n+\n+    def visit_decoration(self, node: Element) -> None:\n+        pass\n+\n+    def depart_decoration(self, node: Element) -> None:\n+        pass\n+\n+    # docutils-generated elements that we don't support\n+\n+    def visit_header(self, node: Element) -> None:\n+        raise nodes.SkipNode\n+\n+    def visit_footer(self, node: Element) -> None:\n+        raise nodes.SkipNode\n+\n+    def visit_docinfo(self, node: Element) -> None:\n+        raise nodes.SkipNode\n+\n+    # text handling\n+\n+    def encode(self, text: str) -> str:\n+        text = self.escape(text)\n+        if self.literal_whitespace:\n+            # Insert a blank before the newline, to avoid\n+            # ! LaTeX Error: There's no line here to end.\n+            text = text.replace(CR, r'~\\\\' + CR).replace(' ', '~')\n+        return text\n+\n+    def encode_uri(self, text: str) -> str:\n+        # TODO: it is probably wrong that this uses texescape.escape()\n+        #       this must be checked against hyperref package exact dealings\n+        #       mainly, %, #, {, } and \\ need escaping via a \\ escape\n+        # in \\href, the tilde is allowed and must be represented literally\n+        return self.encode(text).replace(r'\\textasciitilde{}', '~').\\\n+            replace(r'\\sphinxhyphen{}', '-').\\\n+            replace(r'\\textquotesingle{}', \"'\")\n+\n+    def visit_Text(self, node: Text) -> None:\n+        text = self.encode(node.astext())\n+        self.body.append(text)\n+\n+    def depart_Text(self, node: Text) -> None:\n+        pass\n+\n+    def visit_comment(self, node: Element) -> None:\n+        raise nodes.SkipNode\n+\n+    def visit_meta(self, node: Element) -> None:\n+        # only valid for HTML\n+        raise nodes.SkipNode\n+\n+    def visit_system_message(self, node: Element) -> None:\n+        pass\n+\n+    def depart_system_message(self, node: Element) -> None:\n+        self.body.append(CR)\n+\n+    def visit_math(self, node: Element) -> None:\n+        if self.in_title:\n+            self.body.append(r'\\protect\\(%s\\protect\\)' % node.astext())\n+        else:\n+            self.body.append(r'\\(%s\\)' % node.astext())\n+        raise nodes.SkipNode\n+\n+    def visit_math_block(self, node: Element) -> None:\n+        if node.get('label'):\n+            label = \"equation:%s:%s\" % (node['docname'], node['label'])\n+        else:\n+            label = None\n+\n+        if node.get('nowrap'):\n+            if label:\n+                self.body.append(r'\\label{%s}' % label)\n+            self.body.append(node.astext())\n+        else:\n+            from sphinx.util.math import wrap_displaymath\n+            self.body.append(wrap_displaymath(node.astext(), label,\n+                                              self.config.math_number_all))\n+        raise nodes.SkipNode\n+\n+    def visit_math_reference(self, node: Element) -> None:\n+        label = \"equation:%s:%s\" % (node['docname'], node['target'])\n+        eqref_format = self.config.math_eqref_format\n+        if eqref_format:\n+            try:\n+                ref = r'\\ref{%s}' % label\n+                self.body.append(eqref_format.format(number=ref))\n+            except KeyError as exc:\n+                logger.warning(__('Invalid math_eqref_format: %r'), exc,\n+                               location=node)\n+                self.body.append(r'\\eqref{%s}' % label)\n+        else:\n+            self.body.append(r'\\eqref{%s}' % label)\n+\n+    def depart_math_reference(self, node: Element) -> None:\n+        pass\n+\n+    @property\n+    def docclasses(self) -> Tuple[str, str]:\n+        \"\"\"Prepends prefix to sphinx document classes\"\"\"\n+        warnings.warn('LaTeXWriter.docclasses() is deprecated.',\n+                      RemovedInSphinx70Warning, stacklevel=2)\n+        return ('howto', 'manual')\n+\n+\n+# FIXME: Workaround to avoid circular import\n+# refs: https://github.com/sphinx-doc/sphinx/issues/5433\n+from sphinx.builders.latex.nodes import ( # NOQA isort:skip\n+    HYPERLINK_SUPPORT_NODES, captioned_literal_block, footnotetext,\n+)\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..9783e57db 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4662,8 +4662,14 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n+                # consume traditional suffix letters like u, l, f\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # support user-defined literal suffixes: identifier starting\n+                # with letter or underscore and followed by letters, digits or underscores\n+                if self.current_char is not None and (self.current_char == '_' or self.current_char.isalpha()):\n+                    while self.current_char is not None and (self.current_char == '_' or self.current_char.isalnum()):\n+                        self.pos += 1\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n"
  },
  "sphinx-doc__sphinx-8265": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8265",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 378174993..83bf979fe 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -390,6 +390,17 @@ def object_description(object: Any) -> str:\n         else:\n             return \"frozenset({%s})\" % \", \".join(object_description(x)\n                                                  for x in sorted_values)\n+    if isinstance(object, tuple):\n+        # Preserve parentheses for tuple defaults, including single-element tuples\n+        try:\n+            return \"(\" + \", \".join(object_description(x) for x in object) + (\",\" if len(object)==1 else \")\")\n+        except Exception:\n+            pass\n+    if isinstance(object, list):\n+        try:\n+            return \"[\" + \", \".join(object_description(x) for x in object) + \"]\"\n+        except Exception:\n+            pass\n     try:\n         s = repr(object)\n     except Exception as exc:\ndiff --git a/sphinx/util/inspect.py.bak b/sphinx/util/inspect.py.bak\nnew file mode 100644\nindex 000000000..378174993\n--- /dev/null\n+++ b/sphinx/util/inspect.py.bak\n@@ -0,0 +1,840 @@\n+\"\"\"\n+    sphinx.util.inspect\n+    ~~~~~~~~~~~~~~~~~~~\n+\n+    Helpers for inspecting Python modules.\n+\n+    :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.\n+    :license: BSD, see LICENSE for details.\n+\"\"\"\n+\n+import builtins\n+import contextlib\n+import enum\n+import inspect\n+import re\n+import sys\n+import types\n+import typing\n+import warnings\n+from functools import partial, partialmethod\n+from inspect import (  # NOQA\n+    Parameter, isclass, ismethod, ismethoddescriptor, ismodule\n+)\n+from io import StringIO\n+from typing import Any, Callable, Dict, Mapping, List, Optional, Tuple\n+from typing import cast\n+\n+from sphinx.deprecation import RemovedInSphinx40Warning, RemovedInSphinx50Warning\n+from sphinx.pycode.ast import ast  # for py35-37\n+from sphinx.pycode.ast import unparse as ast_unparse\n+from sphinx.util import logging\n+from sphinx.util.typing import ForwardRef\n+from sphinx.util.typing import stringify as stringify_annotation\n+\n+if sys.version_info > (3, 7):\n+    from types import (\n+        ClassMethodDescriptorType,\n+        MethodDescriptorType,\n+        WrapperDescriptorType\n+    )\n+else:\n+    ClassMethodDescriptorType = type(object.__init__)\n+    MethodDescriptorType = type(str.join)\n+    WrapperDescriptorType = type(dict.__dict__['fromkeys'])\n+\n+logger = logging.getLogger(__name__)\n+\n+memory_address_re = re.compile(r' at 0x[0-9a-f]{8,16}(?=>)', re.IGNORECASE)\n+\n+\n+# Copied from the definition of inspect.getfullargspec from Python master,\n+# and modified to remove the use of special flags that break decorated\n+# callables and bound methods in the name of backwards compatibility. Used\n+# under the terms of PSF license v2, which requires the above statement\n+# and the following:\n+#\n+#   Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n+#   2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017 Python Software\n+#   Foundation; All Rights Reserved\n+def getargspec(func: Callable) -> Any:\n+    \"\"\"Like inspect.getfullargspec but supports bound methods, and wrapped\n+    methods.\"\"\"\n+    warnings.warn('sphinx.ext.inspect.getargspec() is deprecated',\n+                  RemovedInSphinx50Warning, stacklevel=2)\n+    # On 3.5+, signature(int) or similar raises ValueError. On 3.4, it\n+    # succeeds with a bogus signature. We want a TypeError uniformly, to\n+    # match historical behavior.\n+    if (isinstance(func, type) and\n+            is_builtin_class_method(func, \"__new__\") and\n+            is_builtin_class_method(func, \"__init__\")):\n+        raise TypeError(\n+            \"can't compute signature for built-in type {}\".format(func))\n+\n+    sig = inspect.signature(func)\n+\n+    args = []\n+    varargs = None\n+    varkw = None\n+    kwonlyargs = []\n+    defaults = ()\n+    annotations = {}\n+    defaults = ()\n+    kwdefaults = {}\n+\n+    if sig.return_annotation is not sig.empty:\n+        annotations['return'] = sig.return_annotation\n+\n+    for param in sig.parameters.values():\n+        kind = param.kind\n+        name = param.name\n+\n+        if kind is Parameter.POSITIONAL_ONLY:\n+            args.append(name)\n+        elif kind is Parameter.POSITIONAL_OR_KEYWORD:\n+            args.append(name)\n+            if param.default is not param.empty:\n+                defaults += (param.default,)  # type: ignore\n+        elif kind is Parameter.VAR_POSITIONAL:\n+            varargs = name\n+        elif kind is Parameter.KEYWORD_ONLY:\n+            kwonlyargs.append(name)\n+            if param.default is not param.empty:\n+                kwdefaults[name] = param.default\n+        elif kind is Parameter.VAR_KEYWORD:\n+            varkw = name\n+\n+        if param.annotation is not param.empty:\n+            annotations[name] = param.annotation\n+\n+    if not kwdefaults:\n+        # compatibility with 'func.__kwdefaults__'\n+        kwdefaults = None\n+\n+    if not defaults:\n+        # compatibility with 'func.__defaults__'\n+        defaults = None\n+\n+    return inspect.FullArgSpec(args, varargs, varkw, defaults,\n+                               kwonlyargs, kwdefaults, annotations)\n+\n+\n+def unwrap(obj: Any) -> Any:\n+    \"\"\"Get an original object from wrapped object (wrapped functions).\"\"\"\n+    try:\n+        return inspect.unwrap(obj)\n+    except ValueError:\n+        # might be a mock object\n+        return obj\n+\n+\n+def unwrap_all(obj: Any, *, stop: Callable = None) -> Any:\n+    \"\"\"\n+    Get an original object from wrapped object (unwrapping partials, wrapped\n+    functions, and other decorators).\n+    \"\"\"\n+    while True:\n+        if stop and stop(obj):\n+            return obj\n+        elif ispartial(obj):\n+            obj = obj.func\n+        elif inspect.isroutine(obj) and hasattr(obj, '__wrapped__'):\n+            obj = obj.__wrapped__\n+        elif isclassmethod(obj):\n+            obj = obj.__func__\n+        elif isstaticmethod(obj):\n+            obj = obj.__func__\n+        else:\n+            return obj\n+\n+\n+def isenumclass(x: Any) -> bool:\n+    \"\"\"Check if the object is subclass of enum.\"\"\"\n+    return inspect.isclass(x) and issubclass(x, enum.Enum)\n+\n+\n+def isenumattribute(x: Any) -> bool:\n+    \"\"\"Check if the object is attribute of enum.\"\"\"\n+    return isinstance(x, enum.Enum)\n+\n+\n+def unpartial(obj: Any) -> Any:\n+    \"\"\"Get an original object from partial object.\n+\n+    This returns given object itself if not partial.\n+    \"\"\"\n+    while ispartial(obj):\n+        obj = obj.func\n+\n+    return obj\n+\n+\n+def ispartial(obj: Any) -> bool:\n+    \"\"\"Check if the object is partial.\"\"\"\n+    return isinstance(obj, (partial, partialmethod))\n+\n+\n+def isclassmethod(obj: Any) -> bool:\n+    \"\"\"Check if the object is classmethod.\"\"\"\n+    if isinstance(obj, classmethod):\n+        return True\n+    elif inspect.ismethod(obj) and obj.__self__ is not None and isclass(obj.__self__):\n+        return True\n+\n+    return False\n+\n+\n+def isstaticmethod(obj: Any, cls: Any = None, name: str = None) -> bool:\n+    \"\"\"Check if the object is staticmethod.\"\"\"\n+    if isinstance(obj, staticmethod):\n+        return True\n+    elif cls and name:\n+        # trace __mro__ if the method is defined in parent class\n+        #\n+        # .. note:: This only works well with new style classes.\n+        for basecls in getattr(cls, '__mro__', [cls]):\n+            meth = basecls.__dict__.get(name)\n+            if meth:\n+                if isinstance(meth, staticmethod):\n+                    return True\n+                else:\n+                    return False\n+\n+    return False\n+\n+\n+def isdescriptor(x: Any) -> bool:\n+    \"\"\"Check if the object is some kind of descriptor.\"\"\"\n+    for item in '__get__', '__set__', '__delete__':\n+        if hasattr(safe_getattr(x, item, None), '__call__'):\n+            return True\n+    return False\n+\n+\n+def isabstractmethod(obj: Any) -> bool:\n+    \"\"\"Check if the object is an abstractmethod.\"\"\"\n+    return safe_getattr(obj, '__isabstractmethod__', False) is True\n+\n+\n+def is_cython_function_or_method(obj: Any) -> bool:\n+    \"\"\"Check if the object is a function or method in cython.\"\"\"\n+    try:\n+        return obj.__class__.__name__ == 'cython_function_or_method'\n+    except AttributeError:\n+        return False\n+\n+\n+def isattributedescriptor(obj: Any) -> bool:\n+    \"\"\"Check if the object is an attribute like descriptor.\"\"\"\n+    if inspect.isdatadescriptor(obj):\n+        # data descriptor is kind of attribute\n+        return True\n+    elif isdescriptor(obj):\n+        # non data descriptor\n+        unwrapped = unwrap(obj)\n+        if isfunction(unwrapped) or isbuiltin(unwrapped) or inspect.ismethod(unwrapped):\n+            # attribute must not be either function, builtin and method\n+            return False\n+        elif is_cython_function_or_method(unwrapped):\n+            # attribute must not be either function and method (for cython)\n+            return False\n+        elif inspect.isclass(unwrapped):\n+            # attribute must not be a class\n+            return False\n+        elif isinstance(unwrapped, (ClassMethodDescriptorType,\n+                                    MethodDescriptorType,\n+                                    WrapperDescriptorType)):\n+            # attribute must not be a method descriptor\n+            return False\n+        elif type(unwrapped).__name__ == \"instancemethod\":\n+            # attribute must not be an instancemethod (C-API)\n+            return False\n+        else:\n+            return True\n+    else:\n+        return False\n+\n+\n+def is_singledispatch_function(obj: Any) -> bool:\n+    \"\"\"Check if the object is singledispatch function.\"\"\"\n+    if (inspect.isfunction(obj) and\n+            hasattr(obj, 'dispatch') and\n+            hasattr(obj, 'register') and\n+            obj.dispatch.__module__ == 'functools'):\n+        return True\n+    else:\n+        return False\n+\n+\n+def is_singledispatch_method(obj: Any) -> bool:\n+    \"\"\"Check if the object is singledispatch method.\"\"\"\n+    try:\n+        from functools import singledispatchmethod  # type: ignore\n+        return isinstance(obj, singledispatchmethod)\n+    except ImportError:  # py35-37\n+        return False\n+\n+\n+def isfunction(obj: Any) -> bool:\n+    \"\"\"Check if the object is function.\"\"\"\n+    return inspect.isfunction(unwrap_all(obj))\n+\n+\n+def isbuiltin(obj: Any) -> bool:\n+    \"\"\"Check if the object is builtin.\"\"\"\n+    return inspect.isbuiltin(unwrap_all(obj))\n+\n+\n+def isroutine(obj: Any) -> bool:\n+    \"\"\"Check is any kind of function or method.\"\"\"\n+    return inspect.isroutine(unwrap_all(obj))\n+\n+\n+def iscoroutinefunction(obj: Any) -> bool:\n+    \"\"\"Check if the object is coroutine-function.\"\"\"\n+    # unwrap staticmethod, classmethod and partial (except wrappers)\n+    obj = unwrap_all(obj, stop=lambda o: hasattr(o, '__wrapped__'))\n+    if hasattr(obj, '__code__') and inspect.iscoroutinefunction(obj):\n+        # check obj.__code__ because iscoroutinefunction() crashes for custom method-like\n+        # objects (see https://github.com/sphinx-doc/sphinx/issues/6605)\n+        return True\n+    else:\n+        return False\n+\n+\n+def isproperty(obj: Any) -> bool:\n+    \"\"\"Check if the object is property.\"\"\"\n+    if sys.version_info > (3, 8):\n+        from functools import cached_property  # cached_property is available since py3.8\n+        if isinstance(obj, cached_property):\n+            return True\n+\n+    return isinstance(obj, property)\n+\n+\n+def isgenericalias(obj: Any) -> bool:\n+    \"\"\"Check if the object is GenericAlias.\"\"\"\n+    if (hasattr(typing, '_GenericAlias') and  # only for py37+\n+            isinstance(obj, typing._GenericAlias)):  # type: ignore\n+        return True\n+    elif (hasattr(types, 'GenericAlias') and  # only for py39+\n+          isinstance(obj, types.GenericAlias)):  # type: ignore\n+        return True\n+    else:\n+        return False\n+\n+\n+def safe_getattr(obj: Any, name: str, *defargs: Any) -> Any:\n+    \"\"\"A getattr() that turns all exceptions into AttributeErrors.\"\"\"\n+    try:\n+        return getattr(obj, name, *defargs)\n+    except Exception as exc:\n+        # sometimes accessing a property raises an exception (e.g.\n+        # NotImplementedError), so let's try to read the attribute directly\n+        try:\n+            # In case the object does weird things with attribute access\n+            # such that accessing `obj.__dict__` may raise an exception\n+            return obj.__dict__[name]\n+        except Exception:\n+            pass\n+\n+        # this is a catch-all for all the weird things that some modules do\n+        # with attribute access\n+        if defargs:\n+            return defargs[0]\n+\n+        raise AttributeError(name) from exc\n+\n+\n+def safe_getmembers(object: Any, predicate: Callable[[str], bool] = None,\n+                    attr_getter: Callable = safe_getattr) -> List[Tuple[str, Any]]:\n+    \"\"\"A version of inspect.getmembers() that uses safe_getattr().\"\"\"\n+    warnings.warn('safe_getmembers() is deprecated', RemovedInSphinx40Warning, stacklevel=2)\n+\n+    results = []  # type: List[Tuple[str, Any]]\n+    for key in dir(object):\n+        try:\n+            value = attr_getter(object, key, None)\n+        except AttributeError:\n+            continue\n+        if not predicate or predicate(value):\n+            results.append((key, value))\n+    results.sort()\n+    return results\n+\n+\n+def object_description(object: Any) -> str:\n+    \"\"\"A repr() implementation that returns text safe to use in reST context.\"\"\"\n+    if isinstance(object, dict):\n+        try:\n+            sorted_keys = sorted(object)\n+        except Exception:\n+            pass  # Cannot sort dict keys, fall back to generic repr\n+        else:\n+            items = (\"%s: %s\" %\n+                     (object_description(key), object_description(object[key]))\n+                     for key in sorted_keys)\n+            return \"{%s}\" % \", \".join(items)\n+    if isinstance(object, set):\n+        try:\n+            sorted_values = sorted(object)\n+        except TypeError:\n+            pass  # Cannot sort set values, fall back to generic repr\n+        else:\n+            return \"{%s}\" % \", \".join(object_description(x) for x in sorted_values)\n+    if isinstance(object, frozenset):\n+        try:\n+            sorted_values = sorted(object)\n+        except TypeError:\n+            pass  # Cannot sort frozenset values, fall back to generic repr\n+        else:\n+            return \"frozenset({%s})\" % \", \".join(object_description(x)\n+                                                 for x in sorted_values)\n+    try:\n+        s = repr(object)\n+    except Exception as exc:\n+        raise ValueError from exc\n+    # Strip non-deterministic memory addresses such as\n+    # ``<__main__.A at 0x7f68cb685710>``\n+    s = memory_address_re.sub('', s)\n+    return s.replace('\\n', ' ')\n+\n+\n+def is_builtin_class_method(obj: Any, attr_name: str) -> bool:\n+    \"\"\"If attr_name is implemented at builtin class, return True.\n+\n+        >>> is_builtin_class_method(int, '__init__')\n+        True\n+\n+    Why this function needed? CPython implements int.__init__ by Descriptor\n+    but PyPy implements it by pure Python code.\n+    \"\"\"\n+    try:\n+        mro = inspect.getmro(obj)\n+    except AttributeError:\n+        # no __mro__, assume the object has no methods as we know them\n+        return False\n+\n+    try:\n+        cls = next(c for c in mro if attr_name in safe_getattr(c, '__dict__', {}))\n+    except StopIteration:\n+        return False\n+\n+    try:\n+        name = safe_getattr(cls, '__name__')\n+    except AttributeError:\n+        return False\n+\n+    return getattr(builtins, name, None) is cls\n+\n+\n+def _should_unwrap(subject: Callable) -> bool:\n+    \"\"\"Check the function should be unwrapped on getting signature.\"\"\"\n+    if (safe_getattr(subject, '__globals__', None) and\n+            subject.__globals__.get('__name__') == 'contextlib' and  # type: ignore\n+            subject.__globals__.get('__file__') == contextlib.__file__):  # type: ignore\n+        # contextmanger should be unwrapped\n+        return True\n+\n+    return False\n+\n+\n+def signature(subject: Callable, bound_method: bool = False, follow_wrapped: bool = False,\n+              type_aliases: Dict = {}) -> inspect.Signature:\n+    \"\"\"Return a Signature object for the given *subject*.\n+\n+    :param bound_method: Specify *subject* is a bound method or not\n+    :param follow_wrapped: Same as ``inspect.signature()``.\n+                           Defaults to ``False`` (get a signature of *subject*).\n+    \"\"\"\n+    try:\n+        try:\n+            if _should_unwrap(subject):\n+                signature = inspect.signature(subject)\n+            else:\n+                signature = inspect.signature(subject, follow_wrapped=follow_wrapped)\n+        except ValueError:\n+            # follow built-in wrappers up (ex. functools.lru_cache)\n+            signature = inspect.signature(subject)\n+        parameters = list(signature.parameters.values())\n+        return_annotation = signature.return_annotation\n+    except IndexError:\n+        # Until python 3.6.4, cpython has been crashed on inspection for\n+        # partialmethods not having any arguments.\n+        # https://bugs.python.org/issue33009\n+        if hasattr(subject, '_partialmethod'):\n+            parameters = []\n+            return_annotation = Parameter.empty\n+        else:\n+            raise\n+\n+    try:\n+        # Update unresolved annotations using ``get_type_hints()``.\n+        annotations = typing.get_type_hints(subject, None, type_aliases)\n+        for i, param in enumerate(parameters):\n+            if isinstance(param.annotation, str) and param.name in annotations:\n+                parameters[i] = param.replace(annotation=annotations[param.name])\n+        if 'return' in annotations:\n+            return_annotation = annotations['return']\n+    except Exception:\n+        # ``get_type_hints()`` does not support some kind of objects like partial,\n+        # ForwardRef and so on.\n+        pass\n+\n+    if bound_method:\n+        if inspect.ismethod(subject):\n+            # ``inspect.signature()`` considers the subject is a bound method and removes\n+            # first argument from signature.  Therefore no skips are needed here.\n+            pass\n+        else:\n+            if len(parameters) > 0:\n+                parameters.pop(0)\n+\n+    # To allow to create signature object correctly for pure python functions,\n+    # pass an internal parameter __validate_parameters__=False to Signature\n+    #\n+    # For example, this helps a function having a default value `inspect._empty`.\n+    # refs: https://github.com/sphinx-doc/sphinx/issues/7935\n+    return inspect.Signature(parameters, return_annotation=return_annotation,  # type: ignore\n+                             __validate_parameters__=False)\n+\n+\n+def evaluate_signature(sig: inspect.Signature, globalns: Dict = None, localns: Dict = None\n+                       ) -> inspect.Signature:\n+    \"\"\"Evaluate unresolved type annotations in a signature object.\"\"\"\n+    def evaluate_forwardref(ref: ForwardRef, globalns: Dict, localns: Dict) -> Any:\n+        \"\"\"Evaluate a forward reference.\"\"\"\n+        if sys.version_info > (3, 9):\n+            return ref._evaluate(globalns, localns, frozenset())\n+        else:\n+            return ref._evaluate(globalns, localns)\n+\n+    def evaluate(annotation: Any, globalns: Dict, localns: Dict) -> Any:\n+        \"\"\"Evaluate unresolved type annotation.\"\"\"\n+        try:\n+            if isinstance(annotation, str):\n+                ref = ForwardRef(annotation, True)\n+                annotation = evaluate_forwardref(ref, globalns, localns)\n+\n+                if isinstance(annotation, ForwardRef):\n+                    annotation = evaluate_forwardref(ref, globalns, localns)\n+                elif isinstance(annotation, str):\n+                    # might be a ForwardRef'ed annotation in overloaded functions\n+                    ref = ForwardRef(annotation, True)\n+                    annotation = evaluate_forwardref(ref, globalns, localns)\n+        except (NameError, TypeError):\n+            # failed to evaluate type. skipped.\n+            pass\n+\n+        return annotation\n+\n+    if globalns is None:\n+        globalns = {}\n+    if localns is None:\n+        localns = globalns\n+\n+    parameters = list(sig.parameters.values())\n+    for i, param in enumerate(parameters):\n+        if param.annotation:\n+            annotation = evaluate(param.annotation, globalns, localns)\n+            parameters[i] = param.replace(annotation=annotation)\n+\n+    return_annotation = sig.return_annotation\n+    if return_annotation:\n+        return_annotation = evaluate(return_annotation, globalns, localns)\n+\n+    return sig.replace(parameters=parameters, return_annotation=return_annotation)\n+\n+\n+def stringify_signature(sig: inspect.Signature, show_annotation: bool = True,\n+                        show_return_annotation: bool = True) -> str:\n+    \"\"\"Stringify a Signature object.\n+\n+    :param show_annotation: Show annotation in result\n+    \"\"\"\n+    args = []\n+    last_kind = None\n+    for param in sig.parameters.values():\n+        if param.kind != param.POSITIONAL_ONLY and last_kind == param.POSITIONAL_ONLY:\n+            # PEP-570: Separator for Positional Only Parameter: /\n+            args.append('/')\n+        if param.kind == param.KEYWORD_ONLY and last_kind in (param.POSITIONAL_OR_KEYWORD,\n+                                                              param.POSITIONAL_ONLY,\n+                                                              None):\n+            # PEP-3102: Separator for Keyword Only Parameter: *\n+            args.append('*')\n+\n+        arg = StringIO()\n+        if param.kind == param.VAR_POSITIONAL:\n+            arg.write('*' + param.name)\n+        elif param.kind == param.VAR_KEYWORD:\n+            arg.write('**' + param.name)\n+        else:\n+            arg.write(param.name)\n+\n+        if show_annotation and param.annotation is not param.empty:\n+            arg.write(': ')\n+            arg.write(stringify_annotation(param.annotation))\n+        if param.default is not param.empty:\n+            if show_annotation and param.annotation is not param.empty:\n+                arg.write(' = ')\n+            else:\n+                arg.write('=')\n+            arg.write(object_description(param.default))\n+\n+        args.append(arg.getvalue())\n+        last_kind = param.kind\n+\n+    if last_kind == Parameter.POSITIONAL_ONLY:\n+        # PEP-570: Separator for Positional Only Parameter: /\n+        args.append('/')\n+\n+    if (sig.return_annotation is Parameter.empty or\n+            show_annotation is False or\n+            show_return_annotation is False):\n+        return '(%s)' % ', '.join(args)\n+    else:\n+        annotation = stringify_annotation(sig.return_annotation)\n+        return '(%s) -> %s' % (', '.join(args), annotation)\n+\n+\n+def signature_from_str(signature: str) -> inspect.Signature:\n+    \"\"\"Create a Signature object from string.\"\"\"\n+    module = ast.parse('def func' + signature + ': pass')\n+    function = cast(ast.FunctionDef, module.body[0])  # type: ignore\n+\n+    return signature_from_ast(function)\n+\n+\n+def signature_from_ast(node: ast.FunctionDef) -> inspect.Signature:\n+    \"\"\"Create a Signature object from AST *node*.\"\"\"\n+    args = node.args\n+    defaults = list(args.defaults)\n+    params = []\n+    if hasattr(args, \"posonlyargs\"):\n+        posonlyargs = len(args.posonlyargs)  # type: ignore\n+        positionals = posonlyargs + len(args.args)\n+    else:\n+        posonlyargs = 0\n+        positionals = len(args.args)\n+\n+    for _ in range(len(defaults), positionals):\n+        defaults.insert(0, Parameter.empty)\n+\n+    if hasattr(args, \"posonlyargs\"):\n+        for i, arg in enumerate(args.posonlyargs):  # type: ignore\n+            if defaults[i] is Parameter.empty:\n+                default = Parameter.empty\n+            else:\n+                default = ast_unparse(defaults[i])\n+\n+            annotation = ast_unparse(arg.annotation) or Parameter.empty\n+            params.append(Parameter(arg.arg, Parameter.POSITIONAL_ONLY,\n+                                    default=default, annotation=annotation))\n+\n+    for i, arg in enumerate(args.args):\n+        if defaults[i + posonlyargs] is Parameter.empty:\n+            default = Parameter.empty\n+        else:\n+            default = ast_unparse(defaults[i + posonlyargs])\n+\n+        annotation = ast_unparse(arg.annotation) or Parameter.empty\n+        params.append(Parameter(arg.arg, Parameter.POSITIONAL_OR_KEYWORD,\n+                                default=default, annotation=annotation))\n+\n+    if args.vararg:\n+        annotation = ast_unparse(args.vararg.annotation) or Parameter.empty\n+        params.append(Parameter(args.vararg.arg, Parameter.VAR_POSITIONAL,\n+                                annotation=annotation))\n+\n+    for i, arg in enumerate(args.kwonlyargs):\n+        default = ast_unparse(args.kw_defaults[i]) or Parameter.empty\n+        annotation = ast_unparse(arg.annotation) or Parameter.empty\n+        params.append(Parameter(arg.arg, Parameter.KEYWORD_ONLY, default=default,\n+                                annotation=annotation))\n+\n+    if args.kwarg:\n+        annotation = ast_unparse(args.kwarg.annotation) or Parameter.empty\n+        params.append(Parameter(args.kwarg.arg, Parameter.VAR_KEYWORD,\n+                                annotation=annotation))\n+\n+    return_annotation = ast_unparse(node.returns) or Parameter.empty\n+\n+    return inspect.Signature(params, return_annotation=return_annotation)\n+\n+\n+class Signature:\n+    \"\"\"The Signature object represents the call signature of a callable object and\n+    its return annotation.\n+    \"\"\"\n+\n+    empty = inspect.Signature.empty\n+\n+    def __init__(self, subject: Callable, bound_method: bool = False,\n+                 has_retval: bool = True) -> None:\n+        warnings.warn('sphinx.util.inspect.Signature() is deprecated',\n+                      RemovedInSphinx40Warning, stacklevel=2)\n+\n+        # check subject is not a built-in class (ex. int, str)\n+        if (isinstance(subject, type) and\n+                is_builtin_class_method(subject, \"__new__\") and\n+                is_builtin_class_method(subject, \"__init__\")):\n+            raise TypeError(\"can't compute signature for built-in type {}\".format(subject))\n+\n+        self.subject = subject\n+        self.has_retval = has_retval\n+        self.partialmethod_with_noargs = False\n+\n+        try:\n+            self.signature = inspect.signature(subject)  # type: Optional[inspect.Signature]\n+        except IndexError:\n+            # Until python 3.6.4, cpython has been crashed on inspection for\n+            # partialmethods not having any arguments.\n+            # https://bugs.python.org/issue33009\n+            if hasattr(subject, '_partialmethod'):\n+                self.signature = None\n+                self.partialmethod_with_noargs = True\n+            else:\n+                raise\n+\n+        try:\n+            self.annotations = typing.get_type_hints(subject)\n+        except Exception:\n+            # get_type_hints() does not support some kind of objects like partial,\n+            # ForwardRef and so on.  For them, it raises an exception. In that case,\n+            # we try to build annotations from argspec.\n+            self.annotations = {}\n+\n+        if bound_method:\n+            # client gives a hint that the subject is a bound method\n+\n+            if inspect.ismethod(subject):\n+                # inspect.signature already considers the subject is bound method.\n+                # So it is not need to skip first argument.\n+                self.skip_first_argument = False\n+            else:\n+                self.skip_first_argument = True\n+        else:\n+            # inspect.signature recognizes type of method properly without any hints\n+            self.skip_first_argument = False\n+\n+    @property\n+    def parameters(self) -> Mapping:\n+        if self.partialmethod_with_noargs:\n+            return {}\n+        else:\n+            return self.signature.parameters\n+\n+    @property\n+    def return_annotation(self) -> Any:\n+        if self.signature:\n+            if self.has_retval:\n+                return self.signature.return_annotation\n+            else:\n+                return Parameter.empty\n+        else:\n+            return None\n+\n+    def format_args(self, show_annotation: bool = True) -> str:\n+        def get_annotation(param: Parameter) -> Any:\n+            if isinstance(param.annotation, str) and param.name in self.annotations:\n+                return self.annotations[param.name]\n+            else:\n+                return param.annotation\n+\n+        args = []\n+        last_kind = None\n+        for i, param in enumerate(self.parameters.values()):\n+            # skip first argument if subject is bound method\n+            if self.skip_first_argument and i == 0:\n+                continue\n+\n+            arg = StringIO()\n+\n+            # insert '*' between POSITIONAL args and KEYWORD_ONLY args::\n+            #     func(a, b, *, c, d):\n+            if param.kind == param.KEYWORD_ONLY and last_kind in (param.POSITIONAL_OR_KEYWORD,\n+                                                                  param.POSITIONAL_ONLY,\n+                                                                  None):\n+                args.append('*')\n+\n+            if param.kind in (param.POSITIONAL_ONLY,\n+                              param.POSITIONAL_OR_KEYWORD,\n+                              param.KEYWORD_ONLY):\n+                arg.write(param.name)\n+                if show_annotation and param.annotation is not param.empty:\n+                    arg.write(': ')\n+                    arg.write(stringify_annotation(get_annotation(param)))\n+                if param.default is not param.empty:\n+                    if param.annotation is param.empty or show_annotation is False:\n+                        arg.write('=')\n+                        arg.write(object_description(param.default))\n+                    else:\n+                        arg.write(' = ')\n+                        arg.write(object_description(param.default))\n+            elif param.kind == param.VAR_POSITIONAL:\n+                arg.write('*')\n+                arg.write(param.name)\n+                if show_annotation and param.annotation is not param.empty:\n+                    arg.write(': ')\n+                    arg.write(stringify_annotation(get_annotation(param)))\n+            elif param.kind == param.VAR_KEYWORD:\n+                arg.write('**')\n+                arg.write(param.name)\n+                if show_annotation and param.annotation is not param.empty:\n+                    arg.write(': ')\n+                    arg.write(stringify_annotation(get_annotation(param)))\n+\n+            args.append(arg.getvalue())\n+            last_kind = param.kind\n+\n+        if self.return_annotation is Parameter.empty or show_annotation is False:\n+            return '(%s)' % ', '.join(args)\n+        else:\n+            if 'return' in self.annotations:\n+                annotation = stringify_annotation(self.annotations['return'])\n+            else:\n+                annotation = stringify_annotation(self.return_annotation)\n+\n+            return '(%s) -> %s' % (', '.join(args), annotation)\n+\n+    def format_annotation(self, annotation: Any) -> str:\n+        \"\"\"Return formatted representation of a type annotation.\"\"\"\n+        return stringify_annotation(annotation)\n+\n+    def format_annotation_new(self, annotation: Any) -> str:\n+        \"\"\"format_annotation() for py37+\"\"\"\n+        return stringify_annotation(annotation)\n+\n+    def format_annotation_old(self, annotation: Any) -> str:\n+        \"\"\"format_annotation() for py36 or below\"\"\"\n+        return stringify_annotation(annotation)\n+\n+\n+def getdoc(obj: Any, attrgetter: Callable = safe_getattr,\n+           allow_inherited: bool = False, cls: Any = None, name: str = None) -> str:\n+    \"\"\"Get the docstring for the object.\n+\n+    This tries to obtain the docstring for some kind of objects additionally:\n+\n+    * partial functions\n+    * inherited docstring\n+    * inherited decorated methods\n+    \"\"\"\n+    doc = attrgetter(obj, '__doc__', None)\n+    if ispartial(obj) and doc == obj.__class__.__doc__:\n+        return getdoc(obj.func)\n+    elif doc is None and allow_inherited:\n+        doc = inspect.getdoc(obj)\n+\n+        if doc is None and cls:\n+            # inspect.getdoc() does not support some kind of inherited and decorated methods.\n+            # This tries to obtain the docstring from super classes.\n+            for basecls in getattr(cls, '__mro__', []):\n+                meth = safe_getattr(basecls, name, None)\n+                if meth is not None:\n+                    doc = inspect.getdoc(meth)\n+                    if doc:\n+                        break\n+\n+    return doc\n"
  },
  "django__django-12039": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12039",
    "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..658a559c20 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -84,7 +84,8 @@ class Columns(TableColumns):\n     def __str__(self):\n         def col_str(column, idx):\n             try:\n-                return self.quote_name(column) + self.col_suffixes[idx]\n+                suffix = self.col_suffixes[idx]\n+                return self.quote_name(column) + (' ' + suffix if suffix else '')\n             except IndexError:\n                 return self.quote_name(column)\n \n@@ -114,7 +115,9 @@ class IndexColumns(Columns):\n             # length as self.columns.\n             col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n             try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n+                suffix = self.col_suffixes[idx]\n+                if suffix:\n+                    col = '{} {}'.format(col, suffix)\n             except IndexError:\n                 pass\n             return col\n"
  },
  "django__django-12193": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12193",
    "model_patch": "diff --git a/django/contrib/postgres/forms/array.py b/django/contrib/postgres/forms/array.py\nindex 2e19cd574a..8a71558b41 100644\n--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -137,17 +137,22 @@ class SplitArrayWidget(forms.Widget):\n             self.widget.is_localized = self.is_localized\n         value = value or []\n         context['widget']['subwidgets'] = []\n-        final_attrs = self.build_attrs(attrs)\n-        id_ = final_attrs.get('id')\n+        base_attrs = self.build_attrs(attrs)\n+        id_ = base_attrs.get('id')\n         for i in range(max(len(value), self.size)):\n             try:\n                 widget_value = value[i]\n             except IndexError:\n                 widget_value = None\n+            # Build a fresh attrs dict for each subwidget so that widgets\n+            # which mutate the attrs passed into get_context (e.g.\n+            # CheckboxInput) don't leak state to subsequent widgets.\n             if id_:\n-                final_attrs = {**final_attrs, 'id': '%s_%s' % (id_, i)}\n+                iteration_attrs = {**base_attrs, 'id': '%s_%s' % (id_, i)}\n+            else:\n+                iteration_attrs = dict(base_attrs)\n             context['widget']['subwidgets'].append(\n-                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs)['widget']\n+                self.widget.get_context(name + '_%s' % i, widget_value, iteration_attrs)['widget']\n             )\n         return context\n \n"
  },
  "django__django-12276": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12276",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..2b2febf8b7 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -272,9 +272,6 @@ class Widget(metaclass=MediaDefiningClass):\n         \"\"\"\n         return id_\n \n-    def use_required_attribute(self, initial):\n-        return not self.is_hidden\n-\n \n class Input(Widget):\n     \"\"\"\n@@ -388,6 +385,10 @@ class FileInput(Input):\n         return name not in files\n \n \n+    def use_required_attribute(self, initial):\n+        \"\"\"Do not use the required attribute if there is initial file data.\"\"\"\n+        return super().use_required_attribute(initial) and not initial\n+\n FILE_INPUT_CONTRADICTION = object()\n \n \n@@ -451,9 +452,6 @@ class ClearableFileInput(FileInput):\n             return False\n         return upload\n \n-    def use_required_attribute(self, initial):\n-        return super().use_required_attribute(initial) and not initial\n-\n     def value_omitted_from_data(self, data, files, name):\n         return (\n             super().value_omitted_from_data(data, files, name) and\n@@ -686,9 +684,6 @@ class Select(ChoiceWidget):\n         value, _ = choice\n         return value is None or value == ''\n \n-    def use_required_attribute(self, initial):\n-        \"\"\"\n-        Don't render 'required' if the first <option> has a value, as that's\n         invalid HTML.\n         \"\"\"\n         use_required_attribute = super().use_required_attribute(initial)\n@@ -766,9 +761,6 @@ class CheckboxSelectMultiple(ChoiceWidget):\n     template_name = 'django/forms/widgets/checkbox_select.html'\n     option_template_name = 'django/forms/widgets/checkbox_option.html'\n \n-    def use_required_attribute(self, initial):\n-        # Don't use the 'required' attribute because browser validation would\n-        # require all checkboxes to be checked instead of at least one.\n         return False\n \n     def value_omitted_from_data(self, data, files, name):\n"
  },
  "django__django-12304": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12304",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex f48143ddaf..2fc3c53d9c 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -7,6 +7,8 @@ __all__ = ['Choices', 'IntegerChoices', 'TextChoices']\n \n class ChoicesMeta(enum.EnumMeta):\n     \"\"\"A metaclass for creating a enum choices.\"\"\"\n+    do_not_call_in_templates = True\n+\n \n     def __new__(metacls, classname, bases, classdict):\n         labels = []\n@@ -61,6 +63,8 @@ class ChoicesMeta(enum.EnumMeta):\n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n \n+    do_not_call_in_templates = True\n+\n     def __str__(self):\n         \"\"\"\n         Use value when cast to str, so that Choices set as model instance\n@@ -71,11 +75,15 @@ class Choices(enum.Enum, metaclass=ChoicesMeta):\n \n class IntegerChoices(int, Choices):\n     \"\"\"Class for creating enumerated integer choices.\"\"\"\n+    do_not_call_in_templates = True\n+\n     pass\n \n \n class TextChoices(str, Choices):\n     \"\"\"Class for creating enumerated string choices.\"\"\"\n+    do_not_call_in_templates = True\n+\n \n     def _generate_next_value_(name, start, count, last_values):\n         return name\n"
  },
  "django__django-12708": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12708",
    "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..f621db985c 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -403,8 +403,16 @@ class BaseDatabaseSchemaEditor:\n         meta_constraint_names = {constraint.name for constraint in model._meta.constraints}\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n         columns = [model._meta.get_field(field).column for field in fields]\n+        # Exclude only the meta names of the same type as the constraint being deleted.\n+        # If we're deleting a unique, exclude meta_constraint_names; if an index, exclude meta_index_names.\n+        if constraint_kwargs.get('unique'):\n+            exclude_names = meta_constraint_names\n+        elif constraint_kwargs.get('index'):\n+            exclude_names = meta_index_names\n+        else:\n+            exclude_names = meta_constraint_names | meta_index_names\n         constraint_names = self._constraint_names(\n-            model, columns, exclude=meta_constraint_names | meta_index_names,\n+            model, columns, exclude=exclude_names,\n             **constraint_kwargs\n         )\n         if len(constraint_names) != 1:\n"
  },
  "django__django-12774": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12774",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..c033ee1e44 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -689,8 +689,19 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+        if field_name != 'pk':\n+            field = self.model._meta.get_field(field_name)\n+            # Consider fields unique if declared unique=True or covered by a UniqueConstraint.\n+            try:\n+                from django.db.models.constraints import UniqueConstraint\n+            except Exception:\n+                UniqueConstraint = None\n+            is_unique = field.unique or (UniqueConstraint and any(\n+                isinstance(c, UniqueConstraint) and field_name in (c.fields or ())\n+                for c in getattr(self.model._meta, 'constraints', [])\n+            ))\n+            if not is_unique:\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n         if id_list is not None:\n             if not id_list:\n                 return {}\n"
  },
  "sphinx-doc__sphinx-10673": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10673",
    "model_patch": "diff --git a/sphinx/environment/adapters/toctree.py b/sphinx/environment/adapters/toctree.py\nindex 9678e3c7c..2e4e6b753 100644\n--- a/sphinx/environment/adapters/toctree.py\n+++ b/sphinx/environment/adapters/toctree.py\n@@ -163,9 +163,13 @@ class TocTree:\n                         logger.warning(__('toctree contains reference to document %r that '\n                                           'doesn\\'t have a title: no link will be generated'),\n                                        ref, location=toctreenode)\n-                except KeyError:\n+                                except KeyError:\n                     # this is raised if the included file does not exist\n-                    if excluded(self.env.doc2path(ref, False)):\n+                    # allow references to special generated pages (genindex, modindex, search)\n+                    if ref in ('genindex', 'modindex', 'search'):\n+                        # these are generated by builders; don't warn about them\n+                        continue\n+if excluded(self.env.doc2path(ref, False)):\n                         message = __('toctree contains reference to excluded document %r')\n                     elif not included(self.env.doc2path(ref, False)):\n                         message = __('toctree contains reference to non-included document %r')\n"
  },
  "sphinx-doc__sphinx-8551": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8551",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 79d7e4f46..030ade47c 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1139,7 +1139,45 @@ class PythonModuleIndex(Index):\n \n \n class PythonDomain(Domain):\n+\n+\n+    def process_field_xref(self, pnode):\n+        \"\"\"Attach current python context to pending_xref nodes created\n+        in doc fields so they resolve like explicit xrefs.\n+        \"\"\"\n+        try:\n+            env = pnode.document.settings.env\n+        except Exception:\n+            return\n+        mod = env.ref_context.get('py:module')\n+        cls = env.ref_context.get('py:class')\n+        if mod:\n+            pnode['py:module'] = mod\n+        if cls:\n+            pnode['py:class'] = cls\n+        # mark as refspecific so lookup prefers the current context\n+        if not pnode.hasattr('refspecific'):\n+            pnode['refspecific'] = True\n     \"\"\"Python language domain.\"\"\"\n+\n+    def process_field_xref(self, pnode):\n+        \"\"\"Attach current python context to pending_xref nodes created\n+        in doc fields so they resolve like explicit xrefs.\n+        \"\"\"\n+        try:\n+            env = pnode.document.settings.env\n+        except Exception:\n+            return\n+        mod = env.ref_context.get('py:module')\n+        cls = env.ref_context.get('py:class')\n+        if mod:\n+            pnode['py:module'] = mod\n+        if cls:\n+            pnode['py:class'] = cls\n+        # mark as refspecific so lookup prefers the current context\n+        if not pnode.hasattr('refspecific'):\n+            pnode['refspecific'] = True\n+\n     name = 'py'\n     label = 'Python'\n     object_types = {\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..29408c01d 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -902,9 +902,9 @@ def _recombine_set_tokens(tokens: List[str]) -> List[str]:\n                 yield previous_token\n                 previous_token = None\n \n-            if token == \"{\":\n+            if token in (\"{\", \"(\"):\n                 open_braces += 1\n-            elif token == \"}\":\n+            elif token in (\"}\", \")\"):\n                 open_braces -= 1\n \n             yield token\n@@ -919,7 +919,7 @@ def _recombine_set_tokens(tokens: List[str]) -> List[str]:\n             except IndexError:\n                 break\n \n-            if token == \"{\":\n+            if token in (\"{\", \"(\"):\n                 tokens.appendleft(\"{\")\n                 yield \"\".join(takewhile_set(tokens))\n             else:\n"
  },
  "sphinx-doc__sphinx-9281": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9281",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex a415a7074..51d960c21 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -457,6 +457,16 @@ def object_description(object: Any) -> str:\n         else:\n             return \"frozenset({%s})\" % \", \".join(object_description(x)\n                                                  for x in sorted_values)\n+    # Render Enum members in a human-friendly way, e.g. MyEnum.Value\n+    if isinstance(object, enum.Enum):\n+        try:\n+            cls = object.__class__\n+            # Use qualified name if available to avoid ambiguity\n+            name = getattr(cls, \"__name__\", cls.__qualname__ if hasattr(cls,\"__qualname__\") else str(cls))\n+            return f\"{name}.{object.name}\"\n+        except Exception:\n+            pass\n+\n     try:\n         s = repr(object)\n     except Exception as exc:\n"
  }
}