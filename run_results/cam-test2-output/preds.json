{
  "django__django-11790": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11790",
    "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..c6cc50d731 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -189,9 +189,13 @@ class AuthenticationForm(forms.Form):\n         self.user_cache = None\n         super().__init__(*args, **kwargs)\n \n+        # Set the max length and label for the \"username\" field.\n         # Set the max length and label for the \"username\" field.\n         self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n-        self.fields['username'].max_length = self.username_field.max_length or 254\n+        max_length = self.username_field.max_length or 254\n+        self.fields['username'].max_length = max_length\n+        if hasattr(self.fields['username'], 'widget') and not self.fields['username'].widget.is_hidden:\n+            self.fields['username'].widget.attrs.setdefault('maxlength', str(max_length))\n         if self.fields['username'].label is None:\n             self.fields['username'].label = capfirst(self.username_field.verbose_name)\n \ndiff --git a/edge_test_username_maxlength_edgecases.py b/edge_test_username_maxlength_edgecases.py\nnew file mode 100644\nindex 0000000000..2da6bfbda0\n--- /dev/null\n+++ b/edge_test_username_maxlength_edgecases.py\n@@ -0,0 +1,48 @@\n+\n+import sys\n+from types import SimpleNamespace\n+from django.conf import settings\n+settings.configure(\n+    INSTALLED_APPS=['django.contrib.auth','django.contrib.contenttypes'],\n+    SECRET_KEY='testkey',\n+)\n+import django\n+django.setup()\n+from django.contrib.auth.forms import AuthenticationForm, UsernameField\n+from django import forms\n+from django.contrib.auth import get_user_model\n+\n+UserModel = get_user_model()\n+\n+# 1) Simulate username field with max_length=None -> expect default 254 applied to widget\n+original_get_field = UserModel._meta.get_field\n+def fake_get_field_none(name):\n+    return SimpleNamespace(max_length=None, verbose_name='username')\n+UserModel._meta.get_field = fake_get_field_none\n+form1 = AuthenticationForm()\n+attrs1 = form1.fields['username'].widget.attrs\n+ok1 = attrs1.get('maxlength') == '254'\n+\n+# Restore real get_field for next tests\n+UserModel._meta.get_field = original_get_field\n+\n+# 2) Hidden widget should not receive maxlength\n+class HiddenUsernameForm(AuthenticationForm):\n+    username = UsernameField(widget=forms.HiddenInput())\n+form2 = HiddenUsernameForm()\n+attrs2 = form2.fields['username'].widget.attrs\n+ok2 = 'maxlength' not in attrs2\n+\n+# 3) Existing maxlength should be preserved (setdefault behavior)\n+class PresetMaxForm(AuthenticationForm):\n+    username = UsernameField(widget=forms.TextInput(attrs={'maxlength': '5'}))\n+form3 = PresetMaxForm()\n+attrs3 = form3.fields['username'].widget.attrs\n+ok3 = attrs3.get('maxlength') == '5'\n+\n+print(\"test_default_fallback:\", ok1, \"value:\", attrs1.get('maxlength'))\n+print(\"test_hidden_widget:\", ok2, \"attrs:\", attrs2)\n+print(\"test_preserve_existing:\", ok3, \"value:\", attrs3.get('maxlength'))\n+\n+if not (ok1 and ok2 and ok3):\n+    sys.exit(2)\ndiff --git a/verify_auth_form_maxlength.py b/verify_auth_form_maxlength.py\nnew file mode 100644\nindex 0000000000..75d48a1e92\n--- /dev/null\n+++ b/verify_auth_form_maxlength.py\n@@ -0,0 +1,15 @@\n+\n+import sys\n+from django.conf import settings\n+settings.configure(\n+    INSTALLED_APPS=['django.contrib.auth','django.contrib.contenttypes'],\n+    SECRET_KEY='testkey',\n+)\n+import django\n+django.setup()\n+from django.contrib.auth.forms import AuthenticationForm\n+form = AuthenticationForm()\n+attrs = form.fields['username'].widget.attrs\n+print(\"maxlength\" in attrs, attrs.get(\"maxlength\"))\n+if \"maxlength\" not in attrs:\n+    sys.exit(2)\n\n"
  },
  "django__django-11815": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11815",
    "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..2884b61896 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,9 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        name_string, name_imports = serializer_factory(self.value.name).serialize()\n+        imports = {'import %s' % module, *name_imports}\n+        return \"%s.%s[%s]\" % (module, enum_class.__name__, name_string), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\ndiff --git a/mymod.py b/mymod.py\nnew file mode 100644\nindex 0000000000..aac05c9ce1\n--- /dev/null\n+++ b/mymod.py\n@@ -0,0 +1,6 @@\n+from enum import Enum\n+class Status(Enum):\n+    GOOD = 'Good'\n+    BAD = 'Bad'\n+    def __str__(self):\n+        return self.name\ndiff --git a/repro_enum_serializer.py b/repro_enum_serializer.py\nnew file mode 100644\nindex 0000000000..780bfc9116\n--- /dev/null\n+++ b/repro_enum_serializer.py\n@@ -0,0 +1,12 @@\n+\n+from enum import Enum\n+from django.utils.translation import gettext_lazy as _\n+from django.db.migrations.serializer import serializer_factory\n+\n+class Status(Enum):\n+    GOOD = _('Good')\n+    BAD = _('Bad')\n+    def __str__(self):\n+        return self.name\n+\n+print(serializer_factory(Status.GOOD).serialize())\ndiff --git a/repro_enum_serializer_lazy.py b/repro_enum_serializer_lazy.py\nnew file mode 100644\nindex 0000000000..3f297fdcd2\n--- /dev/null\n+++ b/repro_enum_serializer_lazy.py\n@@ -0,0 +1,14 @@\n+\n+from django.conf import settings\n+settings.configure(USE_I18N=True)\n+from django.utils.translation import gettext_lazy as _\n+from enum import Enum\n+from django.db.migrations.serializer import serializer_factory\n+\n+class Status(Enum):\n+    GOOD = _('Good')\n+    BAD = _('Bad')\n+    def __str__(self):\n+        return self.name\n+\n+print(serializer_factory(Status.GOOD).serialize())\ndiff --git a/repro_enum_serializer_simple.py b/repro_enum_serializer_simple.py\nnew file mode 100644\nindex 0000000000..1cfc8acbea\n--- /dev/null\n+++ b/repro_enum_serializer_simple.py\n@@ -0,0 +1,11 @@\n+\n+from enum import Enum\n+from django.db.migrations.serializer import serializer_factory\n+\n+class Status(Enum):\n+    GOOD = 'Good'\n+    BAD = 'Bad'\n+    def __str__(self):\n+        return self.name\n+\n+print(serializer_factory(Status.GOOD).serialize())\ndiff --git a/test_enum_serializer_cases.py b/test_enum_serializer_cases.py\nnew file mode 100644\nindex 0000000000..c13f75629d\n--- /dev/null\n+++ b/test_enum_serializer_cases.py\n@@ -0,0 +1,36 @@\n+\n+# create a module file with an Enum\n+with open(\"mymod.py\", \"w\") as f:\n+    f.write(\"\"\"from enum import Enum\n+class Status(Enum):\n+    GOOD = 'Good'\n+    BAD = 'Bad'\n+    def __str__(self):\n+        return self.name\n+\"\"\")\n+\n+from django.db.migrations.serializer import serializer_factory\n+from enum import Enum\n+\n+# Inline enum\n+class InlineStatus(Enum):\n+    YES = 'Yes'\n+    NO = 'No'\n+\n+# Module enum\n+import mymod\n+\n+# Numeric enum\n+class NumEnum(Enum):\n+    A = 1\n+    B = 2\n+\n+cases = [\n+    (\"inline\", InlineStatus.YES),\n+    (\"module\", mymod.Status.GOOD),\n+    (\"numeric\", NumEnum.A),\n+]\n+\n+for name, val in cases:\n+    s = serializer_factory(val).serialize()\n+    print(name, \"->\", s)\n\n"
  },
  "django__django-11848": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11848",
    "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..f7a9bbdc0f 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -173,13 +173,16 @@ def parse_http_date(date):\n             break\n     else:\n         raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n+\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            curr = datetime.datetime.utcnow().year\n+            century = curr - (curr % 100)\n+            candidate = century + year\n+            if candidate - curr > 50:\n+                candidate -= 100\n+            year = candidate\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\ndiff --git a/django/utils/tests/test_http_date_parse.py b/django/utils/tests/test_http_date_parse.py\nnew file mode 100644\nindex 0000000000..45d083b095\n--- /dev/null\n+++ b/django/utils/tests/test_http_date_parse.py\n@@ -0,0 +1,28 @@\n+import datetime\n+from django.utils import http\n+\n+def make_fixed_datetime(year):\n+    class FixedDatetime(datetime.datetime):\n+        @classmethod\n+        def utcnow(cls):\n+            return datetime.datetime(year, 1, 1)\n+    return FixedDatetime\n+\n+def test_two_digit_year_rfc7231_behavior():\n+    cases = [\n+        (2050, 80, 2080),\n+        (2000, 80, 1980),\n+        (2023, 23, 2023),\n+        (2023, 80, 1980),\n+        (2075, 24, 2024),  # candidate 2000+24=2024; curr 2075 => candidate-curr=-51 -> not >50 so 2024\n+    ]\n+    orig = http.datetime.datetime\n+    try:\n+        for curr, two, expected in cases:\n+            http.datetime.datetime = make_fixed_datetime(curr)\n+            date = f\\\"Sunday, 06-Nov-{two:02d} 08:49:37 GMT\\\"\n+            secs = http.parse_http_date(date)\n+            dt = datetime.datetime.utcfromtimestamp(secs)\n+            assert dt.year == expected, (curr, two, dt.year, expected)\n+    finally:\n+        http.datetime.datetime = orig\ndiff --git a/repro_parse_http_date.py b/repro_parse_http_date.py\nnew file mode 100644\nindex 0000000000..9e4405da8e\n--- /dev/null\n+++ b/repro_parse_http_date.py\n@@ -0,0 +1,31 @@\n+import datetime, sys\n+from django.utils import http\n+\n+orig_datetime = http.datetime.datetime\n+\n+def make_fixed_datetime(year):\n+    class FixedDatetime(datetime.datetime):\n+        @classmethod\n+        def utcnow(cls):\n+            return datetime.datetime(year, 1, 1)\n+    return FixedDatetime\n+\n+cases = [\n+    (2050, 80, 2080),\n+    (2000, 80, 1980),\n+    (2023, 23, 2023),\n+    (2023, 80, 1980),\n+]\n+\n+for curr_year, two_digit, expected in cases:\n+    http.datetime.datetime = make_fixed_datetime(curr_year)\n+    date = f\"Sunday, 06-Nov-{two_digit:02d} 08:49:37 GMT\"\n+    secs = http.parse_http_date(date)\n+    dt = datetime.datetime.utcfromtimestamp(secs)\n+    print(f\"curr={curr_year}, input={two_digit:02d} -> parsed={dt.year}, expected={expected}\")\n+    if dt.year != expected:\n+        print(\"FAIL\")\n+        sys.exit(1)\n+\n+http.datetime.datetime = orig_datetime\n+print(\"ALL_OK\")\n\n"
  },
  "django__django-11880": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11880",
    "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..4cc3133ca0 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -200,6 +200,7 @@ class Field:\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        result.error_messages = copy.deepcopy(self.error_messages, memo)\n         return result\n \n \ndiff --git a/test_deepcopy_error_messages.py b/test_deepcopy_error_messages.py\nnew file mode 100644\nindex 0000000000..94bf2c1694\n--- /dev/null\n+++ b/test_deepcopy_error_messages.py\n@@ -0,0 +1,19 @@\n+\n+from django.forms import CharField\n+import copy\n+\n+f1 = CharField(error_messages={'required': 'Please enter', 'invalid': 'Bad'})\n+f2 = copy.deepcopy(f1)\n+\n+print(\"Before mutation:\")\n+print(\"f1.error_messages:\", f1.error_messages)\n+print(\"f2.error_messages:\", f2.error_messages)\n+print(\"same dict object:\", f1.error_messages is f2.error_messages)\n+\n+f1.error_messages['required'] = 'Changed message'\n+f1.error_messages['new_key'] = 'New'\n+\n+print(\"\\nAfter mutation of f1:\")\n+print(\"f1.error_messages:\", f1.error_messages)\n+print(\"f2.error_messages:\", f2.error_messages)\n+print(\"same dict object:\", f1.error_messages is f2.error_messages)\ndiff --git a/test_form_instances_error_messages.py b/test_form_instances_error_messages.py\nnew file mode 100644\nindex 0000000000..00cb726f4d\n--- /dev/null\n+++ b/test_form_instances_error_messages.py\n@@ -0,0 +1,21 @@\n+\n+from django import forms\n+\n+class ProfileForm(forms.Form):\n+    name = forms.CharField(error_messages={'required': 'Please enter your name'})\n+\n+f1 = ProfileForm()\n+f2 = ProfileForm()\n+\n+print(\"Before mutation:\")\n+print(\"f1 field error_messages:\", f1.fields['name'].error_messages)\n+print(\"f2 field error_messages:\", f2.fields['name'].error_messages)\n+print(\"same dict object before:\", f1.fields['name'].error_messages is f2.fields['name'].error_messages)\n+\n+f1.fields['name'].error_messages['required'] = 'Changed for f1'\n+f1.fields['name'].error_messages['new_key'] = 'Added in f1'\n+\n+print(\"\\nAfter mutation on f1:\")\n+print(\"f1 field error_messages:\", f1.fields['name'].error_messages)\n+print(\"f2 field error_messages:\", f2.fields['name'].error_messages)\n+print(\"same dict object after:\", f1.fields['name'].error_messages is f2.fields['name'].error_messages)\ndiff --git a/test_form_instances_error_messages_configured.py b/test_form_instances_error_messages_configured.py\nnew file mode 100644\nindex 0000000000..037c720aa7\n--- /dev/null\n+++ b/test_form_instances_error_messages_configured.py\n@@ -0,0 +1,27 @@\n+\n+from django.conf import settings\n+if not settings.configured:\n+    settings.configure(USE_I18N=False, SECRET_KEY='test', INSTALLED_APPS=[])\n+import django\n+django.setup()\n+\n+from django import forms\n+\n+class ProfileForm(forms.Form):\n+    name = forms.CharField(error_messages={'required': 'Please enter your name'})\n+\n+f1 = ProfileForm()\n+f2 = ProfileForm()\n+\n+print(\"Before mutation:\")\n+print(\"f1 field error_messages:\", f1.fields['name'].error_messages)\n+print(\"f2 field error_messages:\", f2.fields['name'].error_messages)\n+print(\"same dict object before:\", f1.fields['name'].error_messages is f2.fields['name'].error_messages)\n+\n+f1.fields['name'].error_messages['required'] = 'Changed for f1'\n+f1.fields['name'].error_messages['new_key'] = 'Added in f1'\n+\n+print(\"\\nAfter mutation on f1:\")\n+print(\"f1 field error_messages:\", f1.fields['name'].error_messages)\n+print(\"f2 field error_messages:\", f2.fields['name'].error_messages)\n+print(\"same dict object after:\", f1.fields['name'].error_messages is f2.fields['name'].error_messages)\n\n"
  },
  "django__django-11885": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11885",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..04584ab94a 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -4,6 +4,7 @@ from operator import attrgetter\n \n from django.db import IntegrityError, connections, transaction\n from django.db.models import signals, sql\n+from django.db.models.query_utils import Q\n \n \n class ProtectedError(IntegrityError):\n@@ -191,7 +192,7 @@ class Collector:\n         If 'keep_parents' is True, data of parent model's will be not deleted.\n         \"\"\"\n         if self.can_fast_delete(objs):\n-            self.fast_deletes.append(objs)\n+            self.fast_deletes.append((objs, None))\n             return\n         new_objs = self.add(objs, source, nullable,\n                             reverse_dependency=reverse_dependency)\n@@ -225,7 +226,7 @@ class Collector:\n                 for batch in batches:\n                     sub_objs = self.related_objects(related, batch)\n                     if self.can_fast_delete(sub_objs, from_field=field):\n-                        self.fast_deletes.append(sub_objs)\n+                        self.fast_deletes.append((sub_objs, field))\n                     else:\n                         related_model = related.related_model\n                         # Non-referenced fields can be deferred if no signal\n@@ -310,10 +311,34 @@ class Collector:\n                     )\n \n             # fast deletes\n-            for qs in self.fast_deletes:\n+            # Combine fast deletes by model and field to reduce DB round trips.\n+            combined = {}\n+            plain_qs = []\n+            for entry in self.fast_deletes:\n+                if isinstance(entry, tuple):\n+                    qs, field = entry\n+                else:\n+                    qs, field = entry, None\n+                if field is None:\n+                    plain_qs.append(qs)\n+                    continue\n+                model = qs.model\n+                fmap = combined.setdefault(model, {})\n+                fname = field.name\n+                pks = set(qs.values_list(model._meta.pk.name, flat=True))\n+                fmap.setdefault(fname, set()).update(pks)\n+            for model, fmap in combined.items():\n+                q_obj = None\n+                for fname, pks in fmap.items():\n+                    part = Q(**{\"%s__in\" % fname: list(pks)})\n+                    q_obj = part if q_obj is None else (q_obj | part)\n+                combined_qs = model._default_manager.filter(q_obj).order_by()\n+                plain_qs.append(combined_qs)\n+            for qs in plain_qs:\n                 count = qs._raw_delete(using=self.using)\n                 deleted_counter[qs.model._meta.label] += count\n \n+\n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n                 for (field, value), instances in instances_for_fieldvalues.items():\n\n"
  },
  "django__django-11951": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11951",
    "model_patch": "diff --git a/check_patch.py b/check_patch.py\nnew file mode 100644\nindex 0000000000..4600dfba16\n--- /dev/null\n+++ b/check_patch.py\n@@ -0,0 +1,8 @@\n+import sys\n+p='django/db/models/query.py'\n+s=open(p).read()\n+if 'batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size' in s:\n+    print('OK')\n+    sys.exit(0)\n+print('FAIL')\n+sys.exit(1)\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..92349cd0c5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,8 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+        max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n+        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n\n"
  },
  "django__django-11964": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11964",
    "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 189fb4fa44..5cd3e9e715 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -5,6 +5,7 @@ Factored out from django.db.models.query to avoid making the main module very\n large and/or so that they can be used by other modules without getting into\n circular import difficulties.\n \"\"\"\n+import enum\n import copy\n import functools\n import inspect\n@@ -136,7 +137,17 @@ class DeferredAttribute:\n                 instance.refresh_from_db(fields=[field_name])\n                 val = getattr(instance, field_name)\n             data[field_name] = val\n-        return data[field_name]\n+\n+    def __set__(self, instance, value):\n+        if instance is None:\n+            return\n+        try:\n+            import enum as _enum_mod\n+        except Exception:\n+            _enum_mod = None\n+        if _enum_mod is not None and isinstance(value, _enum_mod.Enum):\n+            value = value.value\n+        instance.__dict__[self.field.attname] = value\n \n     def _check_parent_chain(self, instance):\n         \"\"\"\ndiff --git a/repro_enum_set.py b/repro_enum_set.py\nnew file mode 100644\nindex 0000000000..7c1773785d\n--- /dev/null\n+++ b/repro_enum_set.py\n@@ -0,0 +1,22 @@\n+\n+from django.db.models.enums import TextChoices\n+from django.db.models.query_utils import DeferredAttribute\n+\n+class MyChoice(TextChoices):\n+    FIRST_CHOICE = \"first\", \"First\"\n+    SECOND_CHOICE = \"second\", \"Second\"\n+\n+class DummyField:\n+    def __init__(self, attname):\n+        self.attname = attname\n+\n+field = DummyField('my_str_value')\n+descriptor = DeferredAttribute(field)\n+\n+class Inst: pass\n+\n+inst = Inst()\n+descriptor.__set__(inst, MyChoice.FIRST_CHOICE)\n+print(type(inst.__dict__['my_str_value']).__name__, inst.__dict__['my_str_value'])\n+descriptor.__set__(inst, \"second\")\n+print(type(inst.__dict__['my_str_value']).__name__, inst.__dict__['my_str_value'])\n\n"
  },
  "django__django-11999": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11999",
    "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..63ddbbf89c 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,10 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            method_name = 'get_%s_display' % self.name\n+            if method_name not in cls.__dict__:\n+                setattr(cls, method_name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\ndiff --git a/run_repro.py b/run_repro.py\nnew file mode 100644\nindex 0000000000..1c23a25c29\n--- /dev/null\n+++ b/run_repro.py\n@@ -0,0 +1,16 @@\n+from django.conf import settings\n+settings.configure(INSTALLED_APPS=['django.contrib.contenttypes'], DATABASES={'default':{'ENGINE':'django.db.backends.sqlite3','NAME':':memory:'}}, USE_I18N=False)\n+import django\n+django.setup()\n+from django.db import models\n+class FooBar(models.Model):\n+    foo_bar = models.CharField(max_length=10, choices=[('1', 'foo'), ('2', 'bar')])\n+    def __str__(self):\n+        return self.get_foo_bar_display()\n+    def get_foo_bar_display(self):\n+        return \"something\"\n+    class Meta:\n+        app_label = 'myapp'\n+obj = FooBar(foo_bar='1')\n+print('get_foo_bar_display output:', obj.get_foo_bar_display())\n+print('str output:', str(obj))\ndiff --git a/run_repro2.py b/run_repro2.py\nnew file mode 100644\nindex 0000000000..f96f5bd3d2\n--- /dev/null\n+++ b/run_repro2.py\n@@ -0,0 +1,19 @@\n+from django.conf import settings\n+settings.configure(INSTALLED_APPS=['django.contrib.contenttypes'], DATABASES={'default':{'ENGINE':'django.db.backends.sqlite3','NAME':':memory:'}}, USE_I18N=False)\n+import django\n+django.setup()\n+from django.db import models\n+class Parent(models.Model):\n+    status = models.CharField(max_length=10, choices=[('a','A')])\n+    class Meta:\n+        app_label = 'myapp'\n+class Child(Parent):\n+    def get_status_display(self):\n+        return 'child override'\n+c = Child(status='a')\n+p = Parent(status='a')\n+print('child:', c.get_status_display())\n+print('parent:', p.get_status_display())\n+assert c.get_status_display() == 'child override'\n+assert p.get_status_display() == 'A'\n+print('OK')\ndiff --git a/run_repro3.py b/run_repro3.py\nnew file mode 100644\nindex 0000000000..d644a6284e\n--- /dev/null\n+++ b/run_repro3.py\n@@ -0,0 +1,21 @@\n+from django.conf import settings\n+settings.configure(INSTALLED_APPS=['django.contrib.contenttypes'], DATABASES={'default':{'ENGINE':'django.db.backends.sqlite3','NAME':':memory:'}}, USE_I18N=False)\n+import django\n+django.setup()\n+from django.db import models\n+class Parent(models.Model):\n+    status = models.CharField(max_length=10, choices=[('a','A')])\n+    class Meta:\n+        app_label = 'myapp'\n+class Child(Parent):\n+    def get_status_display(self):\n+        return 'child override'\n+    class Meta:\n+        app_label = 'myapp'\n+c = Child(status='a')\n+p = Parent(status='a')\n+print('child:', c.get_status_display())\n+print('parent:', p.get_status_display())\n+assert c.get_status_display() == 'child override'\n+assert p.get_status_display() == 'A'\n+print('OK')\ndiff --git a/tests/test_get_field_display.py b/tests/test_get_field_display.py\nnew file mode 100644\nindex 0000000000..a908d193f1\n--- /dev/null\n+++ b/tests/test_get_field_display.py\n@@ -0,0 +1,16 @@\n+from django.test import SimpleTestCase\n+from django.db import models\n+class Parent(models.Model):\n+    status = models.CharField(max_length=10, choices=[('a','A')])\n+    class Meta:\n+        app_label = 'tests'\n+class Child(Parent):\n+    def get_status_display(self):\n+        return 'child override'\n+class TestGetFieldDisplay(SimpleTestCase):\n+    def test_override_in_subclass(self):\n+        c = Child(status='a')\n+        self.assertEqual(c.get_status_display(), 'child override')\n+    def test_parent_default(self):\n+        p = Parent(status='a')\n+        self.assertEqual(p.get_status_display(), 'A')\n\n"
  },
  "django__django-12039": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12039",
    "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..567441fef7 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -110,14 +110,20 @@ class IndexColumns(Columns):\n \n     def __str__(self):\n         def col_str(column, idx):\n-            # Index.__init__() guarantees that self.opclasses is the same\n-            # length as self.columns.\n-            col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n+            base = self.quote_name(column)\n             try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n+                op = self.opclasses[idx]\n             except IndexError:\n-                pass\n-            return col\n+                op = ''\n+            if op:\n+                base = '{} {}'.format(base, op)\n+            try:\n+                suffix = self.col_suffixes[idx]\n+            except IndexError:\n+                suffix = ''\n+            if suffix:\n+                base = '{}{}'.format(base, suffix)\n+            return base\n \n         return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \ndiff --git a/edge_repro_indexcolumns.py b/edge_repro_indexcolumns.py\nnew file mode 100644\nindex 0000000000..0251ffa10f\n--- /dev/null\n+++ b/edge_repro_indexcolumns.py\n@@ -0,0 +1,33 @@\n+from django.db.backends.ddl_references import IndexColumns\n+\n+def quote_name(x):\n+    return '\"%s\"' % x\n+\n+cases = [\n+    (['name'], [''], ['text_pattern_ops']),\n+    (['name'], [' DESC'], ['text_pattern_ops']),\n+    (['name'], [' DESC'], []),\n+    (['name'], [''], []),\n+    (['a','b'], ['',' DESC'], ['text_pattern_ops','']),\n+    (['a','b'], ['',''], ['']),\n+    (['a','b','c'], ['','',''], ['op1','op2','']),\n+    (['a'], [''], ['']),\n+]\n+\n+errors = []\n+for cols, col_suffixes, opclasses in cases:\n+    ic = IndexColumns('schema_author', cols, quote_name, col_suffixes=col_suffixes, opclasses=opclasses)\n+    s = str(ic)\n+    if s.endswith(' '):\n+        errors.append((\"trailing_space\", cols, col_suffixes, opclasses, s))\n+    if '  ' in s:\n+        errors.append((\"double_space\", cols, col_suffixes, opclasses, s))\n+    print(cols, col_suffixes, opclasses, \"->\", s)\n+\n+if errors:\n+    print(\"ERRORS FOUND:\")\n+    for e in errors:\n+        print(e)\n+    raise SystemExit(1)\n+else:\n+    print(\"All checks passed.\")\ndiff --git a/repro_indexcolumns.py b/repro_indexcolumns.py\nnew file mode 100644\nindex 0000000000..65f1cc808d\n--- /dev/null\n+++ b/repro_indexcolumns.py\n@@ -0,0 +1,15 @@\n+from django.db.backends.ddl_references import IndexColumns\n+\n+def quote_name(x):\n+    return '\"%s\"' % x\n+\n+cases = [\n+    (\"opclass_no_suffix\", ['name'], [''], ['text_pattern_ops']),\n+    (\"opclass_with_desc\", ['name'], [' DESC'], ['text_pattern_ops']),\n+    (\"no_opclass_with_suffix\", ['name'], [' DESC'], []),\n+    (\"no_opclass_no_suffix\", ['name'], [''], []),\n+]\n+\n+for name, cols, col_suffixes, opclasses in cases:\n+    ic = IndexColumns('schema_author', cols, quote_name, col_suffixes=col_suffixes, opclasses=opclasses)\n+    print(name + \" -> \" + str(ic))\n\n"
  },
  "django__django-12050": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12050",
    "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..d8d22c2552 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1073,7 +1073,14 @@ class Query(BaseExpression):\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n-            value = tuple(resolved_values)\n+            try:\n+                value = type(value)(resolved_values)\n+            except Exception:\n+                if isinstance(value, tuple):\n+                    value = tuple(resolved_values)\n+                else:\n+                    value = list(resolved_values)\n+\n         return value\n \n     def solve_lookup_type(self, lookup):\ndiff --git a/repro_resolve_lookup_value.py b/repro_resolve_lookup_value.py\nnew file mode 100644\nindex 0000000000..a752244630\n--- /dev/null\n+++ b/repro_resolve_lookup_value.py\n@@ -0,0 +1,22 @@\n+\n+from django.db.models.sql.query import Query\n+class MyList(list):\n+    pass\n+\n+q = Query(model=None)\n+l = [1, 2]\n+t = (3, 4)\n+m = MyList([5, 6])\n+\n+res_l = q.resolve_lookup_value(l, can_reuse=None, allow_joins=False, simple_col=None)\n+res_t = q.resolve_lookup_value(t, can_reuse=None, allow_joins=False, simple_col=None)\n+res_m = q.resolve_lookup_value(m, can_reuse=None, allow_joins=False, simple_col=None)\n+\n+print(type(res_l).__name__, res_l)\n+print(type(res_t).__name__, res_t)\n+print(type(res_m).__name__, res_m)\n+\n+assert isinstance(res_l, list), \"list input was not preserved as list\"\n+assert isinstance(res_t, tuple), \"tuple input was not preserved as tuple\"\n+assert isinstance(res_m, MyList), \"custom list subclass was not preserved\"\n+print(\"OK\")\ndiff --git a/repro_resolve_lookup_value_edges.py b/repro_resolve_lookup_value_edges.py\nnew file mode 100644\nindex 0000000000..5872915ba7\n--- /dev/null\n+++ b/repro_resolve_lookup_value_edges.py\n@@ -0,0 +1,20 @@\n+\n+# Additional edge tests for resolve_lookup_value\n+from django.db.models.sql.query import Query\n+class CustomTuple(tuple):\n+    pass\n+class CustomSeq(list):\n+    pass\n+\n+q = Query(model=None)\n+inputs = [\n+    ([1], list),\n+    ((1,), tuple),\n+    (CustomSeq([1,2]), CustomSeq),\n+    (CustomTuple((3,4)), CustomTuple),\n+]\n+for value, expected_type in inputs:\n+    res = q.resolve_lookup_value(value, can_reuse=None, allow_joins=False, simple_col=None)\n+    print(type(value).__name__, '->', type(res).__name__)\n+    assert isinstance(res, expected_type), f'Expected {expected_type} but got {type(res)}'\n+print('EDGE OK')\n\n"
  },
  "django__django-12143": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12143",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..effc5e9296 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1631,7 +1631,7 @@ class ModelAdmin(BaseModelAdmin):\n \n     def _get_edited_object_pks(self, request, prefix):\n         \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), re.escape(self.model._meta.pk.name)))\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\ndiff --git a/repro_pk_pattern.py b/repro_pk_pattern.py\nnew file mode 100644\nindex 0000000000..2c61740d2a\n--- /dev/null\n+++ b/repro_pk_pattern.py\n@@ -0,0 +1,24 @@\n+\n+import re, sys\n+prefix = \"a.b\"\n+pk = \"id\"\n+raw_pat = re.compile(r'{}-\\d+-{}$'.format(prefix, pk))\n+escaped_pat = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), re.escape(pk)))\n+tests = [\n+    (\"a.b-123-id\", True, True),\n+    (\"a_b-123-id\", True, False),  # raw pattern wrongly matches because '.' is any char\n+    (\"aXb-456-id\", True, False),  # raw pattern matches 'aXb' due to '.', escaped should not\n+]\n+ok = True\n+out = []\n+for key, raw_expected, esc_expected in tests:\n+    raw_m = bool(raw_pat.match(key))\n+    esc_m = bool(escaped_pat.match(key))\n+    out.append((key, raw_m, esc_m))\n+    if raw_m != raw_expected or esc_m != esc_expected:\n+        ok = False\n+for line in out:\n+    print(line)\n+print(\"OK\" if ok else \"FAIL\")\n+if not ok:\n+    sys.exit(2)\n\n"
  },
  "django__django-12155": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12155",
    "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..be22852599 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,8 +34,16 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n-    trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n+    if len(lines) == 1:\n+        return lines[0].strip()\n+    indents = [len(line) - len(line.lstrip()) for line in lines[1:] if line.lstrip()]\n+    nonzero_indents = [i for i in indents if i > 0]\n+    indent = min(nonzero_indents) if nonzero_indents else 0\n+    trimmed = [lines[0].lstrip()]\n+    for line in lines[1:]:\n+        leading = len(line) - len(line.lstrip())\n+        remove = indent if leading >= indent else leading\n+        trimmed.append(line[remove:].rstrip())\n     return \"\\n\".join(trimmed).strip()\n \n \ndiff --git a/trim_docstring_more_tests.py b/trim_docstring_more_tests.py\nnew file mode 100644\nindex 0000000000..cb20258cc2\n--- /dev/null\n+++ b/trim_docstring_more_tests.py\n@@ -0,0 +1,21 @@\n+\n+from django.contrib.admindocs import utils\n+\n+def assert_equal(a, b):\n+    if a != b:\n+        print(\"FAIL\", repr(a), \"!=\", repr(b))\n+        raise SystemExit(1)\n+\n+# tabs expanded\n+doc1 = \"First.\\n\\tsecond\\n\\tthird\\n\"\n+assert_equal(utils.trim_docstring(doc1), \"First.\\nsecond\\nthird\")\n+\n+# no indent on subsequent lines\n+doc2 = \"Title\\nnoindent\\n    indented\\n\"\n+assert_equal(utils.trim_docstring(doc2), \"Title\\nnoindent\\nindented\")\n+\n+# only blanks after first\n+doc3 = \"Solo\\n    \\n   \\n\"\n+assert_equal(utils.trim_docstring(doc3), \"Solo\")\n+\n+print(\"OK\")\ndiff --git a/trim_docstring_test.py b/trim_docstring_test.py\nnew file mode 100644\nindex 0000000000..1eed711505\n--- /dev/null\n+++ b/trim_docstring_test.py\n@@ -0,0 +1,25 @@\n+\n+from django.contrib.admindocs import utils\n+\n+def assert_equal(a, b):\n+    if a != b:\n+        print(\"FAIL\", repr(a), \"!=\", repr(b))\n+        raise SystemExit(1)\n+\n+# single-line docstring (content on first line)\n+doc1 = \"test tests something.\\n\"\n+assert_equal(utils.trim_docstring(doc1), \"test tests something.\")\n+\n+# docstring with closing on next line (common triple-quoted style)\n+doc2 = \"test tests something.\\n\"\n+assert_equal(utils.trim_docstring(doc2), \"test tests something.\")\n+\n+# multiline with indentation on subsequent lines\n+doc3 = \"First line.\\n    second line\\n    third line\\n\"\n+assert_equal(utils.trim_docstring(doc3), \"First line.\\nsecond line\\nthird line\")\n+\n+# multiline where only first line has content and following are blank\n+doc4 = \"Alone.\\n\\n\"\n+assert_equal(utils.trim_docstring(doc4), \"Alone.\")\n+\n+print(\"OK\")\n\n"
  },
  "django__django-12193": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12193",
    "model_patch": "diff --git a/comprehensive_repro.py b/comprehensive_repro.py\nnew file mode 100644\nindex 0000000000..a07da215a4\n--- /dev/null\n+++ b/comprehensive_repro.py\n@@ -0,0 +1,56 @@\n+\n+import sys, types\n+from pathlib import Path\n+\n+pkg_root = Path('django')\n+modules = {\n+    'django': str(pkg_root.resolve()),\n+    'django.contrib': str((pkg_root / 'contrib').resolve()),\n+    'django.contrib.postgres': str((pkg_root / 'contrib' / 'postgres').resolve()),\n+    'django.contrib.postgres.forms': str((pkg_root / 'contrib' / 'postgres' / 'forms').resolve()),\n+}\n+for name, path in modules.items():\n+    m = types.ModuleType(name)\n+    m.__path__ = [path]\n+    sys.modules[name] = m\n+\n+import importlib\n+mod = importlib.import_module('django.contrib.postgres.forms.array')\n+from django import forms\n+SplitArrayWidget = mod.SplitArrayWidget\n+\n+def run_case(name, attrs, values, expected_checked_indices):\n+    widget_inst = SplitArrayWidget(forms.CheckboxInput(), size=4)\n+    widget_type = SplitArrayWidget(forms.CheckboxInput, size=4)\n+    results = []\n+    for w in (widget_inst, widget_type):\n+        context = w.get_context('field', values, attrs=attrs)\n+        ok = True\n+        for i, sub in enumerate(context['widget']['subwidgets']):\n+            a = sub.get('attrs', {})\n+            checked = a.get('checked', None)\n+            exp = True if i in expected_checked_indices else None\n+            if checked != exp:\n+                print(f\"FAIL {name} widget={type(w.widget)} index={i} checked={checked} expected={exp}\")\n+                ok = False\n+                break\n+        if ok:\n+            print(f\"PASS {name} widget={type(w.widget)}\")\n+        results.append(ok)\n+    return all(results)\n+\n+cases = [\n+    ('case1', {'id':'field_id'}, [True, False, False, False], [0]),\n+    ('case2', {'id':'f'}, [False, True, False, True], [1,3]),\n+    ('case3', None, [True, False, False, False], [0]),\n+    ('case4', {'id':'x','data-x':'y'}, [False,1,0,False], [1]),  # truthy values at index 1\n+    ('case5', None, [False, False, False, False], []),\n+    ('case6', {'id':'a'}, [True, True, False, True], [0,1,3]),\n+]\n+\n+all_ok = True\n+for name, attrs, values, expected in cases:\n+    ok = run_case(name, attrs, values, expected)\n+    all_ok = all_ok and ok\n+\n+print(\"ALL OK\" if all_ok else \"SOME FAILURES\")\ndiff --git a/comprehensive_repro_fixed.py b/comprehensive_repro_fixed.py\nnew file mode 100644\nindex 0000000000..a95968ee85\n--- /dev/null\n+++ b/comprehensive_repro_fixed.py\n@@ -0,0 +1,56 @@\n+\n+import sys, types\n+from pathlib import Path\n+\n+pkg_root = Path('django')\n+modules = {\n+    'django': str(pkg_root.resolve()),\n+    'django.contrib': str((pkg_root / 'contrib').resolve()),\n+    'django.contrib.postgres': str((pkg_root / 'contrib' / 'postgres').resolve()),\n+    'django.contrib.postgres.forms': str((pkg_root / 'contrib' / 'postgres' / 'forms').resolve()),\n+}\n+for name, path in modules.items():\n+    m = types.ModuleType(name)\n+    m.__path__ = [path]\n+    sys.modules[name] = m\n+\n+import importlib\n+mod = importlib.import_module('django.contrib.postgres.forms.array')\n+from django import forms\n+SplitArrayWidget = mod.SplitArrayWidget\n+\n+def run_case(name, attrs, values, expected_checked_indices):\n+    widget_inst = SplitArrayWidget(forms.CheckboxInput(), size=4)\n+    widget_type = SplitArrayWidget(forms.CheckboxInput, size=4)\n+    results = []\n+    for w in (widget_inst, widget_type):\n+        context = w.get_context('field', values, attrs=attrs)\n+        ok = True\n+        for i, sub in enumerate(context['widget']['subwidgets']):\n+            a = sub.get('attrs', {})\n+            checked = a.get('checked', None)\n+            exp = True if i in expected_checked_indices else None\n+            if checked != exp:\n+                print(f\"FAIL {name} widget={type(w.widget)} index={i} checked={checked} expected={exp}\")\n+                ok = False\n+                break\n+        if ok:\n+            print(f\"PASS {name} widget={type(w.widget)}\")\n+        results.append(ok)\n+    return all(results)\n+\n+cases = [\n+    ('case1', {'id':'field_id'}, [True, False, False, False], [0]),\n+    ('case2', {'id':'f'}, [False, True, False, True], [1,3]),\n+    ('case3', None, [True, False, False, False], [0]),\n+    ('case4', {'id':'x','data-x':'y'}, [False,1,0,False], [1,2]),  # 0 is treated as checked by default boolean_check\n+    ('case5', None, [False, False, False, False], []),\n+    ('case6', {'id':'a'}, [True, True, False, True], [0,1,3]),\n+]\n+\n+all_ok = True\n+for name, attrs, values, expected in cases:\n+    ok = run_case(name, attrs, values, expected)\n+    all_ok = all_ok and ok\n+\n+print(\"ALL OK\" if all_ok else \"SOME FAILURES\")\ndiff --git a/django/contrib/postgres/forms/array.py b/django/contrib/postgres/forms/array.py\nindex 2e19cd574a..41d114d29c 100644\n--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -137,17 +137,18 @@ class SplitArrayWidget(forms.Widget):\n             self.widget.is_localized = self.is_localized\n         value = value or []\n         context['widget']['subwidgets'] = []\n-        final_attrs = self.build_attrs(attrs)\n-        id_ = final_attrs.get('id')\n+        base_attrs = self.build_attrs(attrs)\n+        id_ = base_attrs.get('id')\n         for i in range(max(len(value), self.size)):\n             try:\n                 widget_value = value[i]\n             except IndexError:\n                 widget_value = None\n+            sub_attrs = dict(base_attrs)\n             if id_:\n-                final_attrs = {**final_attrs, 'id': '%s_%s' % (id_, i)}\n+                sub_attrs['id'] = '%s_%s' % (id_, i)\n             context['widget']['subwidgets'].append(\n-                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs)['widget']\n+                self.widget.get_context(name + '_%s' % i, widget_value, sub_attrs)['widget']\n             )\n         return context\n \ndiff --git a/repro_splitarray_checkbox.py b/repro_splitarray_checkbox.py\nnew file mode 100644\nindex 0000000000..a0c31394e3\n--- /dev/null\n+++ b/repro_splitarray_checkbox.py\n@@ -0,0 +1,9 @@\n+\n+from django import forms\n+from django.contrib.postgres.forms.array import SplitArrayWidget\n+\n+widget = SplitArrayWidget(forms.CheckboxInput(), size=4)\n+context = widget.get_context('field', [True, False, False, False], attrs={'id': 'field_id'})\n+for i, sub in enumerate(context['widget']['subwidgets']):\n+    attrs = sub.get('attrs', {})\n+    print(i, attrs.get('id'), attrs.get('checked', None))\ndiff --git a/repro_splitarray_checkbox_direct.py b/repro_splitarray_checkbox_direct.py\nnew file mode 100644\nindex 0000000000..7e00c54259\n--- /dev/null\n+++ b/repro_splitarray_checkbox_direct.py\n@@ -0,0 +1,19 @@\n+\n+import importlib.util\n+import sys\n+from pathlib import Path\n+\n+module_path = Path('django/contrib/postgres/forms/array.py').resolve()\n+spec = importlib.util.spec_from_file_location('pg_array_module', str(module_path))\n+pg_array = importlib.util.module_from_spec(spec)\n+sys.modules['pg_array_module'] = pg_array\n+spec.loader.exec_module(pg_array)\n+\n+from django import forms\n+SplitArrayWidget = pg_array.SplitArrayWidget\n+\n+widget = SplitArrayWidget(forms.CheckboxInput(), size=4)\n+context = widget.get_context('field', [True, False, False, False], attrs={'id': 'field_id'})\n+for i, sub in enumerate(context['widget']['subwidgets']):\n+    attrs = sub.get('attrs', {})\n+    print(i, attrs.get('id'), attrs.get('checked', None))\ndiff --git a/repro_splitarray_checkbox_pkg.py b/repro_splitarray_checkbox_pkg.py\nnew file mode 100644\nindex 0000000000..2555fd962a\n--- /dev/null\n+++ b/repro_splitarray_checkbox_pkg.py\n@@ -0,0 +1,14 @@\n+\n+import sys\n+from pathlib import Path\n+sys.path.insert(0, str(Path('.').resolve()))\n+import importlib\n+mod = importlib.import_module('django.contrib.postgres.forms.array')\n+from django import forms\n+SplitArrayWidget = mod.SplitArrayWidget\n+\n+widget = SplitArrayWidget(forms.CheckboxInput(), size=4)\n+context = widget.get_context('field', [True, False, False, False], attrs={'id': 'field_id'})\n+for i, sub in enumerate(context['widget']['subwidgets']):\n+    attrs = sub.get('attrs', {})\n+    print(i, attrs.get('id'), attrs.get('checked', None))\ndiff --git a/repro_splitarray_checkbox_pkg2.py b/repro_splitarray_checkbox_pkg2.py\nnew file mode 100644\nindex 0000000000..0096373a7f\n--- /dev/null\n+++ b/repro_splitarray_checkbox_pkg2.py\n@@ -0,0 +1,25 @@\n+\n+import sys, types\n+from pathlib import Path\n+pkg_root = Path('django')\n+modules = {\n+    'django': str(pkg_root.resolve()),\n+    'django.contrib': str((pkg_root / 'contrib').resolve()),\n+    'django.contrib.postgres': str((pkg_root / 'contrib' / 'postgres').resolve()),\n+    'django.contrib.postgres.forms': str((pkg_root / 'contrib' / 'postgres' / 'forms').resolve()),\n+}\n+for name, path in modules.items():\n+    m = types.ModuleType(name)\n+    m.__path__ = [path]\n+    sys.modules[name] = m\n+\n+import importlib\n+mod = importlib.import_module('django.contrib.postgres.forms.array')\n+from django import forms\n+SplitArrayWidget = mod.SplitArrayWidget\n+\n+widget = SplitArrayWidget(forms.CheckboxInput(), size=4)\n+context = widget.get_context('field', [True, False, False, False], attrs={'id': 'field_id'})\n+for i, sub in enumerate(context['widget']['subwidgets']):\n+    attrs = sub.get('attrs', {})\n+    print(i, attrs.get('id'), attrs.get('checked', None))\n\n"
  },
  "django__django-12209": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12209",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..b8cbc11ae7 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -840,17 +840,20 @@ class Model(metaclass=ModelBase):\n                        if f.name in update_fields or f.attname in update_fields]\n \n         pk_val = self._get_pk_val(meta)\n-        if pk_val is None:\n+        pk_was_unset = pk_val is None\n+        if pk_was_unset:\n             pk_val = meta.pk.get_pk_value_on_save(self)\n             setattr(self, meta.pk.attname, pk_val)\n         pk_set = pk_val is not None\n         if not pk_set and (force_update or update_fields):\n             raise ValueError(\"Cannot force an update in save() with no primary key.\")\n         updated = False\n-        # Skip an UPDATE when adding an instance and primary key has a default.\n+        # Skip an UPDATE when adding an instance and primary key has a default,\n+        # but only when the primary key wasn't explicitly set on the instance.\n         if (\n             not force_insert and\n             self._state.adding and\n+            pk_was_unset and\n             self._meta.pk.default and\n             self._meta.pk.default is not NOT_PROVIDED\n         ):\ndiff --git a/repro_uuid_save.py b/repro_uuid_save.py\nnew file mode 100644\nindex 0000000000..d5477cb929\n--- /dev/null\n+++ b/repro_uuid_save.py\n@@ -0,0 +1,34 @@\n+\n+from uuid import uuid4\n+from django.conf import settings\n+settings.configure(\n+    DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},\n+    INSTALLED_APPS=[],\n+    TIME_ZONE='UTC',\n+    USE_TZ=True,\n+)\n+import django\n+django.setup()\n+from django.db import models, connection, IntegrityError\n+\n+class Sample(models.Model):\n+    id = models.UUIDField(primary_key=True, default=uuid4)\n+    name = models.CharField(blank=True, max_length=100)\n+    class Meta:\n+        app_label = 'testapp'\n+\n+with connection.schema_editor() as schema_editor:\n+    schema_editor.create_model(Sample)\n+\n+# Create first instance (INSERT)\n+s0 = Sample.objects.create()\n+print(\"s0.pk:\", s0.pk)\n+\n+# Create second instance with same pk: expect UPDATE (no IntegrityError) historically,\n+# but if code does INSERT, IntegrityError occurs.\n+s1 = Sample(pk=s0.pk, name='Test 1')\n+try:\n+    s1.save()\n+    print(\"s1.save() completed without IntegrityError (UPDATE occurred).\")\n+except IntegrityError as e:\n+    print(\"IntegrityError on s1.save():\", e)\ndiff --git a/test_save_behavior.py b/test_save_behavior.py\nnew file mode 100644\nindex 0000000000..171a326df5\n--- /dev/null\n+++ b/test_save_behavior.py\n@@ -0,0 +1,36 @@\n+\n+import os\n+from uuid import uuid4\n+from django.conf import settings\n+settings.configure(\n+    DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},\n+    INSTALLED_APPS=[],\n+    TIME_ZONE='UTC',\n+    USE_TZ=True,\n+)\n+import django\n+django.setup()\n+from django.db import models, connection, IntegrityError\n+\n+class Sample(models.Model):\n+    id = models.UUIDField(primary_key=True, default=uuid4)\n+    name = models.CharField(blank=True, max_length=100)\n+    class Meta:\n+        app_label = 'testapp'\n+\n+with connection.schema_editor() as schema_editor:\n+    schema_editor.create_model(Sample)\n+\n+# Test 1: explicit PK should lead to UPDATE\n+s0 = Sample.objects.create()\n+s1 = Sample(pk=s0.pk, name='Test1')\n+try:\n+    s1.save()\n+    print('Test1: passed (UPDATE occurred)')\n+except IntegrityError:\n+    print('Test1: failed (INSERT attempted)')\n+\n+# Test 2: default PK generation path should insert new when no explicit pk given\n+s2 = Sample()\n+s2.save()\n+print('Test2: created s2.pk', s2.pk)\ndiff --git a/verify_pk_logic.py b/verify_pk_logic.py\nnew file mode 100644\nindex 0000000000..b18db7afd1\n--- /dev/null\n+++ b/verify_pk_logic.py\n@@ -0,0 +1,26 @@\n+\n+# Minimal logical check of modified condition without requiring DB.\n+def decision(pk_initial, has_default, state_adding, force_insert, force_update, update_fields):\n+    # simulate _get_pk_val(meta)\n+    pk_val = pk_initial\n+    pk_was_unset = pk_val is None\n+    if pk_was_unset:\n+        # simulate meta.pk.get_pk_value_on_save(self) producing a default value\n+        pk_val = 'DEFAULT'\n+    pk_set = pk_val is not None\n+    if not pk_set and (force_update or update_fields):\n+        raise ValueError(\"Cannot force an update in save() with no primary key.\")\n+    updated = False\n+    if (\n+        not force_insert and\n+        state_adding and\n+        pk_was_unset and\n+        has_default\n+    ):\n+        force_insert = True\n+    return {'pk_was_unset': pk_was_unset, 'pk_set': pk_set, 'force_insert': force_insert}\n+\n+print(\"Explicit PK provided case:\")\n+print(decision(pk_initial='EXPLICIT', has_default=True, state_adding=True, force_insert=False, force_update=False, update_fields=None))\n+print(\"No PK provided (default generated) case:\")\n+print(decision(pk_initial=None, has_default=True, state_adding=True, force_insert=False, force_update=False, update_fields=None))\n\n"
  },
  "django__django-12262": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12262",
    "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..85f5dc35fe 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -256,31 +256,22 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if not kwonly_defaults or kwarg not in kwonly_defaults\n     ]\n     for bit in bits:\n-        # First we try to extract a potential kwarg from the bit\n         kwarg = token_kwargs([bit], parser)\n         if kwarg:\n-            # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n-                # An unexpected keyword argument was supplied\n+            if param in kwargs:\n                 raise TemplateSyntaxError(\n-                    \"'%s' received unexpected keyword argument '%s'\" %\n+                    \"'%s' received multiple values for keyword argument '%s'\" %\n                     (name, param))\n-            elif param in kwargs:\n-                # The keyword argument has already been supplied once\n+            if param not in params and param not in kwonly and varkw is None:\n                 raise TemplateSyntaxError(\n-                    \"'%s' received multiple values for keyword argument '%s'\" %\n+                    \"'%s' received unexpected keyword argument '%s'\" %\n                     (name, param))\n-            else:\n-                # All good, record the keyword argument\n-                kwargs[str(param)] = value\n-                if param in unhandled_params:\n-                    # If using the keyword syntax for a positional arg, then\n-                    # consume it.\n-                    unhandled_params.remove(param)\n-                elif param in unhandled_kwargs:\n-                    # Same for keyword-only arguments\n-                    unhandled_kwargs.remove(param)\n+            kwargs[str(param)] = value\n+            if param in unhandled_params:\n+                unhandled_params.remove(param)\n+            elif param in unhandled_kwargs:\n+                unhandled_kwargs.remove(param)\n         else:\n             if kwargs:\n                 raise TemplateSyntaxError(\ndiff --git a/django/templatetags/test_tags.py b/django/templatetags/test_tags.py\nnew file mode 100644\nindex 0000000000..6e60357e87\n--- /dev/null\n+++ b/django/templatetags/test_tags.py\n@@ -0,0 +1,10 @@\n+from django.template import Library\n+register = Library()\n+\n+@register.simple_tag\n+def hello(*, greeting='hello'):\n+    return f'{greeting} world'\n+\n+@register.simple_tag\n+def hi(*, greeting):\n+    return f'{greeting} world'\ndiff --git a/repro_template_tags.py b/repro_template_tags.py\nnew file mode 100644\nindex 0000000000..fe5f400fd1\n--- /dev/null\n+++ b/repro_template_tags.py\n@@ -0,0 +1,25 @@\n+from django.conf import settings\n+if not settings.configured:\n+    settings.configure(\n+        TEMPLATES=[{\n+            'BACKEND': 'django.template.backends.django.DjangoTemplates',\n+            'APP_DIRS': False,\n+            'OPTIONS': {\n+                'libraries': {'test_tags': 'django.templatetags.test_tags'},\n+            },\n+        }],\n+    )\n+from django.template import Template, Context\n+from django.template.exceptions import TemplateSyntaxError\n+\n+templates = [\n+    (\"hello with default\", \"{% load test_tags %}{% hello greeting='hi' %}\"),\n+    (\"hi duplicate kw\", \"{% load test_tags %}{% hi greeting='hi' greeting='hello' %}\"),\n+]\n+\n+for name, tpl in templates:\n+    try:\n+        t = Template(tpl)\n+        print(name, \"->\", t.render(Context({})))\n+    except TemplateSyntaxError as e:\n+        print(name, \"raised TemplateSyntaxError:\", e)\ndiff --git a/repro_template_tags_engine.py b/repro_template_tags_engine.py\nnew file mode 100644\nindex 0000000000..b704d0e315\n--- /dev/null\n+++ b/repro_template_tags_engine.py\n@@ -0,0 +1,20 @@\n+from django.conf import settings\n+if not settings.configured:\n+    settings.configure()\n+from django.template.engine import Engine\n+from django.template import Template, Context\n+from django.template.exceptions import TemplateSyntaxError\n+\n+engine = Engine(app_dirs=False, libraries={'test_tags': 'django.templatetags.test_tags'})\n+\n+templates = [\n+    (\"hello with default\", \"{% load test_tags %}{% hello greeting='hi' %}\"),\n+    (\"hi duplicate kw\", \"{% load test_tags %}{% hi greeting='hi' greeting='hello' %}\"),\n+]\n+\n+for name, tpl in templates:\n+    try:\n+        t = Template(tpl, engine=engine)\n+        print(name, \"->\", t.render(Context({})))\n+    except TemplateSyntaxError as e:\n+        print(name, \"raised TemplateSyntaxError:\", e)\n\n"
  },
  "django__django-12273": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12273",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 844c01e95e..a6535d2eb1 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -803,8 +803,9 @@ class Model(metaclass=ModelBase):\n         meta = cls._meta\n         inserted = False\n         for parent, field in meta.parents.items():\n-            # Make sure the link fields are synced between parent and self.\n-            if (field and getattr(self, parent._meta.pk.attname) is None and\n+            # Only populate the parent's PK from the child link if the parent's\n+            # PK wasn't explicitly set on this instance (i.e. not present in __dict__).\n+            if (field and parent._meta.pk.attname not in self.__dict__ and\n                     getattr(self, field.attname) is not None):\n                 setattr(self, parent._meta.pk.attname, getattr(self, field.attname))\n             parent_inserted = self._save_parents(cls=parent, using=using, update_fields=update_fields)\ndiff --git a/repro.py b/repro.py\nnew file mode 100644\nindex 0000000000..e2ffcdb5dc\n--- /dev/null\n+++ b/repro.py\n@@ -0,0 +1,34 @@\n+\n+import os\n+from django.conf import settings\n+\n+BASE_DIR = os.path.dirname(__file__)\n+settings.configure(\n+    INSTALLED_APPS=['testapp'],\n+    DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},\n+    DEFAULT_AUTO_FIELD='django.db.models.AutoField',\n+)\n+import django\n+django.setup()\n+\n+from django.db import connection\n+from django.apps import apps\n+from testapp.models import Item, Derived\n+\n+# Create database tables for our models\n+with connection.schema_editor() as schema_editor:\n+    schema_editor.create_model(Item)\n+    schema_editor.create_model(Derived)\n+\n+# Reproduce the sequence from PR description\n+derived = Derived.objects.create(f=True)\n+print(\"Created Derived with pk:\", derived.pk, \"f:\", derived.f)\n+item = Item.objects.get(pk=derived.pk)\n+obj1 = item.derived\n+obj1.reset()\n+print(\"After reset, obj1.pk:\", obj1.pk, \"obj1.f:\", obj1.f, \"item.pk:\", item.pk)\n+obj1.save()\n+print(\"After save, original item's f (should remain True):\", Item.objects.get(pk=derived.pk).f)\n+# Check how many items exist\n+print(\"Total Item rows:\", Item.objects.count())\n+print(\"Total Derived rows:\", Derived.objects.count())\ndiff --git a/test_models.py b/test_models.py\nnew file mode 100644\nindex 0000000000..6948217fef\n--- /dev/null\n+++ b/test_models.py\n@@ -0,0 +1,28 @@\n+\n+import django\n+from django.conf import settings\n+import os\n+settings.configure(\n+    INSTALLED_APPS=['testapp'],\n+    DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},\n+    DEFAULT_AUTO_FIELD='django.db.models.AutoField',\n+)\n+django.setup()\n+from django.db import connection\n+from testapp.models import Item, Derived\n+from django.test import TestCase\n+\n+class SaveResetPKTestCase(TestCase):\n+    def setUp(self):\n+        with connection.schema_editor() as schema_editor:\n+            schema_editor.create_model(Item)\n+            schema_editor.create_model(Derived)\n+        self.derived = Derived.objects.create(f=True)\n+        item = Item.objects.get(pk=self.derived.pk)\n+        obj1 = item.derived\n+        obj1.reset()\n+        obj1.save()\n+\n+    def test_f_true(self):\n+        obj = Item.objects.get(pk=self.derived.pk)\n+        assert obj.f is True\ndiff --git a/testapp/__init__.py b/testapp/__init__.py\nnew file mode 100644\nindex 0000000000..e69de29bb2\ndiff --git a/testapp/models.py b/testapp/models.py\nnew file mode 100644\nindex 0000000000..8675861fcc\n--- /dev/null\n+++ b/testapp/models.py\n@@ -0,0 +1,12 @@\n+\n+from django.db import models\n+\n+class Item(models.Model):\n+    uid = models.AutoField(primary_key=True, editable=False)\n+    f = models.BooleanField(default=False)\n+    def reset(self):\n+        self.uid = None\n+        self.f = False\n+\n+class Derived(Item):\n+    pass\n\n"
  },
  "django__django-12276": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12276",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..02973499f6 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -379,11 +379,16 @@ class FileInput(Input):\n     def format_value(self, value):\n         \"\"\"File input never renders a value.\"\"\"\n         return\n+    def use_required_attribute(self, initial):\n+        return super().use_required_attribute(initial) and not initial\n+\n \n     def value_from_datadict(self, data, files, name):\n         \"File widgets take data from FILES, not POST\"\n         return files.get(name)\n \n+\n+\n     def value_omitted_from_data(self, data, files, name):\n         return name not in files\n \n@@ -451,8 +456,7 @@ class ClearableFileInput(FileInput):\n             return False\n         return upload\n \n-    def use_required_attribute(self, initial):\n-        return super().use_required_attribute(initial) and not initial\n+\n \n     def value_omitted_from_data(self, data, files, name):\n         return (\ndiff --git a/tests/test_use_required_attribute.py b/tests/test_use_required_attribute.py\nnew file mode 100644\nindex 0000000000..13faafbd59\n--- /dev/null\n+++ b/tests/test_use_required_attribute.py\n@@ -0,0 +1,20 @@\n+\n+from django.forms.widgets import FileInput, ClearableFileInput\n+\n+def assert_equal(a, b):\n+    if a != b:\n+        raise SystemExit('ASSERTION FAILED: {!r} != {!r}'.format(a, b))\n+\n+print('FileInput None:', FileInput().use_required_attribute(None))\n+assert_equal(FileInput().use_required_attribute(None), True)\n+\n+print('FileInput file:', FileInput().use_required_attribute('file'))\n+assert_equal(FileInput().use_required_attribute('file'), False)\n+\n+print('ClearableFileInput None:', ClearableFileInput().use_required_attribute(None))\n+assert_equal(ClearableFileInput().use_required_attribute(None), True)\n+\n+print('ClearableFileInput file:', ClearableFileInput().use_required_attribute('file'))\n+assert_equal(ClearableFileInput().use_required_attribute('file'), False)\n+\n+print('OK')\n\n"
  },
  "django__django-12304": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12304",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex f48143ddaf..8cb3da0665 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -59,6 +59,7 @@ class ChoicesMeta(enum.EnumMeta):\n \n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n+    do_not_call_in_templates = True\n     \"\"\"Class for creating enumerated choices.\"\"\"\n \n     def __str__(self):\ndiff --git a/django/template/base.py b/django/template/base.py\nindex 7efc45356c..e9651450f9 100644\n--- a/django/template/base.py\n+++ b/django/template/base.py\n@@ -51,6 +51,7 @@ times with multiple contexts)\n \"\"\"\n \n import inspect\n+import enum\n import logging\n import re\n from enum import Enum\n@@ -849,7 +850,7 @@ class Variable:\n                                                        \"[%s] in %r\",\n                                                        (bit, current))  # missing attribute\n                 if callable(current):\n-                    if getattr(current, 'do_not_call_in_templates', False):\n+                    if getattr(current, 'do_not_call_in_templates', False) or isinstance(current, enum.EnumMeta):\n                         pass\n                     elif getattr(current, 'alters_data', False):\n                         current = context.template.engine.string_if_invalid\ndiff --git a/final_verify.py b/final_verify.py\nnew file mode 100644\nindex 0000000000..f994ac3edc\n--- /dev/null\n+++ b/final_verify.py\n@@ -0,0 +1,10 @@\n+import enum\n+print('EnumMeta has attr:', getattr(enum.EnumMeta, 'do_not_call_in_templates', False))\n+from django.db.models import enums\n+print('Choices has attr:', getattr(enums.Choices, 'do_not_call_in_templates', False))\n+print('IntegerChoices has attr:', getattr(enums.IntegerChoices, 'do_not_call_in_templates', False))\n+print('TextChoices has attr:', getattr(enums.TextChoices, 'do_not_call_in_templates', False))\n+class YearInSchool(enums.TextChoices):\n+    FRESHMAN = 'FR'\n+print('YearInSchool class attr:', getattr(YearInSchool, 'do_not_call_in_templates', False))\n+print('Member attr on YearInSchool.FRESHMAN:', getattr(YearInSchool.FRESHMAN, 'do_not_call_in_templates', False))\ndiff --git a/final_verify_enum_meta.py b/final_verify_enum_meta.py\nnew file mode 100644\nindex 0000000000..86ab1e29e4\n--- /dev/null\n+++ b/final_verify_enum_meta.py\n@@ -0,0 +1,9 @@\n+import enum\n+print('EnumMeta attr:', getattr(enum.EnumMeta, 'do_not_call_in_templates', False))\n+from django.db.models import enums\n+print('Choices:', getattr(enums.Choices, 'do_not_call_in_templates', False))\n+print('IntegerChoices:', getattr(enums.IntegerChoices, 'do_not_call_in_templates', False))\n+print('TextChoices:', getattr(enums.TextChoices, 'do_not_call_in_templates', False))\n+class YearInSchool(enums.TextChoices):\n+    FRESHMAN = 'FR'\n+print('YearInSchool class attribute:', getattr(YearInSchool, 'do_not_call_in_templates', False))\ndiff --git a/quick_check_do_not_call.py b/quick_check_do_not_call.py\nnew file mode 100644\nindex 0000000000..1a73e3e75b\n--- /dev/null\n+++ b/quick_check_do_not_call.py\n@@ -0,0 +1,4 @@\n+from django.db.models import enums\n+print('Choices:', getattr(enums.Choices, 'do_not_call_in_templates', False))\n+print('IntegerChoices:', getattr(enums.IntegerChoices, 'do_not_call_in_templates', False))\n+print('TextChoices:', getattr(enums.TextChoices, 'do_not_call_in_templates', False))\ndiff --git a/quick_check_do_not_call_v2.py b/quick_check_do_not_call_v2.py\nnew file mode 100644\nindex 0000000000..31b2e5061b\n--- /dev/null\n+++ b/quick_check_do_not_call_v2.py\n@@ -0,0 +1,8 @@\n+from django.db.models import enums\n+print('Choices:', getattr(enums.Choices, 'do_not_call_in_templates', False))\n+print('IntegerChoices:', getattr(enums.IntegerChoices, 'do_not_call_in_templates', False))\n+print('TextChoices:', getattr(enums.TextChoices, 'do_not_call_in_templates', False))\n+class YearInSchool(enums.TextChoices):\n+    FRESHMAN = 'FR'\n+print('YearInSchool class attribute:', getattr(YearInSchool, 'do_not_call_in_templates', False))\n+print('Member attribute (should be False for instance):', getattr(YearInSchool.FRESHMAN, 'do_not_call_in_templates', False))\ndiff --git a/template_repro.py b/template_repro.py\nnew file mode 100644\nindex 0000000000..757e2d0d4c\n--- /dev/null\n+++ b/template_repro.py\n@@ -0,0 +1,9 @@\n+from django.template import Template, Context\n+from django.db import models\n+\n+class YearInSchool(models.TextChoices):\n+    FRESHMAN = 'FR'\n+\n+s = Template('{% if student.year_in_school == YearInSchool.FRESHMAN %}yes{% else %}no{% endif %}')\n+c = Context({'student': type('S',(object,),{'year_in_school':'FR'})(), 'YearInSchool': YearInSchool})\n+print(s.render(c))\ndiff --git a/verify_do_not_call.py b/verify_do_not_call.py\nnew file mode 100644\nindex 0000000000..eaef564ebe\n--- /dev/null\n+++ b/verify_do_not_call.py\n@@ -0,0 +1,8 @@\n+from django.db.models import enums\n+print('Choices:', getattr(enums.Choices, 'do_not_call_in_templates', False))\n+print('IntegerChoices:', getattr(enums.IntegerChoices, 'do_not_call_in_templates', False))\n+print('TextChoices:', getattr(enums.TextChoices, 'do_not_call_in_templates', False))\n+class YearInSchool(enums.TextChoices):\n+    FRESHMAN = 'FR'\n+print('YearInSchool class attribute:', getattr(YearInSchool, 'do_not_call_in_templates', False))\n+print('Member attribute:', getattr(YearInSchool.FRESHMAN, 'do_not_call_in_templates', False))\n\n"
  },
  "django__django-12308": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12308",
    "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..0f499f6b60 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -382,8 +382,6 @@ def display_for_field(value, field, empty_value_display):\n \n     if getattr(field, 'flatchoices', None):\n         return dict(field.flatchoices).get(value, empty_value_display)\n-    # BooleanField needs special-case null-handling, so it comes before the\n-    # general null test.\n     elif isinstance(field, models.BooleanField):\n         return _boolean_icon(value)\n     elif value is None:\n@@ -398,6 +396,12 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        try:\n+            prepared = field.formfield().prepare_value(value)\n+        except Exception:\n+            prepared = value\n+        return display_for_value(prepared, empty_value_display)\n     else:\n         return display_for_value(value, empty_value_display)\n \ndiff --git a/test_json_display.py b/test_json_display.py\nnew file mode 100644\nindex 0000000000..39e8a40524\n--- /dev/null\n+++ b/test_json_display.py\n@@ -0,0 +1,19 @@\n+\n+from django.contrib.admin.utils import display_for_field\n+from django.db import models\n+from django.forms.fields import InvalidJSONInput\n+\n+cases = [\n+    (\"dict_value\", {\"foo\": \"bar\"}),\n+    (\"invalid_json_input\", InvalidJSONInput('{\"foo\": \"bar\"')),\n+    (\"plain_string\", \"hello\"),\n+]\n+\n+for name, val in cases:\n+    f = models.JSONField()\n+    out = display_for_field(val, f, \"-\")\n+    print(name, \"->\", out)\n+\n+# Non-JSONField baseline\n+char_field = models.CharField()\n+print(\"dict_with_charfield ->\", display_for_field({\"foo\": \"bar\"}, char_field, \"-\"))\n\n"
  },
  "django__django-12325": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12325",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..375462e149 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -194,17 +194,24 @@ class ModelBase(type):\n         # Collect the parent links for multi-table inheritance.\n         parent_links = {}\n         for base in reversed([new_class] + parents):\n-            # Conceptually equivalent to `if base is Model`.\n             if not hasattr(base, '_meta'):\n                 continue\n-            # Skip concrete parent classes.\n+\n             if base != new_class and not base._meta.abstract:\n                 continue\n-            # Locate OneToOneField instances.\n+\n             for field in base._meta.local_fields:\n                 if isinstance(field, OneToOneField):\n                     related = resolve_relation(new_class, field.remote_field.model)\n-                    parent_links[make_model_tuple(related)] = field\n+                    key = make_model_tuple(related)\n+                    existing = parent_links.get(key)\n+                    if existing is None:\n+                        parent_links[key] = field\n+                    else:\n+                        existing_parent = bool(getattr(existing.remote_field, 'parent_link', False))\n+                        this_parent = bool(getattr(field.remote_field, 'parent_link', False))\n+                        if this_parent and not existing_parent:\n+                            parent_links[key] = field\n \n         # Track fields inherited from base models.\n         inherited_attributes = set()\ndiff --git a/repro_test.py b/repro_test.py\nnew file mode 100644\nindex 0000000000..6d148e5717\n--- /dev/null\n+++ b/repro_test.py\n@@ -0,0 +1,42 @@\n+\n+import django\n+from django.conf import settings\n+\n+settings.configure(\n+    DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},\n+    INSTALLED_APPS=['django.contrib.contenttypes'],\n+    SECRET_KEY='test',\n+)\n+django.setup()\n+\n+from django.db import models\n+\n+class Document(models.Model):\n+    class Meta:\n+        app_label = 'myapp'\n+\n+results = {}\n+\n+# Case 1: document_ptr first, then origin\n+try:\n+    class PickingDocPtrFirst(Document):\n+        document_ptr = models.OneToOneField(Document, on_delete=models.CASCADE, parent_link=True, related_name='+')\n+        origin = models.OneToOneField(Document, related_name='picking', on_delete=models.PROTECT)\n+        class Meta:\n+            app_label = 'myapp'\n+    results['docptr_first'] = 'ok'\n+except Exception as e:\n+    results['docptr_first'] = ('error', type(e).__name__, str(e))\n+\n+# Case 2: origin first, then document_ptr\n+try:\n+    class PickingOriginFirst(Document):\n+        origin = models.OneToOneField(Document, related_name='picking', on_delete=models.PROTECT)\n+        document_ptr = models.OneToOneField(Document, on_delete=models.CASCADE, parent_link=True, related_name='+')\n+        class Meta:\n+            app_label = 'myapp'\n+    results['origin_first'] = 'ok'\n+except Exception as e:\n+    results['origin_first'] = ('error', type(e).__name__, str(e))\n+\n+print(results)\n\n"
  },
  "django__django-12406": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..df1a729b2b 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -169,6 +169,17 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n             kwargs['error_messages'] = error_messages[f.name]\n         if field_classes and f.name in field_classes:\n             kwargs['form_class'] = field_classes[f.name]\n+        # If a RadioSelect widget is requested for a non-blank ForeignKey, don't provide an empty_label.\n+        # If a RadioSelect widget is requested for a non-blank related field (e.g. ForeignKey), don't provide an empty_label.\n+        try:\n+            from django.forms.widgets import RadioSelect as _RadioSelect\n+        except Exception:\n+            _RadioSelect = None\n+        if _RadioSelect is not None and 'widget' in kwargs and hasattr(f, 'remote_field'):\n+            w = kwargs['widget']\n+            if (isinstance(w, _RadioSelect) or (isinstance(w, type) and issubclass(w, _RadioSelect))):\n+                if getattr(f, 'blank', False) is False:\n+                    kwargs.setdefault('empty_label', None)\n \n         if formfield_callback is None:\n             formfield = f.formfield(**kwargs)\ndiff --git a/inspect_radio_kwargs.py b/inspect_radio_kwargs.py\nnew file mode 100644\nindex 0000000000..0632f6c8e7\n--- /dev/null\n+++ b/inspect_radio_kwargs.py\n@@ -0,0 +1,30 @@\n+\n+from django.forms.models import fields_for_model\n+from django.forms.widgets import RadioSelect\n+\n+class DummyRemote: pass\n+\n+class DummyField:\n+    def __init__(self, name, blank=False, editable=True, remote_field=None):\n+        self.name = name\n+        self.blank = blank\n+        self.editable = editable\n+        self.remote_field = remote_field\n+    def formfield(self, **kwargs):\n+        return kwargs\n+\n+class DummyOptions:\n+    def __init__(self, fields):\n+        self.concrete_fields = fields\n+        self.private_fields = []\n+        self.many_to_many = []\n+\n+class DummyModel: pass\n+\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=False, editable=True, remote_field=DummyRemote())])\n+res1 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print('related non-blank repr:', repr(res1['data_file']))\n+\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=True, editable=True, remote_field=DummyRemote())])\n+res2 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print('related blank true repr:', repr(res2['data_file']))\ndiff --git a/repro_related_radio.py b/repro_related_radio.py\nnew file mode 100644\nindex 0000000000..d4df752362\n--- /dev/null\n+++ b/repro_related_radio.py\n@@ -0,0 +1,32 @@\n+\n+from django.forms.models import fields_for_model\n+from django.forms.widgets import RadioSelect\n+\n+class DummyRemote: pass\n+\n+class DummyField:\n+    def __init__(self, name, blank=False, editable=True, remote_field=None):\n+        self.name = name\n+        self.blank = blank\n+        self.editable = editable\n+        self.remote_field = remote_field\n+    def formfield(self, **kwargs):\n+        return kwargs\n+\n+class DummyOptions:\n+    def __init__(self, fields):\n+        self.concrete_fields = fields\n+        self.private_fields = []\n+        self.many_to_many = []\n+\n+class DummyModel: pass\n+\n+# related non-blank -> empty_label should be None\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=False, editable=True, remote_field=DummyRemote())])\n+res1 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print('related non-blank:', res1['data_file'].get('empty_label'))\n+\n+# related blank True -> should keep default empty_label if not suppressed\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=True, editable=True, remote_field=DummyRemote())])\n+res2 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print('related blank true:', res2['data_file'].get('empty_label'))\ndiff --git a/repro_test_radio.py b/repro_test_radio.py\nnew file mode 100644\nindex 0000000000..998b7540d1\n--- /dev/null\n+++ b/repro_test_radio.py\n@@ -0,0 +1,19 @@\n+\n+from django.forms.models import fields_for_model\n+from django.forms.widgets import RadioSelect\n+class DummyField:\n+    def __init__(self, name, blank=False, editable=True):\n+        self.name = name\n+        self.blank = blank\n+        self.editable = editable\n+    def formfield(self, **kwargs):\n+        return kwargs\n+class DummyOptions:\n+    def __init__(self, fields):\n+        self.concrete_fields = fields\n+        self.private_fields = []\n+        self.many_to_many = []\n+class DummyModel: pass\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=False, editable=True)])\n+result = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print(repr(result.get('data_file')))\ndiff --git a/repro_tests_radio_expanded.py b/repro_tests_radio_expanded.py\nnew file mode 100644\nindex 0000000000..d38b8ea266\n--- /dev/null\n+++ b/repro_tests_radio_expanded.py\n@@ -0,0 +1,38 @@\n+\n+from django.forms.models import fields_for_model\n+from django.forms.widgets import RadioSelect\n+\n+class DummyField:\n+    def __init__(self, name, blank=False, editable=True):\n+        self.name = name\n+        self.blank = blank\n+        self.editable = editable\n+    def formfield(self, **kwargs):\n+        return kwargs\n+\n+class DummyOptions:\n+    def __init__(self, fields):\n+        self.concrete_fields = fields\n+        self.private_fields = []\n+        self.many_to_many = []\n+\n+class DummyModel: pass\n+\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=False, editable=True)])\n+res1 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print('instance:', res1['data_file'].get('empty_label'))\n+\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=False, editable=True)])\n+res2 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect})\n+print('class:', res2['data_file'].get('empty_label'))\n+\n+class SubRadio(RadioSelect):\n+    pass\n+\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=False, editable=True)])\n+res3 = fields_for_model(DummyModel, widgets={'data_file': SubRadio()})\n+print('subclass instance:', res3['data_file'].get('empty_label'))\n+\n+DummyModel._meta = DummyOptions([DummyField('data_file', blank=True, editable=True)])\n+res4 = fields_for_model(DummyModel, widgets={'data_file': RadioSelect()})\n+print('blank true:', res4['data_file'].get('empty_label'))\n\n"
  },
  "django__django-12708": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12708",
    "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..af6c27cf7e 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -408,12 +408,29 @@ class BaseDatabaseSchemaEditor:\n             **constraint_kwargs\n         )\n         if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-                \", \".join(columns),\n-            ))\n-        self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n+            with self.connection.cursor() as cursor:\n+                all_constraints = self.connection.introspection.get_constraints(cursor, model._meta.db_table)\n+            filtered = []\n+            for name in constraint_names:\n+                infodict = all_constraints.get(name, {})\n+                match = True\n+                for k, v in constraint_kwargs.items():\n+                    if infodict.get(k) != v:\n+                        match = False\n+                        break\n+                if match:\n+                    filtered.append(name)\n+            if len(filtered) == 1:\n+                constraint_name = filtered[0]\n+            else:\n+                raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n+                    len(constraint_names),\n+                    model._meta.db_table,\n+                    \", \".join(columns),\n+                ))\n+        else:\n+            constraint_name = constraint_names[0]\n+        self.execute(self._delete_constraint_sql(sql, model, constraint_name))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n         \"\"\"Rename the table a model points to.\"\"\"\ndiff --git a/tests/repro_delete_composed_index.py b/tests/repro_delete_composed_index.py\nnew file mode 100644\nindex 0000000000..5d9d65d0c6\n--- /dev/null\n+++ b/tests/repro_delete_composed_index.py\n@@ -0,0 +1,67 @@\n+\n+import importlib\n+schema = importlib.import_module(\"django.db.backends.base.schema\")\n+EditorClass = schema.BaseDatabaseSchemaEditor\n+\n+class DummyFeatures:\n+    def __init__(self):\n+        self.can_rollback_ddl = False\n+        self.supports_partial_indexes = False\n+\n+class DummyIntrospection:\n+    def identifier_converter(self, name):\n+        return name\n+    def get_constraints(self, cursor, table_name):\n+        return {\n+            \"uniq_c\": {\"columns\": [\"a_col\", \"b_col\"], \"unique\": True, \"index\": False, \"primary_key\": False, \"check\": False, \"foreign_key\": False, \"type\": None},\n+            \"idx_c\":  {\"columns\": [\"a_col\", \"b_col\"], \"unique\": False, \"index\": True, \"primary_key\": False, \"check\": False, \"foreign_key\": False, \"type\": None},\n+        }\n+\n+class DummyOps:\n+    def quote_name(self, name):\n+        return name\n+\n+class DummyConnection:\n+    def __init__(self):\n+        self.introspection = DummyIntrospection()\n+        self.features = DummyFeatures()\n+        self.ops = DummyOps()\n+    class _cur_cm:\n+        def __enter__(self):\n+            return None\n+        def __exit__(self, exc_type, exc, tb):\n+            return False\n+    def cursor(self):\n+        return DummyConnection._cur_cm()\n+\n+class DummyField:\n+    def __init__(self, column):\n+        self.column = column\n+\n+class Meta:\n+    def __init__(self):\n+        self.constraints = []\n+        self.indexes = []\n+        self.db_table = \"test_table\"\n+    def get_field(self, name):\n+        return DummyField(column=name + \"_col\")\n+\n+class Model:\n+    def __init__(self):\n+        self._meta = Meta()\n+\n+conn = DummyConnection()\n+editor = EditorClass(conn)\n+executed = []\n+def fake_execute(statement):\n+    executed.append(statement)\n+editor.execute = fake_execute\n+\n+model = Model()\n+fields = (\"a\", \"b\")\n+constraint_kwargs = {\"index\": True}\n+sql_template = \"SQL_DELETE\"\n+\n+editor._delete_composed_index(model, fields, constraint_kwargs, sql_template)\n+\n+print(\"OK\", len(executed), executed[0])\ndiff --git a/tests/test_schema_delete_composed.py b/tests/test_schema_delete_composed.py\nnew file mode 100644\nindex 0000000000..0fd2c27b5c\n--- /dev/null\n+++ b/tests/test_schema_delete_composed.py\n@@ -0,0 +1,78 @@\n+\n+import importlib\n+schema = importlib.import_module(\"django.db.backends.base.schema\")\n+EditorClass = schema.BaseDatabaseSchemaEditor\n+\n+class DummyFeatures:\n+    def __init__(self):\n+        self.can_rollback_ddl = False\n+        self.supports_partial_indexes = False\n+\n+class DummyIntrospection:\n+    def identifier_converter(self, name):\n+        return name\n+    def get_constraints(self, cursor, table_name):\n+        return {\n+            \"uniq_c\": {\"columns\": [\"a_col\", \"b_col\"], \"unique\": True, \"index\": False, \"primary_key\": False, \"check\": False, \"foreign_key\": False, \"type\": None},\n+            \"idx_c\":  {\"columns\": [\"a_col\", \"b_col\"], \"unique\": False, \"index\": True, \"primary_key\": False, \"check\": False, \"foreign_key\": False, \"type\": None},\n+            \"other\":  {\"columns\": [\"x_col\"], \"unique\": False, \"index\": True, \"primary_key\": False, \"check\": False, \"foreign_key\": False, \"type\": None},\n+        }\n+\n+class DummyOps:\n+    def quote_name(self, name):\n+        return name\n+\n+class DummyConnection:\n+    def __init__(self):\n+        self.introspection = DummyIntrospection()\n+        self.features = DummyFeatures()\n+        self.ops = DummyOps()\n+    class _cur_cm:\n+        def __enter__(self):\n+            return None\n+        def __exit__(self, exc_type, exc, tb):\n+            return False\n+    def cursor(self):\n+        return DummyConnection._cur_cm()\n+\n+class DummyField:\n+    def __init__(self, column):\n+        self.column = column\n+    def get_internal_type(self):\n+        return 'CharField'\n+\n+class Meta:\n+    def __init__(self):\n+        self.constraints = []\n+        self.indexes = []\n+        self.db_table = \"test_table\"\n+    def get_field(self, name):\n+        return DummyField(column=name + \"_col\")\n+\n+class Model:\n+    def __init__(self):\n+        self._meta = Meta()\n+\n+def run_case(constraint_kwargs):\n+    conn = DummyConnection()\n+    editor = EditorClass(conn)\n+    executed = []\n+    def fake_execute(statement):\n+        executed.append(statement)\n+    editor.execute = fake_execute\n+    model = Model()\n+    fields = (\"a\", \"b\")\n+    sql_template = \"SQL_DELETE\"\n+    editor._delete_composed_index(model, fields, constraint_kwargs, sql_template)\n+    return executed\n+\n+# Case 1: delete index (should pick idx_c)\n+e1 = run_case({\"index\": True})\n+# Case 2: delete unique (should pick uniq_c)\n+e2 = run_case({\"unique\": True})\n+\n+if not e1 or not e2:\n+    print(\"FAIL: No execution recorded\")\n+    raise SystemExit(2)\n+\n+print(\"PASS\", len(e1), len(e2))\n\n"
  },
  "django__django-12713": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12713",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..b3c4020f39 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -250,15 +250,16 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n         db = kwargs.get('using')\n \n         autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n-            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n-            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n-            kwargs['widget'] = widgets.FilteredSelectMultiple(\n-                db_field.verbose_name,\n-                db_field.name in self.filter_vertical\n-            )\n+        if 'widget' not in kwargs:\n+            if db_field.name in autocomplete_fields:\n+                kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in self.raw_id_fields:\n+                kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+                kwargs['widget'] = widgets.FilteredSelectMultiple(\n+                    db_field.verbose_name,\n+                    db_field.name in self.filter_vertical\n+                )\n \n         if 'queryset' not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\ndiff --git a/repro_widget_override.py b/repro_widget_override.py\nnew file mode 100644\nindex 0000000000..2a10acc5e5\n--- /dev/null\n+++ b/repro_widget_override.py\n@@ -0,0 +1,35 @@\n+from django.conf import settings\n+if not settings.configured:\n+    settings.configure(INSTALLED_APPS=[], SECRET_KEY='x', USE_I18N=False)\n+import django\n+django.setup()\n+from django.contrib.admin.options import BaseModelAdmin\n+from django.forms.widgets import SelectMultiple\n+\n+class DummyThroughMeta:\n+    auto_created = True\n+\n+class DummyThrough:\n+    _meta = DummyThroughMeta()\n+\n+class DummyRemoteField:\n+    through = DummyThrough()\n+    model = None\n+\n+class DummyDBField:\n+    def __init__(self):\n+        self.name = 'm2mfield'\n+        self.verbose_name = 'VN'\n+        self.remote_field = DummyRemoteField()\n+    def formfield(self, **kwargs):\n+        class FF:\n+            def __init__(self, widget, help_text=None):\n+                self.widget = widget if widget is not None else SelectMultiple()\n+                self.help_text = help_text\n+        return FF(kwargs.get('widget'), kwargs.get('help_text'))\n+\n+admin = BaseModelAdmin()\n+admin.admin_site = type('AS', (), {'_registry': {}})()\n+def my_widget(): pass\n+result = admin.formfield_for_manytomany(DummyDBField(), request=None, widget=my_widget)\n+print('PRESERVED' if getattr(result, 'widget') is my_widget else 'OVERRIDDEN')\n\\ No newline at end of file\n\n"
  },
  "django__django-12774": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12774",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..cbbf0e05ea 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -689,8 +689,20 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+        if field_name != 'pk':\n+            field = self.model._meta.get_field(field_name)\n+            is_unique = field.unique\n+            if not is_unique:\n+                from django.db.models.constraints import UniqueConstraint\n+                for constraint in getattr(self.model._meta, 'constraints', ()):\n+                    if (isinstance(constraint, UniqueConstraint) and\n+                            len(constraint.fields) == 1 and\n+                            constraint.fields[0] == field_name and\n+                            constraint.condition is None):\n+                        is_unique = True\n+                        break\n+            if not is_unique:\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n         if id_list is not None:\n             if not id_list:\n                 return {}\ndiff --git a/repro_in_bulk.py b/repro_in_bulk.py\nnew file mode 100644\nindex 0000000000..be0adbdb53\n--- /dev/null\n+++ b/repro_in_bulk.py\n@@ -0,0 +1,26 @@\n+\n+from django.db.models.query import QuerySet\n+from django.db.models.constraints import UniqueConstraint\n+\n+class FakeField:\n+    def __init__(self, unique):\n+        self.unique = unique\n+\n+class FakeMeta:\n+    def __init__(self):\n+        self.constraints = [UniqueConstraint(fields=('slug',), name='app_model_slug_unq')]\n+    def get_field(self, name):\n+        return FakeField(False)\n+\n+class FakeModel:\n+    _meta = FakeMeta()\n+\n+class DummyQS:\n+    def __init__(self):\n+        self.model = FakeModel()\n+        self.db = 'default'\n+\n+# Call unbound method with dummy qs and empty id_list to short-circuit DB usage.\n+qs = DummyQS()\n+result = QuerySet.in_bulk(qs, id_list=[], field_name='slug')\n+print('OK', result)\ndiff --git a/repro_in_bulk2.py b/repro_in_bulk2.py\nnew file mode 100644\nindex 0000000000..8fd8b35354\n--- /dev/null\n+++ b/repro_in_bulk2.py\n@@ -0,0 +1,26 @@\n+\n+from django.db.models.query import QuerySet\n+from django.db.models.constraints import UniqueConstraint\n+\n+class FakeField:\n+    def __init__(self, unique):\n+        self.unique = unique\n+\n+class FakeMeta:\n+    def __init__(self):\n+        self.constraints = [UniqueConstraint(fields=('slug',), name='app_model_slug_unq')]\n+    def get_field(self, name):\n+        return FakeField(False)\n+\n+class FakeModel:\n+    _meta = FakeMeta()\n+\n+class DummyQS:\n+    def __init__(self):\n+        self.model = FakeModel()\n+        self.db = 'default'\n+        self.query = type('Q', (), {'is_sliced': False})()\n+\n+qs = DummyQS()\n+result = QuerySet.in_bulk(qs, id_list=[], field_name='slug')\n+print('OK', result)\n\n"
  },
  "django__django-9296": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-9296",
    "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..27cc31b0e3 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -105,6 +105,10 @@ class Paginator:\n         a template for loop.\n         \"\"\"\n         return range(1, self.num_pages + 1)\n+    def __iter__(self):\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n \n     def _check_object_list_is_ordered(self):\n         \"\"\"\ndiff --git a/test_paginator_edge.py b/test_paginator_edge.py\nnew file mode 100644\nindex 0000000000..9319cb9108\n--- /dev/null\n+++ b/test_paginator_edge.py\n@@ -0,0 +1,6 @@\n+from django.core.paginator import Paginator\n+def test_empty(allow):\n+    p = Paginator([], 3, allow_empty_first_page=allow)\n+    print('allow', allow, 'num_pages', p.num_pages, 'list', list(p))\n+test_empty(True)\n+test_empty(False)\ndiff --git a/test_paginator_iter.py b/test_paginator_iter.py\nnew file mode 100644\nindex 0000000000..204a5d20f6\n--- /dev/null\n+++ b/test_paginator_iter.py\n@@ -0,0 +1,5 @@\n+from django.core.paginator import Paginator\n+p = Paginator(list(range(10)), 3)\n+for pg in p:\n+    print(pg.number, list(pg))\n+print('page_range:', list(p.page_range))\n\n"
  },
  "sphinx-doc__sphinx-10323": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10323",
    "model_patch": "diff --git a/check_prepend_append.py b/check_prepend_append.py\nnew file mode 100644\nindex 000000000..357226b62\n--- /dev/null\n+++ b/check_prepend_append.py\n@@ -0,0 +1,23 @@\n+\n+from sphinx.directives.code import LiteralIncludeReader\n+class DummyConfig: source_encoding = \"utf-8\"\n+xml = \"\"\"<root>\n+      <plugin>\n+        <child>value</child>\n+      </plugin>\n+</root>\n+\"\"\"\n+open(\"test.xml\",\"w\",encoding=\"utf-8\").write(xml)\n+def run_case(opts, name):\n+    reader = LiteralIncludeReader(\"test.xml\", opts, DummyConfig())\n+    text, lines = reader.read()\n+    print(\"CASE:\", name)\n+    print(text)\n+    print(\"LINES:\", lines)\n+    print(\"---\")\n+# case: dedent should remove leading 6 spaces from included content only\n+run_case({\"start-at\":\"<plugin>\",\"end-at\":\"</plugin>\",\"dedent\":6,\"prepend\":\"      <plugin>\"},\"prepend_with_dedent\")\n+# case: append preserved\n+run_case({\"start-at\":\"<plugin>\",\"end-at\":\"</plugin>\",\"dedent\":6,\"append\":\"      </plugin>\"},\"append_with_dedent\")\n+# case: both prepend and append preserved when dedent present\n+run_case({\"start-at\":\"<plugin>\",\"end-at\":\"</plugin>\",\"dedent\":6,\"prepend\":\"      <plugin>\",\"append\":\"      </plugin>\"},\"both_with_dedent\")\ndiff --git a/pom.xml b/pom.xml\nnew file mode 100644\nindex 000000000..f7ecc68de\n--- /dev/null\n+++ b/pom.xml\n@@ -0,0 +1,26 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project>\n+  <build>\n+    <plugins>\n+      <plugin>\n+        <groupId>org.apache.maven.plugins</groupId>\n+        <artifactId>maven-compiler-plugin</artifactId>\n+        <version>3.8.0</version>\n+        <configuration>\n+          <source>1.8</source>\n+          <target>1.8</target>\n+          <debug>true</debug>\n+          <encoding>UTF-8</encoding>\n+        </configuration>\n+      </plugin>\n+      <plugin>\n+        <groupId>com.github.ekryd.sortpom</groupId>\n+        <artifactId>sortpom-maven-plugin</artifactId>\n+        <version>2.15.0</version>\n+        <configuration>\n+          <verifyFailOn>strict</verifyFailOn>\n+        </configuration>\n+      </plugin>\n+    </plugins>\n+  </build>\n+</project>\ndiff --git a/repro_literalinclude.py b/repro_literalinclude.py\nnew file mode 100644\nindex 000000000..9c34bfe1f\n--- /dev/null\n+++ b/repro_literalinclude.py\n@@ -0,0 +1,40 @@\n+\n+from sphinx.directives.code import LiteralIncludeReader\n+class DummyConfig: source_encoding = \"utf-8\"\n+pom = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project>\n+  <build>\n+    <plugins>\n+      <plugin>\n+        <groupId>org.apache.maven.plugins</groupId>\n+        <artifactId>maven-compiler-plugin</artifactId>\n+        <version>3.8.0</version>\n+        <configuration>\n+          <source>1.8</source>\n+          <target>1.8</target>\n+          <debug>true</debug>\n+          <encoding>UTF-8</encoding>\n+        </configuration>\n+      </plugin>\n+      <plugin>\n+        <groupId>com.github.ekryd.sortpom</groupId>\n+        <artifactId>sortpom-maven-plugin</artifactId>\n+        <version>2.15.0</version>\n+        <configuration>\n+          <verifyFailOn>strict</verifyFailOn>\n+        </configuration>\n+      </plugin>\n+    </plugins>\n+  </build>\n+</project>\n+\"\"\"\n+open(\"pom.xml\",\"w\",encoding=\"utf-8\").write(pom)\n+opts = {\n+    \"start-at\": \"<groupId>com.github.ekryd.sortpom</groupId>\",\n+    \"end-at\": \"</plugin>\",\n+    \"prepend\": \"      <plugin>\",\n+    \"dedent\": 6\n+}\n+reader = LiteralIncludeReader(\"pom.xml\", opts, DummyConfig())\n+text, lines = reader.read()\n+print(\"===RAW TEXT===\\\\n\" + text + \"\\\\n===LINES_LEN===\\\\n\" + str(lines))\ndiff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..9437fe9a5 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -224,9 +224,9 @@ class LiteralIncludeReader:\n                        self.start_filter,\n                        self.end_filter,\n                        self.lines_filter,\n+                       self.dedent_filter,\n                        self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+                       self.append_filter]\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\ndiff --git a/test.xml b/test.xml\nnew file mode 100644\nindex 000000000..fd8376069\n--- /dev/null\n+++ b/test.xml\n@@ -0,0 +1,5 @@\n+<root>\n+      <plugin>\n+        <child>value</child>\n+      </plugin>\n+</root>\n\n"
  },
  "sphinx-doc__sphinx-10435": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10435",
    "model_patch": "diff --git a/sphinx/texinputs/sphinxlatexstyletext.sty b/sphinx/texinputs/sphinxlatexstyletext.sty\nindex 539ee0de3..a7753b1fc 100644\n--- a/sphinx/texinputs/sphinxlatexstyletext.sty\n+++ b/sphinx/texinputs/sphinxlatexstyletext.sty\n@@ -8,7 +8,7 @@\n \n % Some custom font markup commands.\n \\protected\\def\\sphinxstrong#1{\\textbf{#1}}\n-\\protected\\def\\sphinxcode#1{\\texttt{#1}}\n+\\protected\\def\\sphinxcode#1{\\texttt{\\ignorespaces#1\\unskip}}\n \\protected\\def\\sphinxbfcode#1{\\textbf{\\sphinxcode{#1}}}\n \\protected\\def\\sphinxemail#1{\\textsf{#1}}\n \\protected\\def\\sphinxtablecontinued#1{\\textsf{#1}}\n\n"
  },
  "sphinx-doc__sphinx-10466": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10466",
    "model_patch": "diff --git a/repro_gettext_dedup.py b/repro_gettext_dedup.py\nnew file mode 100644\nindex 000000000..ffac48ce6\n--- /dev/null\n+++ b/repro_gettext_dedup.py\n@@ -0,0 +1,20 @@\n+from sphinx.builders.gettext import Catalog, MsgOrigin, Message\n+c = Catalog()\n+o1 = MsgOrigin(\"doc/file.rst\", 10)\n+o2 = MsgOrigin(\"doc/file.rst\", 10)\n+o3 = MsgOrigin(\"doc/other.rst\", 5)\n+c.add(\"Type\", o1)\n+c.add(\"Type\", o2)\n+c.add(\"Type\", o3)\n+for m in c:\n+    print(\"locations:\", m.locations)\n+    print(\"uuids:\", m.uuids)\n+    assert len(m.locations) == len(m.uuids)\n+    assert len(m.locations) == 2\n+# direct Message construction with mismatched lengths should still dedupe locations\n+m2 = Message(\"X\", [(\"a.rst\",1),(\"a.rst\",1)], [\"u\"])\n+print(\"m2 locations:\", m2.locations)\n+print(\"m2 uuids:\", m2.uuids)\n+assert m2.locations == [(\"a.rst\",1)]\n+assert m2.uuids == [\"u\"]\n+print(\"OK\")\n\\ No newline at end of file\ndiff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..c69f36d7b 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -29,11 +29,29 @@ logger = logging.getLogger(__name__)\n \n \n class Message:\n-    \"\"\"An entry of translatable message.\"\"\"\n+\n     def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n         self.text = text\n-        self.locations = locations\n-        self.uuids = uuids\n+        if locations and uuids and len(locations) == len(uuids):\n+            seen = set()\n+            unique_locations = []\n+            unique_uuids = []\n+            for loc, uid in zip(locations, uuids):\n+                if loc not in seen:\n+                    seen.add(loc)\n+                    unique_locations.append(loc)\n+                    unique_uuids.append(uid)\n+            self.locations = unique_locations\n+            self.uuids = unique_uuids\n+        else:\n+            seen = set()\n+            unique_locations = []\n+            for loc in locations:\n+                if loc not in seen:\n+                    seen.add(loc)\n+                    unique_locations.append(loc)\n+            self.locations = unique_locations\n+            self.uuids = uuids\n \n \n class Catalog:\ndiff --git a/test_gettext_dedup.py b/test_gettext_dedup.py\nnew file mode 100644\nindex 000000000..f4f310cf1\n--- /dev/null\n+++ b/test_gettext_dedup.py\n@@ -0,0 +1,25 @@\n+import unittest\n+from sphinx.builders.gettext import Message, Catalog, MsgOrigin\n+\n+class TestGettextMessageDedup(unittest.TestCase):\n+    def test_catalog_add_dedup(self):\n+        c = Catalog()\n+        o1 = MsgOrigin(\"doc/file.rst\", 10)\n+        o2 = MsgOrigin(\"doc/file.rst\", 10)\n+        o3 = MsgOrigin(\"doc/other.rst\", 5)\n+        c.add(\"Type\", o1)\n+        c.add(\"Type\", o2)\n+        c.add(\"Type\", o3)\n+        msgs = list(c)\n+        self.assertEqual(len(msgs), 1)\n+        m = msgs[0]\n+        self.assertEqual(m.locations, [(\"doc/file.rst\", 10), (\"doc/other.rst\", 5)])\n+        self.assertEqual(len(m.uuids), 2)\n+\n+    def test_message_constructor_mismatched_lengths(self):\n+        m = Message(\"X\", [(\"a.rst\",1),(\"a.rst\",1)], [\"u\"])\n+        self.assertEqual(m.locations, [(\"a.rst\",1)])\n+        self.assertEqual(m.uuids, [\"u\"])\n+\n+if __name__ == \"__main__\":\n+    unittest.main()\n\n"
  },
  "sphinx-doc__sphinx-10673": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10673",
    "model_patch": "diff --git a/sphinx/environment/adapters/toctree.py b/sphinx/environment/adapters/toctree.py\nindex 9678e3c7c..009e25c71 100644\n--- a/sphinx/environment/adapters/toctree.py\n+++ b/sphinx/environment/adapters/toctree.py\n@@ -163,8 +163,12 @@ class TocTree:\n                         logger.warning(__('toctree contains reference to document %r that '\n                                           'doesn\\'t have a title: no link will be generated'),\n                                        ref, location=toctreenode)\n+\n                 except KeyError:\n-                    # this is raised if the included file does not exist\n+                    # Allow references to autogenerated index/search pages without warning\n+                    if ref in ('genindex', 'modindex', 'search'):\n+                        continue\n+\n                     if excluded(self.env.doc2path(ref, False)):\n                         message = __('toctree contains reference to excluded document %r')\n                     elif not included(self.env.doc2path(ref, False)):\n\n"
  },
  "sphinx-doc__sphinx-11510": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-11510",
    "model_patch": "diff --git a/docstest/doctree/environment.pickle b/docstest/doctree/environment.pickle\nnew file mode 100644\nindex 000000000..7f9036ed6\nBinary files /dev/null and b/docstest/doctree/environment.pickle differ\ndiff --git a/docstest/doctree/index.doctree b/docstest/doctree/index.doctree\nnew file mode 100644\nindex 000000000..c3fb2a638\nBinary files /dev/null and b/docstest/doctree/index.doctree differ\ndiff --git a/docstest/doctree/something-to-include.doctree b/docstest/doctree/something-to-include.doctree\nnew file mode 100644\nindex 000000000..692c98144\nBinary files /dev/null and b/docstest/doctree/something-to-include.doctree differ\ndiff --git a/docstest/source/conf.py b/docstest/source/conf.py\nnew file mode 100644\nindex 000000000..d512766ad\n--- /dev/null\n+++ b/docstest/source/conf.py\n@@ -0,0 +1,3 @@\n+import os, sys\n+sys.path.insert(0, os.path.abspath('.'))\n+extensions = ['my_extension']\ndiff --git a/docstest/source/index.rst b/docstest/source/index.rst\nnew file mode 100644\nindex 000000000..f2dec1395\n--- /dev/null\n+++ b/docstest/source/index.rst\n@@ -0,0 +1,6 @@\n+This is a test\n+==============\n+\n+.. include:: something-to-include.rst\n+\n+&REPLACE_ME;\ndiff --git a/docstest/source/my_extension.py b/docstest/source/my_extension.py\nnew file mode 100644\nindex 000000000..886fd8165\n--- /dev/null\n+++ b/docstest/source/my_extension.py\n@@ -0,0 +1,10 @@\n+from sphinx.application import Sphinx\n+\n+def subst_vars_replace(app: Sphinx, docname, source):\n+    result = source[0]\n+    result = result.replace(\"&REPLACE_ME;\", \"REPLACED\")\n+    source[0] = result\n+\n+def setup(app):\n+    app.connect('source-read', subst_vars_replace)\n+    return dict(version='1.0')\ndiff --git a/docstest/source/something-to-include.rst b/docstest/source/something-to-include.rst\nnew file mode 100644\nindex 000000000..e63253568\n--- /dev/null\n+++ b/docstest/source/something-to-include.rst\n@@ -0,0 +1,4 @@\n+Testing\n+=======\n+\n+&REPLACE_ME;\ndiff --git a/run_repro.py b/run_repro.py\nnew file mode 100644\nindex 000000000..6fba55f92\n--- /dev/null\n+++ b/run_repro.py\n@@ -0,0 +1,36 @@\n+import os, sys\n+repo_root = os.path.abspath('.')\n+sys.path.insert(0, repo_root)\n+from sphinx.application import Sphinx\n+\n+docdir = 'docstest'\n+src = os.path.join(docdir, 'source')\n+out = os.path.join(docdir, 'build')\n+doctree = os.path.join(docdir, 'doctree')\n+os.makedirs(src, exist_ok=True)\n+os.makedirs(out, exist_ok=True)\n+os.makedirs(doctree, exist_ok=True)\n+\n+conf = \"import os, sys\\nsys.path.insert(0, os.path.abspath('.'))\\nextensions = ['my_extension']\\n\"\n+with open(os.path.join(src, 'conf.py'), 'w') as f:\n+    f.write(conf)\n+\n+index = \"This is a test\\n==============\\n\\n.. include:: something-to-include.rst\\n\\n&REPLACE_ME;\\n\"\n+with open(os.path.join(src, 'index.rst'), 'w') as f:\n+    f.write(index)\n+\n+included = \"Testing\\n=======\\n\\n&REPLACE_ME;\\n\"\n+with open(os.path.join(src, 'something-to-include.rst'), 'w') as f:\n+    f.write(included)\n+\n+ext = \"from sphinx.application import Sphinx\\n\\ndef subst_vars_replace(app: Sphinx, docname, source):\\n    result = source[0]\\n    result = result.replace(\\\"&REPLACE_ME;\\\", \\\"REPLACED\\\")\\n    source[0] = result\\n\\ndef setup(app):\\n    app.connect('source-read', subst_vars_replace)\\n    return dict(version='1.0')\\n\"\n+with open(os.path.join(src, 'my_extension.py'), 'w') as f:\n+    f.write(ext)\n+\n+app = Sphinx(src, src, out, doctree, 'html')\n+app.build()\n+outfile = os.path.join(out, 'index.html')\n+with open(outfile, 'r', encoding='utf-8') as f:\n+    html = f.read()\n+print('FOUND_REPLACED_IN_INCLUDED:', html.count('REPLACED'))\n+print('FOUND_LITERAL_REPLACE_ME:', html.count('&REPLACE_ME;'))\ndiff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 19f7c0a8d..194de8be5 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -363,20 +363,40 @@ class Only(SphinxDirective):\n \n \n class Include(BaseInclude, SphinxDirective):\n-    \"\"\"\n-    Like the standard \"Include\" directive, but interprets absolute paths\n-    \"correctly\", i.e. relative to source directory.\n-    \"\"\"\n \n     def run(self) -> list[Node]:\n-        if self.arguments[0].startswith('<') and \\\n-           self.arguments[0].endswith('>'):\n-            # docutils \"standard\" includes, do not do path processing\n+        if self.arguments[0].startswith('<') and            self.arguments[0].endswith('>'):\n             return super().run()\n         rel_filename, filename = self.env.relfn2path(self.arguments[0])\n         self.arguments[0] = filename\n         self.env.note_included(filename)\n-        return super().run()\n+        import docutils.io as _dio\n+        _orig_FileInput = _dio.FileInput\n+        _env = self.env\n+\n+        def _make_wrapper(orig):\n+            class _WrappedFileInput(orig):  # type: ignore[misc]\n+                def read(self_inner, *args, **kwargs):\n+                    text = super(_WrappedFileInput, self_inner).read(*args, **kwargs)\n+                    source_path = getattr(self_inner, 'source_path',\n+                                          getattr(self_inner, 'source', None))\n+                    try:\n+                        if source_path:\n+                            docname = _env.path2doc(source_path)\n+                            if docname:\n+                                arg = [text]\n+                                _env.events.emit('source-read', docname, arg)\n+                                return arg[0]\n+                    except Exception:\n+                        pass\n+                    return text\n+            return _WrappedFileInput\n+\n+        _dio.FileInput = _make_wrapper(_orig_FileInput)\n+        try:\n+            return super().run()\n+        finally:\n+            _dio.FileInput = _orig_FileInput\n \n \n def setup(app: Sphinx) -> dict[str, Any]:\n\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/dbg_udl.py b/dbg_udl.py\nnew file mode 100644\nindex 000000000..3e0cf85af\n--- /dev/null\n+++ b/dbg_udl.py\n@@ -0,0 +1,26 @@\n+\n+from sphinx.domains.cpp import DefinitionParser\n+class Cfg:\n+    cpp_id_attributes = []\n+    cpp_paren_attributes = []\n+s = 'constexpr auto units::si::planck_constant = 6.62607015e-34q_J * 1q_s'\n+parser = DefinitionParser(s, location=('<test>',1), config=Cfg())\n+# advance to the expression part by parsing up to '='\n+try:\n+    # find '=' position and set parser.pos after it\n+    eq = s.find('=')\n+    if eq == -1:\n+        print(\"no eq\")\n+    else:\n+        parser.pos = eq + 1\n+        parser.skip_ws()\n+        lit = parser._parse_literal()\n+        print(\"pos after literal:\", parser.pos)\n+        print(\"literal type:\", type(lit).__name__)\n+        print(\"literal str:\", str(lit))\n+        # try to parse a binary * expression: parse expression next\n+        parser.pos = eq + 1\n+        expr = parser._parse_expression()\n+        print(\"parsed expression type:\", type(expr).__name__, str(expr))\n+except Exception as e:\n+    print(\"Error:\", type(e).__name__, e)\ndiff --git a/repro_udl.py b/repro_udl.py\nnew file mode 100644\nindex 000000000..291470b59\n--- /dev/null\n+++ b/repro_udl.py\n@@ -0,0 +1,11 @@\n+\n+from sphinx.domains import cpp\n+from sphinx.domains.cpp import DefinitionParser\n+\n+s = 'constexpr auto units::si::planck_constant = 6.62607015e-34q_J * 1q_s'\n+p = DefinitionParser(s)\n+try:\n+    res = p.parse_definition()\n+    print(\"Parsed OK:\", res)\n+except Exception as e:\n+    print(\"Error:\", type(e).__name__, e)\ndiff --git a/repro_udl_edges.py b/repro_udl_edges.py\nnew file mode 100644\nindex 000000000..ca9ff7e3b\n--- /dev/null\n+++ b/repro_udl_edges.py\n@@ -0,0 +1,20 @@\n+\n+from sphinx.domains.cpp import DefinitionParser\n+class Cfg:\n+    cpp_id_attributes = []\n+    cpp_paren_attributes = []\n+tests = [\n+ 'auto x = 123abc',\n+ 'auto y = 3.14m_ft',\n+ 'auto s = \"hello\"_udl',\n+ \"auto c = 'a'zzz\",\n+ 'auto mix = 1e10_K * \"s\"_suf + \\'b\\'b',\n+]\n+for t in tests:\n+    parser = DefinitionParser(t, location=('<test>',1), config=Cfg())\n+    try:\n+        ast = parser.parse_declaration('member', 'var')\n+        parser.assert_end()\n+        print(\"OK:\", t)\n+    except Exception as e:\n+        print(\"FAIL:\", t, \"->\", type(e).__name__, e)\ndiff --git a/repro_udl_run.py b/repro_udl_run.py\nnew file mode 100644\nindex 000000000..00a650628\n--- /dev/null\n+++ b/repro_udl_run.py\n@@ -0,0 +1,13 @@\n+\n+from sphinx.domains.cpp import DefinitionParser\n+class Cfg:\n+    cpp_id_attributes = []\n+    cpp_paren_attributes = []\n+s = 'constexpr auto units::si::planck_constant = 6.62607015e-34q_J * 1q_s'\n+parser = DefinitionParser(s, location=('<test>',1), config=Cfg())\n+try:\n+    ast = parser.parse_definition()\n+    parser.assert_end()\n+    print(\"Parsed OK:\", type(ast).__name__, str(ast))\n+except Exception as e:\n+    print(\"Error:\", type(e).__name__, e)\ndiff --git a/repro_udl_run2.py b/repro_udl_run2.py\nnew file mode 100644\nindex 000000000..7129af8ce\n--- /dev/null\n+++ b/repro_udl_run2.py\n@@ -0,0 +1,13 @@\n+\n+from sphinx.domains.cpp import DefinitionParser\n+class Cfg:\n+    cpp_id_attributes = []\n+    cpp_paren_attributes = []\n+s = 'constexpr auto units::si::planck_constant = 6.62607015e-34q_J * 1q_s'\n+parser = DefinitionParser(s, location=('<test>',1), config=Cfg())\n+try:\n+    ast = parser.parse_declaration('member', 'var')\n+    parser.assert_end()\n+    print(\"Parsed OK:\", type(ast).__name__, str(ast))\n+except Exception as e:\n+    print(\"Error:\", type(e).__name__, e)\ndiff --git a/repro_udl_test.py b/repro_udl_test.py\nnew file mode 100644\nindex 000000000..7129af8ce\n--- /dev/null\n+++ b/repro_udl_test.py\n@@ -0,0 +1,13 @@\n+\n+from sphinx.domains.cpp import DefinitionParser\n+class Cfg:\n+    cpp_id_attributes = []\n+    cpp_paren_attributes = []\n+s = 'constexpr auto units::si::planck_constant = 6.62607015e-34q_J * 1q_s'\n+parser = DefinitionParser(s, location=('<test>',1), config=Cfg())\n+try:\n+    ast = parser.parse_declaration('member', 'var')\n+    parser.assert_end()\n+    print(\"Parsed OK:\", type(ast).__name__, str(ast))\n+except Exception as e:\n+    print(\"Error:\", type(e).__name__, e)\ndiff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..17b089162 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -882,6 +882,23 @@ class ASTCharLiteral(ASTLiteral):\n         signode.append(nodes.Text(txt, txt))\n \n \n+class ASTUserDefinedLiteral(ASTLiteral):\n+    def __init__(self, literal: ASTLiteral, identifier: ASTIdentifier) -> None:\n+        self.literal = literal\n+        self.identifier = identifier\n+\n+    def _stringify(self, transform: StringifyTransform) -> str:\n+        return transform(self.literal) + transform(self.identifier)\n+\n+    def get_id(self, version: int) -> str:\n+        return 'ud' + self.literal.get_id(version) + self.identifier.get_id(version)\n+\n+    def describe_signature(self, signode: 'TextElement', mode: str,\n+                           env: 'BuildEnvironment', symbol: 'Symbol') -> None:\n+        txt = str(self)\n+        signode.append(nodes.Text(txt, txt))\n+\n+\n class ASTThisLiteral(ASTExpression):\n     def _stringify(self, transform: StringifyTransform) -> str:\n         return \"this\"\n@@ -4644,13 +4661,6 @@ class DefinitionParser(BaseParser):\n         return self.definition[startPos:self.pos]\n \n     def _parse_literal(self) -> ASTLiteral:\n-        # -> integer-literal\n-        #  | character-literal\n-        #  | floating-literal\n-        #  | string-literal\n-        #  | boolean-literal -> \"false\" | \"true\"\n-        #  | pointer-literal -> \"nullptr\"\n-        #  | user-defined-literal\n         self.skip_ws()\n         if self.skip_word('nullptr'):\n             return ASTPointerLiteral()\n@@ -4664,25 +4674,35 @@ class DefinitionParser(BaseParser):\n             if self.match(regex):\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+                lit = ASTNumberLiteral(self.definition[pos:self.pos])\n+                if self.match(identifier_re):\n+                    identifier = ASTIdentifier(self.matched_text)\n+                    return ASTUserDefinedLiteral(lit, identifier)\n+                return lit\n \n         string = self._parse_string()\n         if string is not None:\n-            return ASTStringLiteral(string)\n+            lit = ASTStringLiteral(string)\n+            if self.match(identifier_re):\n+                identifier = ASTIdentifier(self.matched_text)\n+                return ASTUserDefinedLiteral(lit, identifier)\n+            return lit\n \n-        # character-literal\n         if self.match(char_literal_re):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)\n             try:\n-                return ASTCharLiteral(prefix, data)\n+                lit = ASTCharLiteral(prefix, data)\n             except UnicodeDecodeError as e:\n                 self.fail(\"Can not handle character literal. Internal error was: %s\" % e)\n             except UnsupportedMultiCharacterCharLiteral:\n                 self.fail(\"Can not handle character literal\"\n                           \" resulting in multiple decoded characters.\")\n+            if self.match(identifier_re):\n+                identifier = ASTIdentifier(self.matched_text)\n+                return ASTUserDefinedLiteral(lit, identifier)\n+            return lit\n \n-        # TODO: user-defined lit\n         return None\n \n     def _parse_fold_or_paren_expression(self) -> ASTExpression:\ndiff --git a/sphinx/util/cfamily.py b/sphinx/util/cfamily.py\nindex 790a492a5..20448c8ce 100644\n--- a/sphinx/util/cfamily.py\n+++ b/sphinx/util/cfamily.py\n@@ -32,7 +32,7 @@ anon_identifier_re = re.compile(r'(@[a-zA-Z0-9_])[a-zA-Z0-9_]*\\b')\n identifier_re = re.compile(r'''(?x)\n     (   # This 'extends' _anon_identifier_re with the ordinary identifiers,\n         # make sure they are in sync.\n-        (~?\\b[a-zA-Z_])  # ordinary identifiers\n+(~?[a-zA-Z_])\n     |   (@[a-zA-Z0-9_])  # our extension for names of anonymous entities\n     )\n     [a-zA-Z0-9_]*\\b\n\n"
  },
  "sphinx-doc__sphinx-7748": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7748",
    "model_patch": "diff --git a/sphinx/addnodes.py b/sphinx/addnodes.py\nindex 5e191e989..949afe03d 100644\n--- a/sphinx/addnodes.py\n+++ b/sphinx/addnodes.py\n@@ -385,7 +385,7 @@ def setup(app: \"Sphinx\") -> Dict[str, Any]:\n     app.add_node(start_of_file)\n     app.add_node(highlightlang)\n     app.add_node(tabular_col_spec)\n-    app.add_node(meta)\n+    app.add_node(meta, override=True)\n     app.add_node(pending_xref)\n     app.add_node(number_reference)\n     app.add_node(download_reference)\ndiff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex f8e4be999..0af541e9c 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1049,24 +1049,35 @@ class DocstringSignatureMixin:\n             # no lines in docstring, no match\n             if not doclines:\n                 continue\n-            # match first line of docstring against signature RE\n-            match = py_ext_sig_re.match(doclines[0])\n-            if not match:\n-                continue\n-            exmod, path, base, args, retann = match.groups()\n-            # the base name must match ours\n-            valid_names = [self.objpath[-1]]  # type: ignore\n-            if isinstance(self, ClassDocumenter):\n-                valid_names.append('__init__')\n-                if hasattr(self.object, '__mro__'):\n-                    valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n-            if base not in valid_names:\n+            # collect consecutive leading signature lines of the docstring\n+            sigs = []\n+            j = 0\n+            while j < len(doclines):\n+                # match this line against signature RE\n+                m = py_ext_sig_re.match(doclines[j])\n+                if not m:\n+                    break\n+                exmod, path, base, args, retann = m.groups()\n+                # the base name must match ours\n+                valid_names = [self.objpath[-1]]  # type: ignore\n+                if isinstance(self, ClassDocumenter):\n+                    valid_names.append('__init__')\n+                    if hasattr(self.object, '__mro__'):\n+                        valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n+                if base not in valid_names:\n+                    break\n+                sigs.append((args, retann))\n+                j += 1\n+            if not sigs:\n                 continue\n             # re-prepare docstring to ignore more leading indentation\n             tab_width = self.directive.state.document.settings.tab_width  # type: ignore\n-            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[1:]),\n+            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[j:]),\n                                                         tabsize=tab_width)\n-            result = args, retann\n+            # combine multiple signatures: join args with newlines, prefer first non-empty return annotation\n+            combined_args = '\\n'.join(a for a, _ in sigs)\n+            combined_retann = next((r for _, r in sigs if r), None)\n+            result = combined_args, combined_retann\n             # don't look any further\n             break\n         return result\n\n"
  },
  "sphinx-doc__sphinx-7757": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7757",
    "model_patch": "diff --git a/repro_sig.py b/repro_sig.py\nnew file mode 100644\nindex 000000000..f7ef676f9\n--- /dev/null\n+++ b/repro_sig.py\n@@ -0,0 +1,6 @@\n+from sphinx.util.inspect import signature_from_str\n+sig = signature_from_str('(a, b=0, /, c=1)')\n+print('Signature repr:', repr(sig))\n+print('Signature str:', str(sig))\n+for p in sig.parameters.values():\n+    print('PARAM', p.name, 'kind', p.kind, 'default', p.default)\n\\ No newline at end of file\ndiff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 15f0d66e2..e4b4a124f 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -521,17 +521,30 @@ def signature_from_str(signature: str) -> inspect.Signature:\n     params = []\n \n     if hasattr(args, \"posonlyargs\"):\n-        for arg in args.posonlyargs:  # type: ignore\n-            annotation = ast_unparse(arg.annotation) or Parameter.empty\n-            params.append(Parameter(arg.arg, Parameter.POSITIONAL_ONLY,\n-                                    annotation=annotation))\n+        posonly = list(args.posonlyargs)  # type: ignore\n+    else:\n+        posonly = []\n \n-    for i, arg in enumerate(args.args):\n-        if len(args.args) - i <= len(args.defaults):\n-            default = ast_unparse(args.defaults[-len(args.args) + i])\n+    pos_args = posonly + list(args.args)\n+    num_pos = len(pos_args)\n+    num_defaults = len(args.defaults)\n+    start = num_pos - num_defaults\n+\n+    for i, arg in enumerate(posonly):\n+        if i >= start:\n+            default = ast_unparse(args.defaults[i - start])\n         else:\n             default = Parameter.empty\n+        annotation = ast_unparse(arg.annotation) or Parameter.empty\n+        params.append(Parameter(arg.arg, Parameter.POSITIONAL_ONLY,\n+                                default=default, annotation=annotation))\n \n+    for i, arg in enumerate(args.args):\n+        idx = len(posonly) + i\n+        if idx >= start:\n+            default = ast_unparse(args.defaults[idx - start])\n+        else:\n+            default = Parameter.empty\n         annotation = ast_unparse(arg.annotation) or Parameter.empty\n         params.append(Parameter(arg.arg, Parameter.POSITIONAL_OR_KEYWORD,\n                                 default=default, annotation=annotation))\n\n"
  },
  "sphinx-doc__sphinx-7985": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7985",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..e7a1a6742 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -209,11 +209,45 @@ class CheckExternalLinksBuilder(Builder):\n                     return 'redirected', new_url, 0\n \n         def check() -> Tuple[str, str, int]:\n-            # check for various conditions without bothering the network\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n             elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+                if '#' in uri:\n+                    req_url, anchor = uri.split('#', 1)\n+                    for rex in self.anchors_ignore:\n+                        if rex.match(anchor):\n+                            anchor = None\n+                            break\n+                else:\n+                    req_url = uri\n+                    anchor = None\n+                req = req_url.rstrip('/')\n+                if req in self.env.found_docs:\n+                    return 'working', '', 0\n+                source_suffix = self.app.config.source_suffix\n+                if isinstance(source_suffix, dict):\n+                    suffixes = list(source_suffix.keys())\n+                else:\n+                    try:\n+                        suffixes = list(source_suffix)\n+                    except TypeError:\n+                        suffixes = [source_suffix]\n+                for suffix in suffixes:\n+                    if suffix and req.endswith(suffix):\n+                        candidate = req[:-len(suffix)]\n+                        if candidate in self.env.found_docs:\n+                            return 'working', '', 0\n+                if req.endswith('.html'):\n+                    candidate = req[:-5]\n+                    if candidate in self.env.found_docs:\n+                        return 'working', '', 0\n+                docpath = path.join(self.env.srcdir, req)\n+                for suffix in suffixes:\n+                    if suffix and path.isfile(docpath + suffix):\n+                        return 'working', '', 0\n+                if path.isfile(docpath):\n+                    return 'working', '', 0\n+                return 'broken', 'local target not found', 0\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n@@ -224,7 +258,6 @@ class CheckExternalLinksBuilder(Builder):\n                 if rex.match(uri):\n                     return 'ignored', '', 0\n \n-            # need to actually check the URI\n             for _ in range(self.app.config.linkcheck_retries):\n                 status, info, code = check_uri()\n                 if status != \"broken\":\ndiff --git a/tmp_linkcheck/source/conf.py b/tmp_linkcheck/source/conf.py\nnew file mode 100644\nindex 000000000..6abdb41fd\n--- /dev/null\n+++ b/tmp_linkcheck/source/conf.py\n@@ -0,0 +1,4 @@\n+project = 'tmp'\n+master_doc = 'index'\n+extensions = []\n+source_suffix = ['.rst']\ndiff --git a/tmp_linkcheck/source/index.rst b/tmp_linkcheck/source/index.rst\nnew file mode 100644\nindex 000000000..774627841\n--- /dev/null\n+++ b/tmp_linkcheck/source/index.rst\n@@ -0,0 +1,5 @@\n+broken external-link_\n+broken local-link_\n+\n+.. _external-link: https://lkfqhlkghflkhs\n+.. _local-link: doesntexist\n\n"
  },
  "sphinx-doc__sphinx-8035": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8035",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 8c3509c3b..0bd595fcd 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -641,6 +641,7 @@ class Documenter:\n                         keep = False\n                     elif is_filtered_inherited_member(membername):\n                         keep = False\n+\n                     else:\n                         keep = has_doc or self.options.undoc_members\n                 elif self.options.special_members:\n@@ -649,18 +650,31 @@ class Documenter:\n             elif (namespace, membername) in attr_docs:\n                 if want_all and isprivate:\n                     # ignore members whose name starts with _ by default\n-                    keep = self.options.private_members\n+                    pm = self.options.private_members\n+                    if pm is ALL:\n+                        keep = True\n+                    elif pm:\n+                        keep = membername in pm\n+                    else:\n+                        keep = False\n+\n                 else:\n                     # keep documented attributes\n                     keep = True\n                 isattr = True\n             elif want_all and isprivate:\n                 # ignore members whose name starts with _ by default\n-                keep = self.options.private_members and \\\n-                    (has_doc or self.options.undoc_members)\n+                pm = self.options.private_members\n+                if pm is ALL:\n+                    keep = (has_doc or self.options.undoc_members)\n+                elif pm:\n+                    keep = (membername in pm) and (has_doc or self.options.undoc_members)\n+                else:\n+                    keep = False\n             else:\n                 if self.options.members is ALL and is_filtered_inherited_member(membername):\n                     keep = False\n+\n                 else:\n                     # ignore undocumented members if :undoc-members: is not given\n                     keep = has_doc or self.options.undoc_members\n@@ -859,7 +873,7 @@ class ModuleDocumenter(Documenter):\n         'show-inheritance': bool_option, 'synopsis': identity,\n         'platform': identity, 'deprecated': bool_option,\n         'member-order': member_order_option, 'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_set_option, 'special-members': members_option,\n         'imported-members': bool_option, 'ignore-module-all': bool_option\n     }  # type: Dict[str, Callable]\n \n@@ -1279,7 +1293,7 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         'noindex': bool_option, 'inherited-members': inherited_members_option,\n         'show-inheritance': bool_option, 'member-order': member_order_option,\n         'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_set_option, 'special-members': members_option,\n     }  # type: Dict[str, Callable]\n \n     _signature_class = None  # type: Any\n\n"
  },
  "sphinx-doc__sphinx-8056": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8056",
    "model_patch": "diff --git a/repro_napoleon.py b/repro_napoleon.py\nnew file mode 100644\nindex 000000000..c802d4e55\n--- /dev/null\n+++ b/repro_napoleon.py\n@@ -0,0 +1,10 @@\n+from sphinx.ext.napoleon.docstring import NumpyDocstring\n+doc = NumpyDocstring(\"\"\"Parameters\n+----------\n+x1, x2 : array_like, optional\n+    Input arrays, description of x1 and x2.\n+y : int\n+    Another param.\n+\"\"\", config=None)\n+lines = doc.lines()\n+print(\"\\n\".join(lines))\ndiff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..d1ab5cd3d 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -392,15 +392,20 @@ class GoogleDocstring:\n         lines = []\n         for _name, _type, _desc in fields:\n             _desc = self._strip_empty(_desc)\n+            names = [n.strip() for n in _name.split(',')] if _name else ['']\n             if any(_desc):\n                 _desc = self._fix_field_desc(_desc)\n-                field = ':%s %s: ' % (field_role, _name)\n+                first = names[0] if names else ''\n+                field = ':%s %s: ' % (field_role, first)\n                 lines.extend(self._format_block(field, _desc))\n+                for name in names[1:]:\n+                    lines.append(':%s %s:' % (field_role, name))\n             else:\n-                lines.append(':%s %s:' % (field_role, _name))\n-\n+                for name in names:\n+                    lines.append(':%s %s:' % (field_role, name))\n             if _type:\n-                lines.append(':%s %s: %s' % (type_role, _name, _type))\n+                for name in names:\n+                    lines.append(':%s %s: %s' % (type_role, name, _type))\n         return lines + ['']\n \n     def _format_field(self, _name: str, _type: str, _desc: List[str]) -> List[str]:\n@@ -683,6 +688,8 @@ class GoogleDocstring:\n     def _parse_parameters_section(self, section: str) -> List[str]:\n         fields = self._consume_fields()\n         if self._config.napoleon_use_param:\n+            if any(',' in (_name or '') for _name, _type, _desc in fields):\n+                return self._format_fields(_('Parameters'), fields)\n             return self._format_docutils_params(fields)\n         else:\n             return self._format_fields(_('Parameters'), fields)\n\n"
  },
  "sphinx-doc__sphinx-8265": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8265",
    "model_patch": "diff --git a/demo_signature.py b/demo_signature.py\nnew file mode 100644\nindex 000000000..37841b2b7\n--- /dev/null\n+++ b/demo_signature.py\n@@ -0,0 +1,10 @@\n+\n+from sphinx.util.inspect import signature_from_str, object_description\n+from sphinx.domains.python import _parse_arglist\n+from sphinx.addnodes import desc_parameterlist\n+print(signature_from_str('(lines, color=(1,1,1), width=5)').parameters)\n+# simulate _parse_arglist output ast-based defaults\n+pl = _parse_arglist('lines, color=(1,1,1), width=5')\n+print(\"paramlist astext:\", pl.astext())\n+for p in pl:\n+    print(type(p), p.astext())\ndiff --git a/demo_unparse.py b/demo_unparse.py\nnew file mode 100644\nindex 000000000..6959cd13d\n--- /dev/null\n+++ b/demo_unparse.py\n@@ -0,0 +1,8 @@\n+\n+import ast\n+from sphinx.pycode.ast import unparse\n+node = ast.parse('(1, 1, 1)', mode='eval').body\n+print(\"unparse:\", unparse(node))\n+# also test empty tuple\n+node2 = ast.parse('()', mode='eval').body\n+print(\"empty:\", unparse(node2))\ndiff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex 9bafff11c..38ea7ffa2 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -173,7 +173,7 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n-            return \", \".join(self.visit(e) for e in node.elts)\n+            return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n \n\n"
  },
  "sphinx-doc__sphinx-8269": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8269",
    "model_patch": "diff --git a/repro_proj/build_linkcheck/.doctrees/environment.pickle b/repro_proj/build_linkcheck/.doctrees/environment.pickle\nnew file mode 100644\nindex 000000000..bdefe9317\nBinary files /dev/null and b/repro_proj/build_linkcheck/.doctrees/environment.pickle differ\ndiff --git a/repro_proj/build_linkcheck/.doctrees/index.doctree b/repro_proj/build_linkcheck/.doctrees/index.doctree\nnew file mode 100644\nindex 000000000..5c7d550e3\nBinary files /dev/null and b/repro_proj/build_linkcheck/.doctrees/index.doctree differ\ndiff --git a/repro_proj/build_linkcheck/output.json b/repro_proj/build_linkcheck/output.json\nnew file mode 100644\nindex 000000000..16d7dabe4\n--- /dev/null\n+++ b/repro_proj/build_linkcheck/output.json\n@@ -0,0 +1 @@\n+{\"filename\": \"index.rst\", \"lineno\": 4, \"status\": \"broken\", \"code\": 0, \"uri\": \"http://127.0.0.1:8000/test.txt#test\", \"info\": \"404 Client Error: Not Found for url: http://127.0.0.1:8000/test.txt\"}\ndiff --git a/repro_proj/build_linkcheck/output.txt b/repro_proj/build_linkcheck/output.txt\nnew file mode 100644\nindex 000000000..bfb7ffbe7\n--- /dev/null\n+++ b/repro_proj/build_linkcheck/output.txt\n@@ -0,0 +1 @@\n+index.rst:4: [broken] http://127.0.0.1:8000/test.txt#test: 404 Client Error: Not Found for url: http://127.0.0.1:8000/test.txt\ndiff --git a/repro_proj/source/conf.py b/repro_proj/source/conf.py\nnew file mode 100644\nindex 000000000..1effb2bc7\n--- /dev/null\n+++ b/repro_proj/source/conf.py\n@@ -0,0 +1,3 @@\n+project = 'proj'\n+extensions = []\n+master_doc = 'index'\ndiff --git a/repro_proj/source/index.rst b/repro_proj/source/index.rst\nnew file mode 100644\nindex 000000000..1a622ac51\n--- /dev/null\n+++ b/repro_proj/source/index.rst\n@@ -0,0 +1,4 @@\n+Welcome\n+=======\n+\n+`foo <http://127.0.0.1:8000/test.txt#test>`_\ndiff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..c539b3bd4 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -163,23 +163,19 @@ class CheckExternalLinksBuilder(Builder):\n \n             try:\n                 if anchor and self.app.config.linkcheck_anchors:\n-                    # Read the whole document and see if #anchor exists\n                     response = requests.get(req_url, stream=True, config=self.app.config,\n                                             auth=auth_info, **kwargs)\n+                    response.raise_for_status()\n                     found = check_anchor(response, unquote(anchor))\n \n                     if not found:\n                         raise Exception(__(\"Anchor '%s' not found\") % anchor)\n                 else:\n                     try:\n-                        # try a HEAD request first, which should be easier on\n-                        # the server and the network\n                         response = requests.head(req_url, config=self.app.config,\n                                                  auth=auth_info, **kwargs)\n                         response.raise_for_status()\n                     except HTTPError:\n-                        # retry with GET request if that fails, some servers\n-                        # don't like HEAD requests.\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n                                                 auth=auth_info, **kwargs)\n                         response.raise_for_status()\ndiff --git a/test_server.py b/test_server.py\nnew file mode 100644\nindex 000000000..657b9ec62\n--- /dev/null\n+++ b/test_server.py\n@@ -0,0 +1,23 @@\n+\n+from http.server import HTTPServer, BaseHTTPRequestHandler\n+class Handler(BaseHTTPRequestHandler):\n+    def do_HEAD(self):\n+        self.do_GET()\n+    def do_GET(self):\n+        if self.path.startswith('/test.txt'):\n+            self.send_response(404)\n+            self.send_header('Content-Type', 'text/plain; charset=utf-8')\n+            self.end_headers()\n+            self.wfile.write(b'Not Found')\n+        else:\n+            self.send_response(200)\n+            self.send_header('Content-Type', 'text/html; charset=utf-8')\n+            self.end_headers()\n+            self.wfile.write(b'<html><body><a id=\"test\">ok</a></body></html>')\n+    def log_message(self, format, *args):\n+        pass\n+\n+if __name__ == \"__main__\":\n+    server = HTTPServer(('127.0.0.1', 8000), Handler)\n+    print(\"SERVING\")\n+    server.serve_forever()\n\n"
  },
  "sphinx-doc__sphinx-8475": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8475",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..104fbb970 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -20,7 +20,7 @@ from urllib.parse import unquote, urlparse\n \n from docutils import nodes\n from docutils.nodes import Node\n-from requests.exceptions import HTTPError\n+from requests.exceptions import HTTPError, TooManyRedirects\n \n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -166,15 +166,11 @@ class CheckExternalLinksBuilder(Builder):\n                         raise Exception(__(\"Anchor '%s' not found\") % anchor)\n                 else:\n                     try:\n-                        # try a HEAD request first, which should be easier on\n-                        # the server and the network\n                         response = requests.head(req_url, allow_redirects=True,\n                                                  config=self.app.config, auth=auth_info,\n                                                  **kwargs)\n                         response.raise_for_status()\n-                    except HTTPError:\n-                        # retry with GET request if that fails, some servers\n-                        # don't like HEAD requests.\n+                    except (HTTPError, TooManyRedirects):\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n                                                 auth=auth_info, **kwargs)\n                         response.raise_for_status()\ndiff --git a/test_linkcheck_too_many_redirects.py b/test_linkcheck_too_many_redirects.py\nnew file mode 100644\nindex 000000000..aa966865a\n--- /dev/null\n+++ b/test_linkcheck_too_many_redirects.py\n@@ -0,0 +1,41 @@\n+\n+import requests\n+from requests.exceptions import TooManyRedirects, HTTPError\n+import importlib, inspect, io, sys\n+\n+# confirm linkcheck.py has the updated except clause\n+with open(\"sphinx/builders/linkcheck.py\", \"r\") as f:\n+    src = f.read()\n+assert \"except (HTTPError, TooManyRedirects):\" in src, \"patch not found in linkcheck.py\"\n+\n+called = {\"get\": False, \"head\": False}\n+\n+def fake_head(*args, **kwargs):\n+    called[\"head\"] = True\n+    raise TooManyRedirects(\"too many redirects for HEAD\")\n+\n+class DummyResponse:\n+    def raise_for_status(self):\n+        return None\n+\n+def fake_get(*args, **kwargs):\n+    called[\"get\"] = True\n+    return DummyResponse()\n+\n+orig_head = requests.head\n+orig_get = requests.get\n+try:\n+    requests.head = fake_head\n+    requests.get = fake_get\n+    # mimic the try-except block from linkcheck to confirm fallback\n+    try:\n+        resp = requests.head(\"http://example.com\", allow_redirects=True)\n+        resp.raise_for_status()\n+    except (HTTPError, TooManyRedirects):\n+        resp = requests.get(\"http://example.com\", stream=True)\n+        resp.raise_for_status()\n+    assert called[\"head\"] and called[\"get\"], \"Fallback to GET did not occur\"\n+    print(\"TEST-PASSED\")\n+finally:\n+    requests.head = orig_head\n+    requests.get = orig_get\n\n"
  },
  "sphinx-doc__sphinx-8548": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8548",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex ddfd2b365..43c30ebe0 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -598,11 +598,27 @@ class Documenter:\n             attr_docs = self.analyzer.find_attr_docs()\n             if self.objpath:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n+                match_key = None\n                 if key in attr_docs:\n+                    match_key = key\n+                else:\n+                    try:\n+                        parent_obj = getattr(self, 'parent', None)\n+                        if parent_obj is not None:\n+                            for base in inspect.getmro(parent_obj):\n+                                qual = safe_getattr(base, '__qualname__', None)\n+                                if qual:\n+                                    key2 = (qual, self.objpath[-1])\n+                                    if key2 in attr_docs:\n+                                        match_key = key2\n+                                        break\n+                    except Exception:\n+                        match_key = None\n+                if match_key:\n                     no_docstring = True\n                     # make a copy of docstring for attributes to avoid cache\n                     # the change of autodoc-process-docstring event.\n-                    docstrings = [list(attr_docs[key])]\n+                    docstrings = [list(attr_docs[match_key])]\n \n                     for i, line in enumerate(self.process_doc(docstrings)):\n                         self.add_line(line, sourcename, i)\n@@ -746,7 +762,19 @@ class Documenter:\n                         keep = has_doc or self.options.undoc_members\n                 else:\n                     keep = False\n-            elif (namespace, membername) in attr_docs:\n+            found_ns = None\n+            if (namespace, membername) in attr_docs:\n+                found_ns = namespace\n+            else:\n+                try:\n+                    for base in inspect.getmro(self.parent):\n+                        qual = safe_getattr(base, '__qualname__', None)\n+                        if qual and (qual, membername) in attr_docs:\n+                            found_ns = qual\n+                            break\n+                except Exception:\n+                    found_ns = None\n+            if found_ns:\n                 if want_all and isprivate:\n                     if self.options.private_members is None:\n                         keep = False\n@@ -756,6 +784,8 @@ class Documenter:\n                     # keep documented attributes\n                     keep = True\n                 isattr = True\n+                if not doc:\n+                    doc = '\\n'.join(attr_docs[(found_ns, membername)])\n             elif want_all and isprivate:\n                 if has_doc or self.options.undoc_members:\n                     if self.options.private_members is None:\n\n"
  },
  "sphinx-doc__sphinx-8551": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8551",
    "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 404bb127f..51dc41875 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -290,11 +290,13 @@ class DocFieldTransformer:\n                         len(content) == 1 and isinstance(content[0], nodes.Text)):\n                     typed_field = cast(TypedField, typedesc)\n                     target = content[0].astext()\n+\n                     xrefs = typed_field.make_xrefs(\n                         typed_field.typerolename,\n                         self.directive.domain,\n                         target,\n                         contnode=content[0],\n+                        env=self.directive.env,\n                     )\n                     if _is_single_paragraph(field_body):\n                         paragraph = cast(nodes.paragraph, field_body[0])\n\n"
  },
  "sphinx-doc__sphinx-8638": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8638",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 000e2e8d3..02f63adab 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1149,17 +1149,23 @@ class PythonDomain(Domain):\n                     if fullname in self.objects and self.objects[fullname].objtype in objtypes:\n                         newname = fullname\n                 if not newname:\n-                    if modname and modname + '.' + name in self.objects and \\\n-                       self.objects[modname + '.' + name].objtype in objtypes:\n-                        newname = modname + '.' + name\n-                    elif name in self.objects and self.objects[name].objtype in objtypes:\n-                        newname = name\n-                    else:\n-                        # \"fuzzy\" searching mode\n-                        searchname = '.' + name\n-                        matches = [(oname, self.objects[oname]) for oname in self.objects\n-                                   if oname.endswith(searchname) and\n-                                   self.objects[oname].objtype in objtypes]\n+                # prefer module-local fuzzy matches when module specified\n+                searchname = '.' + name\n+                module_matches = []\n+                other_matches = []\n+                for oname, oentry in self.objects.items():\n+                    if oname.endswith(searchname) and oentry.objtype in objtypes:\n+                        if modname and oname.startswith(modname + '.'):\n+                            module_matches.append((oname, oentry))\n+                        else:\n+                            other_matches.append((oname, oentry))\n+                matches = module_matches + other_matches\n+                            # fallback fuzzy search across all objects\n+                            searchname = '.' + name\n+                            matches = [(oname, self.objects[oname]) for oname in self.objects\n+                                       if oname.endswith(searchname) and\n+                                       self.objects[oname].objtype in objtypes]\n+\n         else:\n             # NOTE: searching for exact match, object type is not considered\n             if name in self.objects:\ndiff --git a/test_fuzzy_search.py b/test_fuzzy_search.py\nnew file mode 100644\nindex 000000000..beb8fb27c\n--- /dev/null\n+++ b/test_fuzzy_search.py\n@@ -0,0 +1,23 @@\n+\n+from sphinx.domains.python import PythonDomain, ObjectEntry\n+# Prepare a domain and fake objects mapping\n+dom = PythonDomain(None)\n+# Simulate objects: keys are full names, values are ObjectEntry(docname, node_id, objtype, canonical)\n+# Create two modules with same attribute name 'somename'\n+dom.objects.clear()\n+dom.objects['pkg.subA.Foo.somename'] = ObjectEntry('docA', 'idA', 'attr', False)\n+dom.objects['pkg.subB.Bar.somename'] = ObjectEntry('docB', 'idB', 'attr', False)\n+# Also a global 'somename'\n+dom.objects['somename'] = ObjectEntry('docG', 'idG', 'data', False)\n+\n+# Case 1: modname provided -> should prefer same module fuzzy match (pkg.subA)\n+matches = dom.find_obj(None, 'pkg.subA', 'Foo', 'somename', None, searchmode=1)\n+print('matches_mod_pkg_subA:', [m[0] for m in matches])\n+\n+# Case 2: modname provided for subB -> should prefer pkg.subB\n+matches2 = dom.find_obj(None, 'pkg.subB', 'Bar', 'somename', None, searchmode=1)\n+print('matches_mod_pkg_subB:', [m[0] for m in matches2])\n+\n+# Case 3: no modname -> may match both fuzzy results (endswith)\n+matches3 = dom.find_obj(None, None, None, 'somename', None, searchmode=1)\n+print('matches_no_mod:', sorted([m[0] for m in matches3]))\ndiff --git a/test_fuzzy_search_env.py b/test_fuzzy_search_env.py\nnew file mode 100644\nindex 000000000..aae6b9548\n--- /dev/null\n+++ b/test_fuzzy_search_env.py\n@@ -0,0 +1,21 @@\n+\n+from sphinx.domains.python import PythonDomain, ObjectEntry\n+class DummyEnv:\n+    def __init__(self):\n+        self.domaindata = {}\n+dummy_env = DummyEnv()\n+dom = PythonDomain(dummy_env)\n+dom.env = dummy_env\n+dom.objects.clear()\n+dom.objects['pkg.subA.Foo.somename'] = ObjectEntry('docA', 'idA', 'attribute', False)\n+dom.objects['pkg.subB.Bar.somename'] = ObjectEntry('docB', 'idB', 'attribute', False)\n+dom.objects['somename'] = ObjectEntry('docG', 'idG', 'data', False)\n+\n+matches = dom.find_obj(dummy_env, 'pkg.subA', 'Foo', 'somename', None, searchmode=1)\n+print('matches_mod_pkg_subA:', [m[0] for m in matches])\n+\n+matches2 = dom.find_obj(dummy_env, 'pkg.subB', 'Bar', 'somename', None, searchmode=1)\n+print('matches_mod_pkg_subB:', [m[0] for m in matches2])\n+\n+matches3 = dom.find_obj(dummy_env, None, None, 'somename', None, searchmode=1)\n+print('matches_no_mod:', sorted([m[0] for m in matches3]))\n\n"
  },
  "sphinx-doc__sphinx-8721": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8721",
    "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..d625e1526 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -184,6 +184,8 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n         return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n \n     modnames = set(env._viewcode_modules)  # type: ignore\n \ndiff --git a/test_viewcode_epub.py b/test_viewcode_epub.py\nnew file mode 100644\nindex 000000000..667d72166\n--- /dev/null\n+++ b/test_viewcode_epub.py\n@@ -0,0 +1,31 @@\n+\n+from sphinx.ext import viewcode\n+class Config:\n+    viewcode_enable_epub = False\n+    highlight_language = 'python3'\n+class Env:\n+    pass\n+env = Env()\n+env._viewcode_modules = {'pkg.mod': ('code', {'a': ('func', 0, 1)}, {'a': 'doc'}, 'pkg')}\n+env.config = Config()\n+class Builder:\n+    def __init__(self):\n+        self.name = 'epub'\n+        self.env = env\n+        self.outdir = 'out'\n+        class Highlighter:\n+            def highlight_block(self, code, lexer, linenos=False):\n+                return '<pre>'+code+'</pre>'\n+        self.highlighter = Highlighter()\n+    def get_relative_uri(self, a, b):\n+        return 'rel'\n+builder = Builder()\n+app = type('A', (), {'builder': builder})()\n+res = list(viewcode.collect_pages(app))\n+print('RESULT_COUNT:', len(res))\n+if len(res) == 0:\n+    print('PASS')\n+    raise SystemExit(0)\n+else:\n+    print('FAIL')\n+    raise SystemExit(2)\ndiff --git a/test_viewcode_html.py b/test_viewcode_html.py\nnew file mode 100644\nindex 000000000..f40a612fd\n--- /dev/null\n+++ b/test_viewcode_html.py\n@@ -0,0 +1,31 @@\n+\n+from sphinx.ext import viewcode\n+class Config:\n+    viewcode_enable_epub = False\n+    highlight_language = 'python3'\n+class Env:\n+    pass\n+env = Env()\n+env._viewcode_modules = {'pkg.mod': ('code', {'a': ('func', 0, 1)}, {'a': 'doc'}, 'pkg')}\n+env.config = Config()\n+class Builder:\n+    def __init__(self):\n+        self.name = 'html'\n+        self.env = env\n+        self.outdir = 'out'\n+        class Highlighter:\n+            def highlight_block(self, code, lexer, linenos=False):\n+                return '<pre>'+code+'</pre>'\n+        self.highlighter = Highlighter()\n+    def get_relative_uri(self, a, b):\n+        return 'rel'\n+builder = Builder()\n+app = type('A', (), {'builder': builder, 'verbosity': 0})()\n+res = list(viewcode.collect_pages(app))\n+print('RESULT_COUNT:', len(res))\n+if len(res) > 0:\n+    print('PASS')\n+    raise SystemExit(0)\n+else:\n+    print('FAIL')\n+    raise SystemExit(2)\ndiff --git a/test_viewcode_html_full.py b/test_viewcode_html_full.py\nnew file mode 100644\nindex 000000000..786d62e0f\n--- /dev/null\n+++ b/test_viewcode_html_full.py\n@@ -0,0 +1,38 @@\n+\n+from sphinx.ext import viewcode\n+class Config:\n+    viewcode_enable_epub = False\n+    highlight_language = 'python3'\n+class Env:\n+    pass\n+env = Env()\n+env._viewcode_modules = {'pkg.mod': ('code', {'a': ('func', 0, 1)}, {'a': 'doc'}, 'pkg')}\n+env.config = Config()\n+class Builder:\n+    def __init__(self):\n+        self.name = 'html'\n+        self.env = env\n+        self.outdir = 'out'\n+        self.out_suffix = '.html'\n+        class Highlighter:\n+            def highlight_block(self, code, lexer, linenos=False):\n+                return '<pre>'+code+'</pre>'\n+        self.highlighter = Highlighter()\n+    def get_relative_uri(self, a, b):\n+        return 'rel'\n+builder = Builder()\n+class App:\n+    def __init__(self, builder):\n+        self.builder = builder\n+        self.verbosity = 0\n+    def emit_firstresult(self, *args, **kwargs):\n+        return None\n+app = App(builder)\n+res = list(viewcode.collect_pages(app))\n+print('RESULT_COUNT:', len(res))\n+if len(res) > 0:\n+    print('PASS')\n+    raise SystemExit(0)\n+else:\n+    print('FAIL')\n+    raise SystemExit(2)\n\n"
  },
  "sphinx-doc__sphinx-9229": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9229",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 1f4c98284..bf76d80e0 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1795,7 +1795,6 @@ class GenericAliasMixin(DataDocumenterMixinBase):\n     def should_suppress_directive_header(self) -> bool:\n         return (inspect.isgenericalias(self.object) or\n                 super().should_suppress_directive_header())\n-\n     def update_content(self, more_content: StringList) -> None:\n         if inspect.isgenericalias(self.object):\n             more_content.append(_('alias of %s') % restify(self.object), '')\n@@ -1813,7 +1812,6 @@ class NewTypeMixin(DataDocumenterMixinBase):\n     def should_suppress_directive_header(self) -> bool:\n         return (inspect.isNewType(self.object) or\n                 super().should_suppress_directive_header())\n-\n     def update_content(self, more_content: StringList) -> None:\n         if inspect.isNewType(self.object):\n             supertype = restify(self.object.__supertype__)\n@@ -1864,6 +1862,23 @@ class TypeVarMixin(DataDocumenterMixinBase):\n \n         super().update_content(more_content)\n \n+    def update_content(self, more_content: StringList) -> None:\n+        if isinstance(self.object, TypeVar):\n+            attrs = [repr(self.object.__name__)]\n+            for constraint in self.object.__constraints__:\n+                attrs.append(stringify_typehint(constraint))\n+            if self.object.__bound__:\n+                attrs.append(r\"bound=\\ \" + restify(self.object.__bound__))\n+            if self.object.__covariant__:\n+                attrs.append(\"covariant=True\")\n+            if self.object.__contravariant__:\n+                attrs.append(\"contravariant=True\")\n+\n+            more_content.append(_('alias of TypeVar(%s)') % \", \".join(attrs), '')\n+            more_content.append('', '')\n+\n+        super().update_content(more_content)\n+\n \n class UninitializedGlobalVariableMixin(DataDocumenterMixinBase):\n     \"\"\"\n\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..6d48e910c 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -298,7 +298,7 @@ class DocFieldTransformer:\n             # also support syntax like ``:param type name:``\n             if typedesc.is_typed:\n                 try:\n-                    argtype, argname = fieldarg.split(None, 1)\n+                    argtype, argname = fieldarg.rsplit(None, 1)\n                 except ValueError:\n                     pass\n                 else:\ndiff --git a/test_docfields_edge.py b/test_docfields_edge.py\nnew file mode 100644\nindex 000000000..da90b7880\n--- /dev/null\n+++ b/test_docfields_edge.py\n@@ -0,0 +1,30 @@\n+\n+from sphinx.util.docfields import TypedField, DocFieldTransformer\n+from docutils import nodes\n+from types import SimpleNamespace\n+\n+def run_case(field_text):\n+    field_name = nodes.field_name('', nodes.Text(field_text))\n+    paragraph = nodes.paragraph('', nodes.Text('(optional)'))\n+    field_body = nodes.field_body('', paragraph)\n+    field = nodes.field('', field_name, field_body)\n+    field_list = nodes.field_list('', field)\n+    parent = nodes.container()\n+    parent += field_list\n+\n+    typed = TypedField('parameter', names=('param',), typenames=('type',),\n+                       label='Parameters', rolename='param', typerolename='type',\n+                       can_collapse=False)\n+\n+    fake_directive = SimpleNamespace()\n+    fake_directive.get_field_type_map = lambda: {'param': (typed, False)}\n+    fake_directive.domain = 'py'\n+    fake_directive.state = SimpleNamespace(document=SimpleNamespace(settings=SimpleNamespace(env=None)))\n+\n+    transformer = DocFieldTransformer(fake_directive)\n+    transformer.transform(field_list)\n+    new_node = parent[0]\n+    print(field_text, '->', new_node.astext())\n+\n+run_case('param dict(str, str) opc_meta')\n+run_case('param dict(str,str) opc_meta')\ndiff --git a/test_docfields_rsplit.py b/test_docfields_rsplit.py\nnew file mode 100644\nindex 000000000..ec43f0144\n--- /dev/null\n+++ b/test_docfields_rsplit.py\n@@ -0,0 +1,29 @@\n+\n+from sphinx.util.docfields import TypedField, DocFieldTransformer\n+from docutils import nodes\n+from types import SimpleNamespace\n+\n+field_name = nodes.field_name('', nodes.Text('param dict(str, str) opc_meta'))\n+paragraph = nodes.paragraph('', nodes.Text('(optional)'))\n+field_body = nodes.field_body('', paragraph)\n+field = nodes.field('', field_name, field_body)\n+field_list = nodes.field_list('', field)\n+\n+parent = nodes.container()\n+parent += field_list\n+\n+typed = TypedField('parameter', names=('param',), typenames=('type',),\n+                   label='Parameters', rolename='param', typerolename='type',\n+                   can_collapse=False)\n+\n+fake_directive = SimpleNamespace()\n+fake_directive.get_field_type_map = lambda: {'param': (typed, False)}\n+fake_directive.domain = 'py'\n+fake_directive.state = SimpleNamespace(document=SimpleNamespace(settings=SimpleNamespace(env=None)))\n+\n+transformer = DocFieldTransformer(fake_directive)\n+transformer.transform(field_list)\n+\n+new_node = parent[0]\n+print('PARENT_CHILD_AS_TEXT:', new_node.astext())\n+print('PARENT_CHILD_REPR:', repr(new_node))\n\n"
  },
  "sphinx-doc__sphinx-9281": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9281",
    "model_patch": "diff --git a/quick_test_enum.py b/quick_test_enum.py\nnew file mode 100644\nindex 000000000..9ef79ebe6\n--- /dev/null\n+++ b/quick_test_enum.py\n@@ -0,0 +1,12 @@\n+from enum import Enum\n+import inspect\n+from sphinx.util.inspect import stringify_signature\n+\n+class MyEnum(Enum):\n+    ValueA = 10\n+\n+def ugly_enum_func(e: MyEnum = MyEnum.ValueA) -> None:\n+    pass\n+\n+sig = inspect.signature(ugly_enum_func)\n+print(stringify_signature(sig))\ndiff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex a415a7074..23b600bdf 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -431,7 +431,6 @@ def safe_getattr(obj: Any, name: str, *defargs: Any) -> Any:\n \n \n def object_description(object: Any) -> str:\n-    \"\"\"A repr() implementation that returns text safe to use in reST context.\"\"\"\n     if isinstance(object, dict):\n         try:\n             sorted_keys = sorted(object)\n@@ -457,12 +456,20 @@ def object_description(object: Any) -> str:\n         else:\n             return \"frozenset({%s})\" % \", \".join(object_description(x)\n                                                  for x in sorted_values)\n+    # Render Enum members as ClassName.MemberName instead of their repr like <MyEnum.Value: 1>\n+    try:\n+        import enum as _enum_module\n+    except Exception:\n+        _enum_module = None\n+    if _enum_module is not None and isinstance(object, _enum_module.Enum):\n+        try:\n+            return \"%s.%s\" % (object.__class__.__name__, object.name)\n+        except Exception:\n+            pass\n     try:\n         s = repr(object)\n     except Exception as exc:\n         raise ValueError from exc\n-    # Strip non-deterministic memory addresses such as\n-    # ``<__main__.A at 0x7f68cb685710>``\n     s = memory_address_re.sub('', s)\n     return s.replace('\\n', ' ')\n \n\n"
  },
  "sphinx-doc__sphinx-9320": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9320",
    "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..8e8ceb943 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -136,18 +136,16 @@ def do_prompt(text: str, default: str = None, validator: Callable[[str], Any] =\n         else:\n             prompt = PROMPT_PREFIX + text + ': '\n         if USE_LIBEDIT:\n-            # Note: libedit has a problem for combination of ``input()`` and escape\n-            # sequence (see #5335).  To avoid the problem, all prompts are not colored\n-            # on libedit.\n             pass\n         elif readline:\n-            # pass input_mode=True if readline available\n             prompt = colorize(COLOR_QUESTION, prompt, input_mode=True)\n         else:\n             prompt = colorize(COLOR_QUESTION, prompt, input_mode=False)\n         x = term_input(prompt).strip()\n         if default and not x:\n             x = default\n+        if x == '' and default == '':\n+            return x\n         try:\n             x = validator(x)\n         except ValidationError as err:\ndiff --git a/test_quickstart_exit.py b/test_quickstart_exit.py\nnew file mode 100644\nindex 000000000..cfaa6c88c\n--- /dev/null\n+++ b/test_quickstart_exit.py\n@@ -0,0 +1,16 @@\n+import os, tempfile, sys\n+from sphinx.cmd import quickstart as qs\n+d = {}\n+td = tempfile.mkdtemp()\n+open(os.path.join(td, 'conf.py'), 'w').write('# conf')\n+cwd = os.getcwd()\n+os.chdir(td)\n+qs.term_input = lambda prompt: ''  # simulate pressing Enter\n+try:\n+    qs.ask_user(d)\n+except SystemExit as e:\n+    print('EXIT', e.code)\n+else:\n+    print('NOEXIT')\n+finally:\n+    os.chdir(cwd)\n\n"
  },
  "sphinx-doc__sphinx-9367": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9367",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..713f4426e 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -214,7 +214,10 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n-            return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n+            if len(node.elts) == 1:\n+                return \"(\" + self.visit(node.elts[0]) + \",)\"\n+            else:\n+                return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n \ndiff --git a/tmp_check_unparse.py b/tmp_check_unparse.py\nnew file mode 100644\nindex 000000000..26a18d739\n--- /dev/null\n+++ b/tmp_check_unparse.py\n@@ -0,0 +1,9 @@\n+\n+from sphinx.pycode import ast as pyast\n+def check(expr):\n+    node = pyast.parse(expr, mode='eval')\n+    out = pyast.unparse(node.body, expr)\n+    print(expr, \"->\", out)\n+tests = [\"(1,)\", \"(1)\", \"(1,2)\", \"()\", \"(a,)\", \"(a)\"]\n+for t in tests:\n+    check(t)\n\n"
  },
  "sphinx-doc__sphinx-9461": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9461",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 1cecb1f79..91c7a35b4 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -2661,7 +2661,24 @@ class PropertyDocumenter(DocstringStripSignatureMixin, ClassLevelDocumenter):  #\n     @classmethod\n     def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n                             ) -> bool:\n-        return inspect.isproperty(member) and isinstance(parent, ClassDocumenter)\n+        if inspect.isproperty(member) and isinstance(parent, ClassDocumenter):\n+            return True\n+        try:\n+            parent_obj = getattr(parent, 'object', None)\n+            if parent_obj is None:\n+                return False\n+            raw = getattr(parent_obj, '__dict__', {}).get(membername, None)\n+            if raw is None:\n+                return False\n+            if inspect.isproperty(raw):\n+                return True\n+            if isinstance(raw, (classmethod, staticmethod)):\n+                func = getattr(raw, '__func__', None)\n+                if inspect.isproperty(func):\n+                    return True\n+        except Exception:\n+            pass\n+        return False\n \n     def document_members(self, all_members: bool = False) -> None:\n         pass\ndiff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 23dd9e930..8afe0296d 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -384,13 +384,20 @@ def iscoroutinefunction(obj: Any) -> bool:\n \n \n def isproperty(obj: Any) -> bool:\n-    \"\"\"Check if the object is property.\"\"\"\n     if sys.version_info >= (3, 8):\n         from functools import cached_property  # cached_property is available since py3.8\n         if isinstance(obj, cached_property):\n             return True\n \n-    return isinstance(obj, property)\n+    # Unwrap classmethod/staticmethod that may wrap property descriptors (py3.9+ allows this).\n+    unwrapped = obj\n+    try:\n+        if isinstance(obj, (classmethod, staticmethod)):\n+            unwrapped = getattr(obj, '__func__', obj)\n+    except Exception:\n+        unwrapped = obj\n+\n+    return isinstance(unwrapped, property)\n \n \n def isgenericalias(obj: Any) -> bool:\n\n"
  },
  "sphinx-doc__sphinx-9698": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9698",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..1a3bd60c7 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -796,7 +796,7 @@ class PyMethod(PyObject):\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n+            return _('%s (%s property)') % (methname, clsname)\n         elif 'staticmethod' in self.options:\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\ndiff --git a/tests/test_domain_py.py b/tests/test_domain_py.py\nindex 682ea76e1..5ba63d0e3 100644\n--- a/tests/test_domain_py.py\n+++ b/tests/test_domain_py.py\n@@ -756,7 +756,7 @@ def test_pymethod_options(app):\n \n     # :property:\n     assert_node(doctree[1][1][8], addnodes.index,\n-                entries=[('single', 'meth5() (Class property)', 'Class.meth5', '', None)])\n+                entries=[('single', 'meth5 (Class property)', 'Class.meth5', '', None)])\n     assert_node(doctree[1][1][9], ([desc_signature, ([desc_annotation, (\"property\", desc_sig_space)],\n                                                      [desc_name, \"meth5\"])],\n                                    [desc_content, ()]))\n\n"
  }
}