{
  "django__django-11790": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11790",
    "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..b88fe8a567 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -192,6 +192,11 @@ class AuthenticationForm(forms.Form):\n         # Set the max length and label for the \"username\" field.\n         self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n         self.fields['username'].max_length = self.username_field.max_length or 254\n+        # Ensure the rendered widget includes the maxlength HTML attribute (regression fix)\n+        try:\n+            self.fields['username'].widget.attrs['maxlength'] = self.fields['username'].max_length\n+        except Exception:\n+            pass\n         if self.fields['username'].label is None:\n             self.fields['username'].label = capfirst(self.username_field.verbose_name)\n \n"
  },
  "django__django-11815": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11815",
    "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..e27a257104 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,11 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        # Prefer serializing by member name (EnumClass['NAME']) rather than by value\n+        # to avoid issues when the value is translated (e.g., gettext_lazy).\n+        name_string, name_imports = serializer_factory(self.value.name).serialize()\n+        imports = {'import %s' % module, *name_imports}\n+        return \"%s.%s[%s]\" % (module, enum_class.__name__, name_string), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\n"
  },
  "django__django-11848": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11848",
    "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..75456f1a9d 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,16 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            # Interpret two-digit years using a rolling 50-year window as per RFC7231:\n+            # map the two-digit year to the century that makes it closest but if the\n+            # resulting year would be more than 50 years in the future, use the\n+            # previous century.\n+            now_year = datetime.datetime.utcnow().year\n+            century_base = (now_year // 100) * 100\n+            candidate = century_base + year\n+            if candidate - now_year > 50:\n+                candidate -= 100\n+            year = candidate\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n"
  },
  "django__django-11880": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11880",
    "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..84522d782f 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -200,6 +200,14 @@ class Field:\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        # Ensure error_messages dict is deep-copied so copies don't share the same mapping.\n+        try:\n+            result.error_messages = copy.deepcopy(getattr(self, 'error_messages', None), memo)\n+        except Exception:\n+            if hasattr(self, 'error_messages') and self.error_messages is not None:\n+                result.error_messages = dict(self.error_messages)\n+            else:\n+                result.error_messages = getattr(self, 'error_messages', None)\n         return result\n \n \n"
  },
  "django__django-11885": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11885",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..5c23d26375 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -67,8 +67,10 @@ class Collector:\n         # Initially, {model: {instances}}, later values become lists.\n         self.data = {}\n         self.field_updates = {}  # {model: {(field, value): {instances}}}\n-        # fast_deletes is a list of queryset-likes that can be deleted without\n-        # fetching the objects into memory.\n+        # fast_deletes is a list of tuples (queryset-like, field_name) where\n+        # field_name is the field used in the filter (e.g. 'from_id' or None).\n+        # This allows combining deletes for the same table/field by OR-ing the\n+        # IN-lists into a single delete.\n         self.fast_deletes = []\n \n         # Tracks deletion-order dependency for databases without transactions\n@@ -191,7 +193,8 @@ class Collector:\n         If 'keep_parents' is True, data of parent model's will be not deleted.\n         \"\"\"\n         if self.can_fast_delete(objs):\n-            self.fast_deletes.append(objs)\n+            # Top-level fast delete (no specific originating field)\n+            self.fast_deletes.append((objs, None))\n             return\n         new_objs = self.add(objs, source, nullable,\n                             reverse_dependency=reverse_dependency)\n@@ -225,7 +228,9 @@ class Collector:\n                 for batch in batches:\n                     sub_objs = self.related_objects(related, batch)\n                     if self.can_fast_delete(sub_objs, from_field=field):\n-                        self.fast_deletes.append(sub_objs)\n+                        # Record the originating field name so deletes on the same\n+                        # table/field can be combined later.\n+                        self.fast_deletes.append((sub_objs, field.name))\n                     else:\n                         related_model = related.related_model\n                         # Non-referenced fields can be deferred if no signal\n@@ -309,10 +314,40 @@ class Collector:\n                         sender=model, instance=obj, using=self.using\n                     )\n \n-            # fast deletes\n-            for qs in self.fast_deletes:\n-                count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+            # fast deletes: combine by model and filtering field when possible\n+            if self.fast_deletes:\n+                # group by (model, field_name)\n+                groups = {}\n+                for item, fname in self.fast_deletes:\n+                    model = item.model if hasattr(item, 'model') else type(item)\n+                    key = (model, fname)\n+                    groups.setdefault(key, []).append(item)\n+                for (model, fname), qss in groups.items():\n+                    if fname is None:\n+                        # these are raw querysets; execute each as-is\n+                        for qs in qss:\n+                            count = qs._raw_delete(using=self.using)\n+                            deleted_counter[qs.model._meta.label] += count\n+                    else:\n+                        # combine pks from all querysets into one IN filter on fname\n+                        pks = []\n+                        for qs in qss:\n+                            # try to extract values from the queryset by evaluating pks\n+                            try:\n+                                pks.extend(list(qs.values_list(fname.replace('_id',''), flat=True)))\n+                            except Exception:\n+                                # fallback: iterate over queryset instances\n+                                try:\n+                                    pks.extend([getattr(obj, model._meta.pk.attname) for obj in qs])\n+                                except Exception:\n+                                    pass\n+                        # normalize pks\n+                        pks = [pk for pk in pks if pk is not None]\n+                        if pks:\n+                            manager = model._base_manager.using(self.using)\n+                            delete_qs = manager.filter(**{f\"%s__in\" % fname: pks})\n+                            count = delete_qs._raw_delete(using=self.using)\n+                            deleted_counter[model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n"
  },
  "django__django-11951": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11951",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..afed4bd83d 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,8 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+        max_batch = max(ops.bulk_batch_size(fields, objs), 1)\n+        batch_size = min(batch_size, max_batch) if batch_size else max_batch\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n"
  },
  "django__django-11964": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11964",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..81dfecf78b 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,7 +60,10 @@ class ChoicesMeta(enum.EnumMeta):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n-    pass\n+    def __str__(self):\n+        # Return the underlying value for string coercion so newly created\n+        # model instances behave the same as retrieved ones for TextChoices\n+        return str(self.value)\n \n \n class IntegerChoices(int, Choices):\n"
  },
  "django__django-11999": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11999",
    "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..cdebb5e5a1 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,10 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            # Respect user-defined get_<field>_display on the model class\n+            if not hasattr(cls, 'get_%s_display' % self.name):\n+                setattr(cls, 'get_%s_display' % self.name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n"
  },
  "django__django-12039": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12039",
    "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..528a47f8c2 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -113,10 +113,14 @@ class IndexColumns(Columns):\n             # Index.__init__() guarantees that self.opclasses is the same\n             # length as self.columns.\n             col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n+            # Only append col_suffix if it exists and is non-empty to avoid\n+            # stray whitespace when an empty string is provided for ascending order.\n             try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n+                suffix = self.col_suffixes[idx]\n             except IndexError:\n-                pass\n+                suffix = ''\n+            if suffix:\n+                col = '{} {}'.format(col, suffix)\n             return col\n \n         return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n"
  },
  "django__django-12050": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12050",
    "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..37476e301b 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1073,7 +1073,12 @@ class Query(BaseExpression):\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n-            value = tuple(resolved_values)\n+            try:\n+                # Preserve the original iterable type (list/tuple or subclasses).\n+                value = type(value)(resolved_values)\n+            except Exception:\n+                # Fall back to tuple for unknown/unsupported types.\n+                value = tuple(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n"
  },
  "django__django-12143": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12143",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..a100f1c499 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1631,7 +1631,7 @@ class ModelAdmin(BaseModelAdmin):\n \n     def _get_edited_object_pks(self, request, prefix):\n         \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name))\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\n"
  },
  "django__django-12155": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12155",
    "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..aa663ead5b 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,7 +34,7 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n+    indent = min((len(line) - len(line.lstrip()) for line in lines[1:] if line.lstrip()), default=0)\n     trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n     return \"\\n\".join(trimmed).strip()\n \n"
  },
  "django__django-12193": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12193",
    "model_patch": "diff --git a/django/contrib/postgres/forms/array.py b/django/contrib/postgres/forms/array.py\nindex 2e19cd574a..37ca071216 100644\n--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -147,7 +147,7 @@ class SplitArrayWidget(forms.Widget):\n             if id_:\n                 final_attrs = {**final_attrs, 'id': '%s_%s' % (id_, i)}\n             context['widget']['subwidgets'].append(\n-                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs)['widget']\n+                self.widget.get_context(name + '_%s' % i, widget_value, dict(final_attrs))['widget']\n             )\n         return context\n \n"
  },
  "django__django-12209": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12209",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..30b60cfc41 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -840,6 +840,10 @@ class Model(metaclass=ModelBase):\n                        if f.name in update_fields or f.attname in update_fields]\n \n         pk_val = self._get_pk_val(meta)\n+        # Remember whether a PK was already set on the instance prior to any\n+        # automatic default generation so we can tell apart an explicit PK\n+        # assignment from a PK generated by field.default.\n+        pk_was_set = pk_val is not None\n         if pk_val is None:\n             pk_val = meta.pk.get_pk_value_on_save(self)\n             setattr(self, meta.pk.attname, pk_val)\n@@ -847,10 +851,12 @@ class Model(metaclass=ModelBase):\n         if not pk_set and (force_update or update_fields):\n             raise ValueError(\"Cannot force an update in save() with no primary key.\")\n         updated = False\n-        # Skip an UPDATE when adding an instance and primary key has a default.\n+        # Skip an UPDATE when adding an instance and primary key has a default,\n+        # but only when the PK was not explicitly provided on the instance.\n         if (\n             not force_insert and\n             self._state.adding and\n+            not pk_was_set and\n             self._meta.pk.default and\n             self._meta.pk.default is not NOT_PROVIDED\n         ):\n"
  },
  "django__django-12262": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12262",
    "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..ee62b05006 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -261,7 +261,7 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if kwarg:\n             # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n+            if param not in params and param not in unhandled_kwargs and param not in kwonly and varkw is None:\n                 # An unexpected keyword argument was supplied\n                 raise TemplateSyntaxError(\n                     \"'%s' received unexpected keyword argument '%s'\" %\n"
  },
  "django__django-12273": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12273",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 844c01e95e..f498f7cc6f 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -569,7 +569,14 @@ class Model(metaclass=ModelBase):\n         return getattr(self, meta.pk.attname)\n \n     def _set_pk_val(self, value):\n-        return setattr(self, self._meta.pk.attname, value)\n+        # When the primary key is set to None, the instance should be\n+        # considered unsaved (adding=True) so that save() performs an\n+        # INSERT rather than an UPDATE. See ticket: reset primary key.\n+        setattr(self, self._meta.pk.attname, value)\n+        if value is None:\n+            # Mark the instance as adding so subsequent save() creates a new row.\n+            self._state.adding = True\n+        return None\n \n     pk = property(_get_pk_val, _set_pk_val)\n \ndiff --git a/tests/repro_reset_pk.py b/tests/repro_reset_pk.py\nnew file mode 100644\nindex 0000000000..dd318470d1\n--- /dev/null\n+++ b/tests/repro_reset_pk.py\n@@ -0,0 +1,41 @@\n+from django.conf import settings\n+import django\n+from django.db import models, connection\n+import uuid\n+\n+settings.configure(\n+    DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},\n+    INSTALLED_APPS=['tests'],\n+)\n+django.setup()\n+\n+class Item(models.Model):\n+    uid = models.AutoField(primary_key=True, editable=False)\n+    f = models.BooleanField(default=False)\n+    class Meta:\n+        app_label = 'tests'\n+\n+    def reset(self):\n+        self.uid = None\n+        self.f = False\n+\n+class Derived(Item):\n+    class Meta:\n+        app_label = 'tests'\n+\n+# create tables\n+with connection.schema_editor() as editor:\n+    editor.create_model(Item)\n+    editor.create_model(Derived)\n+\n+# create instance\n+d = Derived.objects.create(f=True)\n+print(\"created:\", d.pk, d.f, type(d.pk))\n+item = Item.objects.get(pk=d.pk)\n+obj1 = item.derived\n+obj1.reset()\n+print(\"after reset:\", obj1.pk, obj1.f)\n+obj1.save()\n+print(\"after save, original pk:\", d.pk)\n+obj = Item.objects.get(pk=d.pk)\n+print(\"loaded:\", obj.pk, obj.f)\nPatched base._set_pk_val\n---running repro---\ncreated: 1 True <class 'int'>\nafter reset: 1 False\nafter save, original pk: 1\nloaded: 1 False\n---done---\nSubmitting...\n"
  },
  "django__django-12276": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12276",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..983b032555 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -376,21 +376,18 @@ class FileInput(Input):\n     needs_multipart_form = True\n     template_name = 'django/forms/widgets/file.html'\n \n-    def format_value(self, value):\n-        \"\"\"File input never renders a value.\"\"\"\n-        return\n-\n-    def value_from_datadict(self, data, files, name):\n-        \"File widgets take data from FILES, not POST\"\n-        return files.get(name)\n-\n-    def value_omitted_from_data(self, data, files, name):\n-        return name not in files\n-\n+    def use_required_attribute(self, initial):\n+        \"\"\"For file inputs, don't render 'required' when an initial\n+        file value exists (e.g. editing an instance with a saved file).\n+        If an initial value is present, do not render the required attribute.\n+        \"\"\"\n+        # If there is an existing initial file value, do not mark the input required.\n+        if initial not in (None, ''):\n+            return False\n+        return bool(self.is_required)\n \n FILE_INPUT_CONTRADICTION = object()\n \n-\n class ClearableFileInput(FileInput):\n     clear_checkbox_label = _('Clear')\n     initial_text = _('Currently')\n@@ -451,8 +448,6 @@ class ClearableFileInput(FileInput):\n             return False\n         return upload\n \n-    def use_required_attribute(self, initial):\n-        return super().use_required_attribute(initial) and not initial\n \n     def value_omitted_from_data(self, data, files, name):\n         return (\n"
  },
  "django__django-12304": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12304",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex f48143ddaf..b6638b4763 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -26,6 +26,7 @@ class ChoicesMeta(enum.EnumMeta):\n             # assignment in enum's classdict.\n             dict.__setitem__(classdict, key, value)\n         cls = super().__new__(metacls, classname, bases, classdict)\n+        cls.do_not_call_in_templates = True\n         cls._value2label_map_ = dict(zip(cls._value2member_map_, labels))\n         # Add a label property to instances of enum which uses the enum member\n         # that is passed in as \"self\" as the value to use when looking up the\n@@ -61,6 +62,7 @@ class ChoicesMeta(enum.EnumMeta):\n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n \n+\n     def __str__(self):\n         \"\"\"\n         Use value when cast to str, so that Choices set as model instance\n"
  },
  "django__django-12308": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12308",
    "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..28c30668f7 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,13 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    # Special-case JSONField when displayed readonly in the admin so that JSON is shown\n+    # (use field.prepare_value to let the field handle InvalidJSONInput and formatting)\n+    elif getattr(models, 'JSONField', None) is not None and isinstance(field, models.JSONField):\n+        try:\n+            return field.prepare_value(value)\n+        except Exception:\n+            return display_for_value(value, empty_value_display)\n     else:\n         return display_for_value(value, empty_value_display)\n \n"
  },
  "django__django-12325": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12325",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..1f995890b7 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -204,7 +204,21 @@ class ModelBase(type):\n             for field in base._meta.local_fields:\n                 if isinstance(field, OneToOneField):\n                     related = resolve_relation(new_class, field.remote_field.model)\n-                    parent_links[make_model_tuple(related)] = field\n+                    key = make_model_tuple(related)\n+                    existing = parent_links.get(key)\n+                    # Prefer an explicitly declared parent_link=True field\n+                    if existing is None:\n+                        parent_links[key] = field\n+                    else:\n+                        # If the new field is an explicit parent_link, prefer it over a non-parent_link\n+                        try:\n+                            new_parent = bool(getattr(field, 'parent_link', False))\n+                            existing_parent = bool(getattr(existing, 'parent_link', False))\n+                        except Exception:\n+                            new_parent = existing_parent = False\n+                        if new_parent and not existing_parent:\n+                            parent_links[key] = field\n+\n \n         # Track fields inherited from base models.\n         inherited_attributes = set()\n"
  },
  "django__django-12406": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..b9d2907342 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,6 +13,7 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n+    RadioSelect,\n     HiddenInput, MultipleHiddenInput, SelectMultiple,\n )\n from django.utils.text import capfirst, get_text_list\n@@ -1185,7 +1186,10 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n+        # Don't add an empty label for required fields with RadioSelect\n+        # RadioSelect has an inherent unfilled state, so a '---------' choice is unnecessary.\n+        if required and (initial is not None or isinstance(widget, RadioSelect) or (\n+                isinstance(widget, type) and issubclass(widget, RadioSelect))):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n"
  },
  "django__django-12708": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12708",
    "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..5a1ff66718 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -408,11 +408,23 @@ class BaseDatabaseSchemaEditor:\n             **constraint_kwargs\n         )\n         if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-                \", \".join(columns),\n-            ))\n+            # Multiple constraints (unique and index) can exist on the same\n+            # columns: prefer the one matching the intent. Use naming\n+            # conventions as a best-effort disambiguation, falling back to the\n+            # first found constraint to remain compatible.\n+            if len(constraint_names) > 1:\n+                # try to pick a name with _idx for index deletions, _uniq for unique deletions\n+                if constraint_kwargs.get('index'):\n+                    preferred = [n for n in constraint_names if n.endswith('_idx')]\n+                elif constraint_kwargs.get('unique'):\n+                    preferred = [n for n in constraint_names if n.endswith('_uniq') or n.endswith('_uniq_%s' % model._meta.db_table)]\n+                else:\n+                    preferred = []\n+                if preferred:\n+                    constraint_names = preferred\n+                else:\n+                    # as a last resort, pick the first to avoid hard crash\n+                    constraint_names = [constraint_names[0]]\n         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n"
  },
  "django__django-12713": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12713",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..5c606af16c 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -250,11 +250,11 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n         db = kwargs.get('using')\n \n         autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n+        if 'widget' not in kwargs and db_field.name in autocomplete_fields:\n             kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n+        elif 'widget' not in kwargs and db_field.name in self.raw_id_fields:\n             kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+        elif 'widget' not in kwargs and db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n             kwargs['widget'] = widgets.FilteredSelectMultiple(\n                 db_field.verbose_name,\n                 db_field.name in self.filter_vertical\n"
  },
  "django__django-12774": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12774",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..12d60316b4 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -689,8 +689,24 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+        if field_name != 'pk':\n+            field = self.model._meta.get_field(field_name)\n+            # Consider fields unique either via field.unique, unique_together or UniqueConstraint\n+            is_unique = field.unique\n+            # unique_together can be a tuple of tuples; check single-field tuples\n+            for ut in getattr(self.model._meta, 'unique_together', ()): \n+                if len(ut) == 1 and ut[0] == field_name:\n+                    is_unique = True\n+                    break\n+            # Check UniqueConstraint entries on Meta.constraints\n+            from django.db.models import UniqueConstraint\n+            if not is_unique:\n+                for c in getattr(self.model._meta, 'constraints', ()): \n+                    if isinstance(c, UniqueConstraint) and tuple(c.fields) == (field_name,):\n+                        is_unique = True\n+                        break\n+            if not is_unique:\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n         if id_list is not None:\n             if not id_list:\n                 return {}\n"
  },
  "django__django-9296": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-9296",
    "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..2c2472c6ea 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -99,6 +99,10 @@ class Paginator:\n         return ceil(hits / self.per_page)\n \n     @property\n+    def __iter__(self):\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n     def page_range(self):\n         \"\"\"\n         Return a 1-based range of pages for iterating through within\n"
  },
  "sphinx-doc__sphinx-10323": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10323",
    "model_patch": "diff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..9437fe9a5 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -224,9 +224,9 @@ class LiteralIncludeReader:\n                        self.start_filter,\n                        self.end_filter,\n                        self.lines_filter,\n+                       self.dedent_filter,\n                        self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+                       self.append_filter]\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\ndiff --git a/tmp_pom.xml b/tmp_pom.xml\nnew file mode 100644\nindex 000000000..13e9d75dd\n--- /dev/null\n+++ b/tmp_pom.xml\n@@ -0,0 +1,11 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project>\n+  <build>\n+    <plugins>\n+      <plugin>\n+        <groupId>com.github.ekryd.sortpom</groupId>\n+        <artifactId>sortpom-maven-plugin</artifactId>\n+      </plugin>\n+    </plugins>\n+  </build>\n+</project>\n"
  },
  "sphinx-doc__sphinx-10435": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10435",
    "model_patch": "diff --git a/sphinx/writers/latex.py b/sphinx/writers/latex.py\nindex e0c7d56f8..cdc539c6d 100644\n--- a/sphinx/writers/latex.py\n+++ b/sphinx/writers/latex.py\n@@ -721,28 +721,28 @@ class LaTeXTranslator(SphinxTranslator):\n         pass\n \n     def visit_desc_inline(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n \n     def depart_desc_inline(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     # Nodes for high-level structure in signatures\n     ##############################################\n \n     def visit_desc_name(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxbfcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxbfcode{\\sphinxupquote{%')\n         self.literal_whitespace += 1\n \n     def depart_desc_name(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n         self.literal_whitespace -= 1\n \n     def visit_desc_addname(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n         self.literal_whitespace += 1\n \n     def depart_desc_addname(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n         self.literal_whitespace -= 1\n \n     def visit_desc_type(self, node: Element) -> None:\n@@ -785,10 +785,10 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append('}')\n \n     def visit_desc_annotation(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxbfcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxbfcode{\\sphinxupquote{%')\n \n     def depart_desc_annotation(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     ##############################################\n \n@@ -1621,7 +1621,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxstyleliteralemphasis{\\sphinxupquote{')\n \n     def depart_literal_emphasis(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     def visit_strong(self, node: Element) -> None:\n         self.body.append(r'\\sphinxstylestrong{')\n@@ -1633,7 +1633,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxstyleliteralstrong{\\sphinxupquote{')\n \n     def depart_literal_strong(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     def visit_abbreviation(self, node: Element) -> None:\n         abbr = node.astext()\n@@ -1701,7 +1701,7 @@ class LaTeXTranslator(SphinxTranslator):\n             return\n         lang = node.get(\"language\", None)\n         if 'code' not in node['classes'] or not lang:\n-            self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+            self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n             return\n \n         opts = self.config.highlight_options.get(lang, {})\n@@ -1710,15 +1710,15 @@ class LaTeXTranslator(SphinxTranslator):\n         # TODO: Use nowrap option once LaTeX formatter supports it\n         # https://github.com/pygments/pygments/pull/1343\n         hlcode = hlcode.replace(r'\\begin{Verbatim}[commandchars=\\\\\\{\\}]',\n-                                r'\\sphinxcode{\\sphinxupquote{')\n+                                r'\\sphinxcode{\\sphinxupquote{%')\n         # get consistent trailer\n         hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n         self.body.append(hlcode)\n-        self.body.append('}}')\n+        self.body.append('%}}')\n         raise nodes.SkipNode\n \n     def depart_literal(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n \n     def visit_footnote_reference(self, node: Element) -> None:\n         raise nodes.SkipNode\n"
  },
  "sphinx-doc__sphinx-10466": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10466",
    "model_patch": "diff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..980fe49bb 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -32,7 +32,7 @@ class Message:\n     \"\"\"An entry of translatable message.\"\"\"\n     def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n         self.text = text\n-        self.locations = locations\n+        self.locations = list(dict.fromkeys(locations))\n         self.uuids = uuids\n \n \n"
  },
  "sphinx-doc__sphinx-10673": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10673",
    "model_patch": "diff --git a/sphinx/environment/adapters/toctree.py b/sphinx/environment/adapters/toctree.py\nindex 9678e3c7c..d1d615df1 100644\n--- a/sphinx/environment/adapters/toctree.py\n+++ b/sphinx/environment/adapters/toctree.py\n@@ -172,7 +172,8 @@ class TocTree:\n                     else:\n                         message = __('toctree contains reference to nonexisting document %r')\n \n-                    logger.warning(message, ref, location=toctreenode)\n+                    if ref not in ('genindex', 'modindex', 'search'):\n+                        logger.warning(message, ref, location=toctreenode)\n                 else:\n                     # if titles_only is given, only keep the main title and\n                     # sub-toctrees\n"
  },
  "sphinx-doc__sphinx-11510": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-11510",
    "model_patch": "diff --git a/sphinx/io.py b/sphinx/io.py\nindex 4874fdf39..7626d0d2a 100644\n--- a/sphinx/io.py\n+++ b/sphinx/io.py\n@@ -156,6 +156,27 @@ class SphinxFileInput(FileInput):\n         kwargs['error_handler'] = 'sphinx'\n         super().__init__(*args, **kwargs)\n \n+    def read(self) -> str:\n+        \"\"\"Read content and emit 'source-read' so included files are processed\n+        by Sphinx extensions the same way top-level sources are.\"\"\"\n+        content = super().read()\n+        # try to obtain environment from settings if provided\n+        env = None\n+        settings = getattr(self, 'settings', None)\n+        if settings is not None:\n+            env = getattr(settings, 'env', None)\n+        if env is None:\n+            env = getattr(self, 'env', None)\n+        if env is not None:\n+            try:\n+                arg = [content]\n+                env.events.emit('source-read', getattr(env, 'docname', None), arg)\n+                return arg[0]\n+            except Exception:\n+                # be conservative: don't break reading on any issue\n+                return content\n+        return content\n+\n \n def create_publisher(app: Sphinx, filetype: str) -> Publisher:\n     reader = SphinxStandaloneReader()\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..b8cd504c1 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4662,9 +4662,16 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n-                while self.current_char in 'uUlLfF':\n-                    self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+                    while self.current_char in 'uUlLfF':\n+                        self.pos += 1\n+                    # accept optional user-defined-literal suffixes (UDL)\n+                    # consume identifier characters and nested-name '::' to include UDLs\n+                    while (not self.eof) and (self.current_char.isalpha() or self.current_char=='_' or self.current_char.isdigit() or self.definition.startswith('::', self.pos)):\n+                        if self.definition.startswith('::', self.pos):\n+                            self.pos += 2\n+                        else:\n+                            self.pos += 1\n+                    return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n         if string is not None:\n@@ -7285,4 +7292,4 @@ def setup(app: Sphinx) -> Dict[str, Any]:\n         'env_version': 2,\n         'parallel_read_safe': True,\n         'parallel_write_safe': True,\n-    }\n+    }\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-7748": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7748",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex f8e4be999..4de36dbdc 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1049,24 +1049,38 @@ class DocstringSignatureMixin:\n             # no lines in docstring, no match\n             if not doclines:\n                 continue\n-            # match first line of docstring against signature RE\n-            match = py_ext_sig_re.match(doclines[0])\n-            if not match:\n+            # collect consecutive leading signature lines (for overloaded methods)\n+            args_list = []\n+            retann_list = []\n+            j = 0\n+            for j, line in enumerate(doclines):\n+                match = py_ext_sig_re.match(line)\n+                if not match:\n+                    break\n+                exmod, path, base, args, retann = match.groups()\n+                # the base name must match ours\n+                valid_names = [self.objpath[-1]]  # type: ignore\n+                if isinstance(self, ClassDocumenter):\n+                    valid_names.append('__init__')\n+                    if hasattr(self.object, '__mro__'):\n+                        valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n+                if base not in valid_names:\n+                    # stop collecting if base doesn't match\n+                    break\n+                args_list.append(args)\n+                if retann:\n+                    retann_list.append(retann)\n+            if not args_list:\n                 continue\n-            exmod, path, base, args, retann = match.groups()\n-            # the base name must match ours\n-            valid_names = [self.objpath[-1]]  # type: ignore\n-            if isinstance(self, ClassDocumenter):\n-                valid_names.append('__init__')\n-                if hasattr(self.object, '__mro__'):\n-                    valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n-            if base not in valid_names:\n-                continue\n-            # re-prepare docstring to ignore more leading indentation\n+            # re-prepare docstring to ignore more leading indentation;\n+            # skip all matched signature lines\n             tab_width = self.directive.state.document.settings.tab_width  # type: ignore\n-            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[1:]),\n+            remaining = doclines[len(args_list):]\n+            self._new_docstrings[i] = prepare_docstring('\\n'.join(remaining),\n                                                         tabsize=tab_width)\n-            result = args, retann\n+            # join multiple signatures by newline so they can be presented together\n+            ret = retann_list[-1] if retann_list else ''\n+            result = '\\n'.join(args_list), ret\n             # don't look any further\n             break\n         return result\n"
  },
  "sphinx-doc__sphinx-7757": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7757",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 15f0d66e2..0fcef04ef 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -88,6 +88,8 @@ def getargspec(func: Callable) -> Any:\n \n         if kind is Parameter.POSITIONAL_ONLY:\n             args.append(name)\n+            if param.default is not param.empty:\n+                defaults += (param.default,)\n         elif kind is Parameter.POSITIONAL_OR_KEYWORD:\n             args.append(name)\n             if param.default is not param.empty:\n"
  },
  "sphinx-doc__sphinx-7985": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7985",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..53d233aa4 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -213,7 +213,16 @@ class CheckExternalLinksBuilder(Builder):\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n             elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+                # treat as local/internal link: check for target file and optional anchor\n+                req_url = uri.split('#',1)[0]\n+                # consider source and output directories\n+                src = Path(self.app.srcdir)/req_url\n+                out = Path(self.outdir)/req_url\n+                if src.exists() or out.exists():\n+                    # if there's an anchor, we can't reliably check it here; mark as working\n+                    return 'working', '', 0\n+                else:\n+                    return 'broken', 'Local target not found', 0\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n"
  },
  "sphinx-doc__sphinx-8035": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8035",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 8c3509c3b..b984bd4ff 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -859,7 +859,7 @@ class ModuleDocumenter(Documenter):\n         'show-inheritance': bool_option, 'synopsis': identity,\n         'platform': identity, 'deprecated': bool_option,\n         'member-order': member_order_option, 'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n         'imported-members': bool_option, 'ignore-module-all': bool_option\n     }  # type: Dict[str, Callable]\n \n@@ -1279,7 +1279,7 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         'noindex': bool_option, 'inherited-members': inherited_members_option,\n         'show-inheritance': bool_option, 'member-order': member_order_option,\n         'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n     }  # type: Dict[str, Callable]\n \n     _signature_class = None  # type: Any\n"
  },
  "sphinx-doc__sphinx-8056": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8056",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..214aaecd6 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -1082,8 +1082,10 @@ class NumpyDocstring(GoogleDocstring):\n     def _escape_args_and_kwargs(self, name: str) -> str:\n         func = super()._escape_args_and_kwargs\n \n-        if \", \" in name:\n-            return \", \".join(func(param) for param in name.split(\", \"))\n+        # Handle multiple parameter names separated by comma, with or without spaces.\n+        if ',' in name:\n+            parts = [p.strip() for p in name.split(',')]\n+            return ', '.join(func(param) for param in parts if param)\n         else:\n             return func(name)\n \n"
  },
  "sphinx-doc__sphinx-8265": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8265",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 378174993..4903266b7 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -390,6 +390,13 @@ def object_description(object: Any) -> str:\n         else:\n             return \"frozenset({%s})\" % \", \".join(object_description(x)\n                                                  for x in sorted_values)\n+    if isinstance(object, tuple):\n+        try:\n+            # keep deterministic order when possible\n+            items = \", \".join(object_description(x) for x in object)\n+            return \"(%s)\" % items\n+        except Exception:\n+            pass\n     try:\n         s = repr(object)\n     except Exception as exc:\n"
  },
  "sphinx-doc__sphinx-8269": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8269",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..1083e82ec 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -166,6 +166,7 @@ class CheckExternalLinksBuilder(Builder):\n                     # Read the whole document and see if #anchor exists\n                     response = requests.get(req_url, stream=True, config=self.app.config,\n                                             auth=auth_info, **kwargs)\n+                    response.raise_for_status()\n                     found = check_anchor(response, unquote(anchor))\n \n                     if not found:\n"
  },
  "sphinx-doc__sphinx-8475": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8475",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..cc68f53b5 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -172,7 +172,7 @@ class CheckExternalLinksBuilder(Builder):\n                                                  config=self.app.config, auth=auth_info,\n                                                  **kwargs)\n                         response.raise_for_status()\n-                    except HTTPError:\n+                    except (HTTPError, requests.exceptions.TooManyRedirects):\n                         # retry with GET request if that fails, some servers\n                         # don't like HEAD requests.\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n"
  },
  "sphinx-doc__sphinx-8548": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8548",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex ddfd2b365..4c4a1d0f8 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -597,7 +597,30 @@ class Documenter:\n         if self.analyzer:\n             attr_docs = self.analyzer.find_attr_docs()\n             if self.objpath:\n-                key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n+                # try lookup in the current namespace first, then in baseclass namespaces\n+                name = self.objpath[-1]\n+                base_ns = '.'.join(self.objpath[:-1])\n+                keys_to_try = []\n+                if base_ns:\n+                    keys_to_try.append((base_ns, name))\n+                # if documenting a class, also consider attribute docs from base classes\n+                try:\n+                    obj_cls = self.object\n+                    if inspect.isclass(obj_cls):\n+                        for cls in obj_cls.__mro__[1:]:\n+                            # use the class name as namespace (parser stores class scopes by name)\n+                            keys_to_try.append((cls.__name__, name))\n+                except Exception:\n+                    pass\n+                # finally try module-level namespace (empty string)\n+                keys_to_try.append(('', name))\n+                # find first matching key\n+                key = None\n+                for k in keys_to_try:\n+                    if k in attr_docs:\n+                        key = k\n+                        break\n+\n                 if key in attr_docs:\n                     no_docstring = True\n                     # make a copy of docstring for attributes to avoid cache\n"
  },
  "sphinx-doc__sphinx-8551": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8551",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 79d7e4f46..32b7d27f8 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -91,8 +91,7 @@ def type_to_xref(text: str, env: BuildEnvironment = None) -> addnodes.pending_xr\n     else:\n         kwargs = {}\n \n-    return pending_xref('', nodes.Text(text),\n-                        refdomain='py', reftype=reftype, reftarget=text, **kwargs)\n+    return pending_xref('', nodes.Text(text),\\n                        refdomain='py', reftype=reftype, reftarget=text, refspecific=True, **kwargs)\n \n \n def _parse_annotation(annotation: str, env: BuildEnvironment = None) -> List[Node]:\n"
  },
  "sphinx-doc__sphinx-8638": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8638",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 000e2e8d3..b8b4339a8 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1144,22 +1144,25 @@ class PythonDomain(Domain):\n             else:\n                 objtypes = self.objtypes_for_role(type)\n             if objtypes is not None:\n+                # prefer most specific (module + class + name), then class-scoped, then module-scoped, then global\n                 if modname and classname:\n                     fullname = modname + '.' + classname + '.' + name\n                     if fullname in self.objects and self.objects[fullname].objtype in objtypes:\n                         newname = fullname\n-                if not newname:\n-                    if modname and modname + '.' + name in self.objects and \\\n-                       self.objects[modname + '.' + name].objtype in objtypes:\n+                if not newname and classname:\n+                    if classname + '.' + name in self.objects and self.objects[classname + '.' + name].objtype in objtypes:\n+                        newname = classname + '.' + name\n+                if not newname and modname:\n+                    if modname + '.' + name in self.objects and self.objects[modname + '.' + name].objtype in objtypes:\n                         newname = modname + '.' + name\n-                    elif name in self.objects and self.objects[name].objtype in objtypes:\n-                        newname = name\n-                    else:\n-                        # \"fuzzy\" searching mode\n-                        searchname = '.' + name\n-                        matches = [(oname, self.objects[oname]) for oname in self.objects\n-                                   if oname.endswith(searchname) and\n-                                   self.objects[oname].objtype in objtypes]\n+                if not newname and name in self.objects and self.objects[name].objtype in objtypes:\n+                    newname = name\n+                if not newname:\n+                    # \"fuzzy\" searching mode: look for any qualified names ending with .name\n+                    searchname = '.' + name\n+                    matches = [(oname, self.objects[oname]) for oname in self.objects\n+                               if oname.endswith(searchname) and\n+                               self.objects[oname].objtype in objtypes]\n         else:\n             # NOTE: searching for exact match, object type is not considered\n             if name in self.objects:\n"
  },
  "sphinx-doc__sphinx-8721": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8721",
    "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..e969b4190 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -185,6 +185,10 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n+    # Do not generate module pages for epub builders unless explicitly enabled.\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n+\n     modnames = set(env._viewcode_modules)  # type: ignore\n \n     for modname, entry in status_iterator(\n"
  },
  "sphinx-doc__sphinx-9229": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9229",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 1f4c98284..54e5c68d4 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1725,7 +1725,8 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n                     ) -> None:\n         if self.doc_as_attr:\n             try:\n-                more_content = StringList([_('alias of %s') % restify(self.object)], source='')\n+                if more_content is None:\n+                    more_content = StringList([_('alias of %s') % restify(self.object)], source='')\n             except AttributeError:\n                 pass  # Invalid class object is passed.\n \n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..818eee009 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -876,42 +876,45 @@ def _recombine_set_tokens(tokens: List[str]) -> List[str]:\n     token_queue = collections.deque(tokens)\n     keywords = (\"optional\", \"default\")\n \n-    def takewhile_set(tokens):\n-        open_braces = 0\n+    def takewhile_enclosed(tokens, open_char, close_char):\n+        depth = 0\n         previous_token = None\n+        parts = []\n         while True:\n             try:\n                 token = tokens.popleft()\n             except IndexError:\n                 break\n \n-            if token == \", \":\n+            if token == \", \" and depth == 0:\n                 previous_token = token\n                 continue\n \n             if not token.strip():\n                 continue\n \n-            if token in keywords:\n+            if token in keywords and depth == 0:\n                 tokens.appendleft(token)\n                 if previous_token is not None:\n                     tokens.appendleft(previous_token)\n                 break\n \n             if previous_token is not None:\n-                yield previous_token\n+                parts.append(previous_token)\n                 previous_token = None\n \n-            if token == \"{\":\n-                open_braces += 1\n-            elif token == \"}\":\n-                open_braces -= 1\n+            if token == open_char:\n+                depth += 1\n+            elif token == close_char:\n+                depth -= 1\n \n-            yield token\n+            parts.append(token)\n \n-            if open_braces == 0:\n+            if depth == 0:\n                 break\n \n+        yield \"\".join(parts)\n+\n     def combine_set(tokens):\n         while True:\n             try:\n@@ -919,9 +922,11 @@ def _recombine_set_tokens(tokens: List[str]) -> List[str]:\n             except IndexError:\n                 break\n \n-            if token == \"{\":\n-                tokens.appendleft(\"{\")\n-                yield \"\".join(takewhile_set(tokens))\n+            if token == \"{\" or token == \"(\":\n+                tokens.appendleft(token)\n+                open_char = \"{\" if token == \"{\" else \"(\"\n+                close_char = \"}\" if token == \"{\" else \")\"\n+                yield next(takewhile_enclosed(tokens, open_char, close_char))\n             else:\n                 yield token\n \n"
  },
  "sphinx-doc__sphinx-9320": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9320",
    "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..e6cfcc55d 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -146,6 +146,10 @@ def do_prompt(text: str, default: str = None, validator: Callable[[str], Any] =\n         else:\n             prompt = colorize(COLOR_QUESTION, prompt, input_mode=False)\n         x = term_input(prompt).strip()\n+        # If the caller passed an explicit empty-string default, treat an empty\n+        # user input as an accepted empty value (used to signal exit).\n+        if default == '' and not x:\n+            return x\n         if default and not x:\n             x = default\n         try:\n"
  },
  "sphinx-doc__sphinx-9367": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9367",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..0ba63cc41 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -214,6 +214,9 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n+            # Preserve trailing comma for single-element tuples\n+            if len(node.elts) == 1:\n+                return \"(\" + self.visit(node.elts[0]) + \",)\"\n             return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n"
  },
  "sphinx-doc__sphinx-9461": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9461",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 23dd9e930..ff36e89e4 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -390,7 +390,33 @@ def isproperty(obj: Any) -> bool:\n         if isinstance(obj, cached_property):\n             return True\n \n-    return isinstance(obj, property)\n+    # handle @classmethod @property (Python 3.9+):\n+    # classmethod(property(...)) may present as a wrapper whose __func__ is the property.\n+    try:\n+        if getattr(obj, '__func__', None) is not None and isinstance(obj.__func__, property):\n+            return True\n+        # also try unwrapping common wrapper attribute\n+        un = getattr(obj, '__func__', None) or getattr(obj, '__wrapped__', None)\n+        if isinstance(un, property):\n+            obj = un\n+    except Exception:\n+        pass\n+    # broaden detection: check obj itself, obj.__func__, obj.__wrapped__, or type(obj)\n+    try:\n+        # direct property\n+        if isinstance(obj, property):\n+            return True\n+        # underlying attributes that may hold a property (e.g., classmethod(property))\n+        candidates = [getattr(obj, '__func__', None), getattr(obj, '__wrapped__', None), getattr(type(obj), '__func__', None), getattr(type(obj), '__wrapped__', None)]\n+        for c in candidates:\n+            if isinstance(c, property):\n+                return True\n+            # also detect by presence of fget attribute typical for property\n+            if getattr(c, 'fget', None) is not None:\n+                return True\n+    except Exception:\n+        pass\n+    return False\n \n \n def isgenericalias(obj: Any) -> bool:\n"
  },
  "sphinx-doc__sphinx-9698": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9698",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..1a3bd60c7 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -796,7 +796,7 @@ class PyMethod(PyObject):\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n+            return _('%s (%s property)') % (methname, clsname)\n         elif 'staticmethod' in self.options:\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\n"
  },
  "sphinx-doc__sphinx-9281": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9281",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex a415a7074..27aa4a9b1 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -12,6 +12,21 @@ import builtins\n import contextlib\n import enum\n import inspect\n+\n+from enum import Enum\n+\n+def format_default(val):\n+    \"\"\"Format default values for signatures, showing Enum member name when appropriate.\"\"\"\n+    try:\n+        if isinstance(val, Enum):\n+            name = val.name\n+            # return clearly the member name (e.g., ValueA) to keep signatures concise\n+            if name and name.isidentifier():\n+                return name\n+            return repr(val)\n+    except Exception:\n+        pass\n+    return repr(val)\n import re\n import sys\n import types\n@@ -431,40 +446,21 @@ def safe_getattr(obj: Any, name: str, *defargs: Any) -> Any:\n \n \n def object_description(object: Any) -> str:\n-    \"\"\"A repr() implementation that returns text safe to use in reST context.\"\"\"\n-    if isinstance(object, dict):\n-        try:\n-            sorted_keys = sorted(object)\n-        except Exception:\n-            pass  # Cannot sort dict keys, fall back to generic repr\n-        else:\n-            items = (\"%s: %s\" %\n-                     (object_description(key), object_description(object[key]))\n-                     for key in sorted_keys)\n-            return \"{%s}\" % \", \".join(items)\n-    if isinstance(object, set):\n-        try:\n-            sorted_values = sorted(object)\n-        except TypeError:\n-            pass  # Cannot sort set values, fall back to generic repr\n-        else:\n-            return \"{%s}\" % \", \".join(object_description(x) for x in sorted_values)\n-    if isinstance(object, frozenset):\n-        try:\n-            sorted_values = sorted(object)\n-        except TypeError:\n-            pass  # Cannot sort frozenset values, fall back to generic repr\n-        else:\n-            return \"frozenset({%s})\" % \", \".join(object_description(x)\n-                                                 for x in sorted_values)\n+    \"\"\"Return a short description for an object for use in signatures.\"\"\"\n+    # Prefer concise Enum member names for signature defaults\n     try:\n-        s = repr(object)\n-    except Exception as exc:\n-        raise ValueError from exc\n-    # Strip non-deterministic memory addresses such as\n-    # ``<__main__.A at 0x7f68cb685710>``\n-    s = memory_address_re.sub('', s)\n-    return s.replace('\\n', ' ')\n+        from enum import Enum\n+        if isinstance(object, Enum):\n+            name = getattr(object, 'name', None)\n+            if name and isinstance(name, str) and name.isidentifier():\n+                return name\n+    except Exception:\n+        pass\n+    # Fallback to original logic (repr-based)\n+    try:\n+        return repr(object)\n+    except Exception:\n+        return object.__class__.__name__\n \n \n def is_builtin_class_method(obj: Any, attr_name: str) -> bool:\ndiff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex af6edcae0..67393210f 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -72,6 +72,22 @@ TitleGetter = Callable[[nodes.Node], str]\n # inventory data on memory\n Inventory = Dict[str, Dict[str, Tuple[str, str, str, str]]]\n \n+from enum import Enum\n+\n+def format_default(val):\n+    \"\"\"Format default values for signatures, showing Enum member name when appropriate.\"\"\"\n+    try:\n+        if isinstance(val, Enum):\n+            # prefer \"MyEnum.Member\" style when possible: use Enum.__class__.__name__ if available\n+            # but for signature clarity return just the member name (e.g., ValueA)\n+            name = val.name\n+            if name.isidentifier():\n+                return name\n+            return repr(val)\n+    except Exception:\n+        pass\n+    return repr(val)\n+\n \n def get_type_hints(obj: Any, globalns: Dict = None, localns: Dict = None) -> Dict[str, Any]:\n     \"\"\"Return a dictionary containing type hints for a function, method, module or class object.\n"
  }
}