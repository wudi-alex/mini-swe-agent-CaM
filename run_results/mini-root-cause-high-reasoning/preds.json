{
  "django__django-11790": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11790",
    "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..454a9a7d1a 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -192,6 +192,11 @@ class AuthenticationForm(forms.Form):\n         # Set the max length and label for the \"username\" field.\n         self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n         self.fields['username'].max_length = self.username_field.max_length or 254\n+        # Ensure widget HTML attributes (like maxlength) reflect the updated max_length.\n+        username_field = self.fields['username']\n+        extra_attrs = username_field.widget_attrs(username_field.widget)\n+        if extra_attrs:\n+            username_field.widget.attrs.update(extra_attrs)\n         if self.fields['username'].label is None:\n             self.fields['username'].label = capfirst(self.username_field.verbose_name)\n \ndiff --git a/tests/settings.py b/tests/settings.py\nnew file mode 100644\nindex 0000000000..5476f16e3c\n--- /dev/null\n+++ b/tests/settings.py\n@@ -0,0 +1,14 @@\n+SECRET_KEY = 'test'\n+INSTALLED_APPS = [\n+    'django.contrib.auth',\n+    'django.contrib.contenttypes',\n+]\n+DATABASES = {\n+    'default': {\n+        'ENGINE': 'django.db.backends.sqlite3',\n+        'NAME': ':memory:',\n+    }\n+}\n+MIDDLEWARE = []\n+ROOT_URLCONF = None\n+AUTH_PASSWORD_VALIDATORS = []\n"
  },
  "django__django-11815": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11815",
    "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..8e74d8b68a 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,11 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        # Serialize enum by member name (e.g., MyEnum['NAME']) instead of by value\n+        # This avoids issues when enum values are translated or otherwise mutable.\n+        name_string = repr(self.value.name)\n+        imports = {'import %s' % module}\n+        return \"%s.%s[%s]\" % (module, enum_class.__name__, name_string), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\n"
  },
  "django__django-11848": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11848",
    "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..f0c26d2c06 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,16 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            # Interpret two-digit years per RFC 7231: a two-digit year that\n+            # appears to be more than 50 years in the future is interpreted\n+            # as the most recent year in the past with the same last two digits.\n+            now_year = datetime.datetime.utcnow().year\n+            current_century = now_year - (now_year % 100)\n+            candidate = current_century + year\n+            # If candidate is more than 50 years in the future, use previous century\n+            if candidate - now_year > 50:\n+                candidate -= 100\n+            year = candidate\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n"
  },
  "django__django-11880": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11880",
    "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..a7bbe86f05 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -200,6 +200,9 @@ class Field:\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        # Ensure error_messages is deep-copied so modifications on one Field\n+        # instance don't affect other copies.\n+        result.error_messages = copy.deepcopy(self.error_messages, memo)\n         return result\n \n \n"
  },
  "django__django-11885": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11885",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..029ca5639f 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -309,10 +309,46 @@ class Collector:\n                         sender=model, instance=obj, using=self.using\n                     )\n \n-            # fast deletes\n+            # fast deletes: combine deletions for the same model into a single SQL statement\n+            # to reduce the number of roundtrips to the database.\n+            from django.db import connections\n+            processed = set()\n             for qs in self.fast_deletes:\n-                count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                model = qs.model\n+                if model in processed:\n+                    continue\n+                # gather all querysets for this model\n+                group = [x for x in self.fast_deletes if x.model is model]\n+                processed.add(model)\n+                wheres = []\n+                params = []\n+                table_sql = None\n+                for gqs in group:\n+                    compiler = gqs.query.get_compiler(using=self.using)\n+                    sql, pparams = compiler.delete()\n+                    parts = sql.split(' WHERE ', 1)\n+                    if len(parts) == 2:\n+                        if table_sql is None:\n+                            table_sql = parts[0]\n+                        wheres.append('(' + parts[1] + ')')\n+                        params.extend(pparams)\n+                    else:\n+                        # no WHERE clause - delegate to raw delete for safety\n+                        count = gqs._raw_delete(using=self.using)\n+                        deleted_counter[gqs.model._meta.label] += count\n+                if wheres and table_sql is not None:\n+                    combined_sql = table_sql + ' WHERE ' + ' OR '.join(wheres)\n+                    cursor = connections[self.using].cursor()\n+                    cursor.execute(combined_sql, params)\n+                    # cursor.rowcount may be -1 for some DB backends; attempt to set a sensible count\n+                    try:\n+                        count = cursor.rowcount if cursor.rowcount != -1 else None\n+                    except Exception:\n+                        count = None\n+                    # We cannot reliably get count for all backends; increment by None-safe logic\n+                    # If count is None, don't change the counter.\n+                    if count:\n+                        deleted_counter[model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n"
  },
  "django__django-11951": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11951",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..92349cd0c5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,8 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+        max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n+        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n"
  },
  "django__django-11964": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11964",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..73c6300891 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,7 +60,14 @@ class ChoicesMeta(enum.EnumMeta):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n-    pass\n+    def __str__(self):\n+        \"\"\"Return the underlying value as its string representation.\n+\n+        Ensures enum members used as model field values behave like their raw\n+        values (e.g. \"first\" not \"MyChoice.FIRST_CHOICE\") when converted to str.\n+        \"\"\"\n+        return str(self.value)\n+\n \n \n class IntegerChoices(int, Choices):\n"
  },
  "django__django-11999": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-11999",
    "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..338e08bc32 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,12 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            # Only create the auto-generated get_<field>_display if the\n+            # model class hasn't provided its own implementation. This\n+            # prevents Django from overriding user-defined methods.\n+            if not hasattr(cls, 'get_%s_display' % self.name):\n+                setattr(cls, 'get_%s_display' % self.name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\ndiff --git a/test_override_display.py b/test_override_display.py\nnew file mode 100644\nindex 0000000000..813f5cb20d\n--- /dev/null\n+++ b/test_override_display.py\n@@ -0,0 +1,17 @@\n+from django.conf import settings\n+settings.configure(INSTALLED_APPS=[], DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}}, USE_I18N=False)\n+import django\n+django.setup()\n+from django.db import models\n+class FooBar(models.Model):\n+    foo_bar = models.CharField(\"foo\", choices=[(1, 'foo'), (2, 'bar')], max_length=10)\n+    def __str__(self):\n+        return self.get_foo_bar_display()\n+    def get_foo_bar_display(self):\n+        return \"something\"\n+    class Meta:\n+        app_label = 'tests'\n+# Instantiate and test\n+f = FooBar()\n+print(f.get_foo_bar_display())\n+print(str(f))\n"
  },
  "django__django-12039": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12039",
    "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..583bdd110f 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -84,9 +84,12 @@ class Columns(TableColumns):\n     def __str__(self):\n         def col_str(column, idx):\n             try:\n-                return self.quote_name(column) + self.col_suffixes[idx]\n+                suffix = self.col_suffixes[idx]\n             except IndexError:\n-                return self.quote_name(column)\n+                suffix = ''\n+            if suffix:\n+                return self.quote_name(column) + ' ' + suffix\n+            return self.quote_name(column)\n \n         return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n@@ -112,11 +115,20 @@ class IndexColumns(Columns):\n         def col_str(column, idx):\n             # Index.__init__() guarantees that self.opclasses is the same\n             # length as self.columns.\n-            col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n+            # Start with the column name and optionally append opclass and suffix\n+            col = self.quote_name(column)\n             try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n+                opclass = self.opclasses[idx]\n             except IndexError:\n-                pass\n+                opclass = ''\n+            if opclass:\n+                col = '{} {}'.format(col, opclass)\n+            try:\n+                suffix = self.col_suffixes[idx]\n+            except IndexError:\n+                suffix = ''\n+            if suffix:\n+                col = '{} {}'.format(col, suffix)\n             return col\n \n         return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n"
  },
  "django__django-12050": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12050",
    "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..ea3a570059 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1073,7 +1073,10 @@ class Query(BaseExpression):\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n-            value = tuple(resolved_values)\n+            if isinstance(value, list):\n+                value = resolved_values\n+            else:\n+                value = tuple(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n"
  },
  "django__django-12143": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12143",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..a100f1c499 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1631,7 +1631,7 @@ class ModelAdmin(BaseModelAdmin):\n \n     def _get_edited_object_pks(self, request, prefix):\n         \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name))\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\n"
  },
  "django__django-12155": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12155",
    "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..aeec9fae5c 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,7 +34,7 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n+    indent = min(len(line) - len(line.lstrip()) for line in lines[1:] if line.lstrip())\n     trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n     return \"\\n\".join(trimmed).strip()\n \n"
  },
  "django__django-12209": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12209",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..d606553db8 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -840,6 +840,7 @@ class Model(metaclass=ModelBase):\n                        if f.name in update_fields or f.attname in update_fields]\n \n         pk_val = self._get_pk_val(meta)\n+        pk_was_set = pk_val is not None\n         if pk_val is None:\n             pk_val = meta.pk.get_pk_value_on_save(self)\n             setattr(self, meta.pk.attname, pk_val)\n@@ -851,6 +852,7 @@ class Model(metaclass=ModelBase):\n         if (\n             not force_insert and\n             self._state.adding and\n+            not pk_was_set and\n             self._meta.pk.default and\n             self._meta.pk.default is not NOT_PROVIDED\n         ):\n"
  },
  "django__django-12262": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12262",
    "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..2f74556268 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -261,7 +261,7 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if kwarg:\n             # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n+            if param not in params and param not in kwonly and varkw is None:\n                 # An unexpected keyword argument was supplied\n                 raise TemplateSyntaxError(\n                     \"'%s' received unexpected keyword argument '%s'\" %\n"
  },
  "django__django-12273": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12273",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 844c01e95e..451828f12f 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -804,8 +804,13 @@ class Model(metaclass=ModelBase):\n         inserted = False\n         for parent, field in meta.parents.items():\n             # Make sure the link fields are synced between parent and self.\n+            # Only copy the child link into the parent's PK when the parent's\n+            # PK attribute hasn't been explicitly set on the instance. If the\n+            # caller has explicitly set parent._meta.pk.attname (even to None),\n+            # treat that as authoritative.\n             if (field and getattr(self, parent._meta.pk.attname) is None and\n-                    getattr(self, field.attname) is not None):\n+                    getattr(self, field.attname) is not None and\n+                    parent._meta.pk.attname not in self.__dict__):\n                 setattr(self, parent._meta.pk.attname, getattr(self, field.attname))\n             parent_inserted = self._save_parents(cls=parent, using=using, update_fields=update_fields)\n             updated = self._save_table(\n"
  },
  "django__django-12276": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12276",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..299b665db3 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -387,6 +387,9 @@ class FileInput(Input):\n     def value_omitted_from_data(self, data, files, name):\n         return name not in files\n \n+    def use_required_attribute(self, initial):\n+        return super().use_required_attribute(initial) and not initial\n+\n \n FILE_INPUT_CONTRADICTION = object()\n \n@@ -450,10 +453,6 @@ class ClearableFileInput(FileInput):\n             # False signals to clear any existing value, as opposed to just None\n             return False\n         return upload\n-\n-    def use_required_attribute(self, initial):\n-        return super().use_required_attribute(initial) and not initial\n-\n     def value_omitted_from_data(self, data, files, name):\n         return (\n             super().value_omitted_from_data(data, files, name) and\n"
  },
  "django__django-12304": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12304",
    "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex f48143ddaf..49b04ff1eb 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -31,8 +31,11 @@ class ChoicesMeta(enum.EnumMeta):\n         # that is passed in as \"self\" as the value to use when looking up the\n         # label in the choices.\n         cls.label = property(lambda self: cls._value2label_map_.get(self.value))\n+        # Prevent Django templates from calling the enum class (they call callables with no args)\n+        cls.do_not_call_in_templates = True\n         return enum.unique(cls)\n \n+\n     def __contains__(cls, member):\n         if not isinstance(member, enum.Enum):\n             # Allow non-enums to match against member values.\n"
  },
  "django__django-12308": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12308",
    "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..86a616ad23 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,15 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    # Special-case JSONField to use the form field's prepare_value which handles\n+    # InvalidJSONInput and respects encoder/decoder options.\n+    elif isinstance(field, models.JSONField):\n+        try:\n+            form_field = field.formfield()\n+            return form_field.prepare_value(value)\n+        except Exception:\n+            return display_for_value(value, empty_value_display)\n+\n     else:\n         return display_for_value(value, empty_value_display)\n \n"
  },
  "django__django-12325": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12325",
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..e7b67b0c9e 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -192,6 +192,10 @@ class ModelBase(type):\n             new_class._meta.concrete_model = new_class\n \n         # Collect the parent links for multi-table inheritance.\n+        # Keep a list of candidate OneToOneFields per related model instead of\n+        # overwriting so that the explicit parent_link=True marker can be used\n+        # to select the correct parent when multiple OneToOneFields point to the\n+        # same model.\n         parent_links = {}\n         for base in reversed([new_class] + parents):\n             # Conceptually equivalent to `if base is Model`.\n@@ -204,7 +208,8 @@ class ModelBase(type):\n             for field in base._meta.local_fields:\n                 if isinstance(field, OneToOneField):\n                     related = resolve_relation(new_class, field.remote_field.model)\n-                    parent_links[make_model_tuple(related)] = field\n+                    key = make_model_tuple(related)\n+                    parent_links.setdefault(key, []).append(field)\n \n         # Track fields inherited from base models.\n         inherited_attributes = set()\n@@ -237,7 +242,17 @@ class ModelBase(type):\n                 base = base._meta.concrete_model\n                 base_key = make_model_tuple(base)\n                 if base_key in parent_links:\n-                    field = parent_links[base_key]\n+                    # If multiple candidate OneToOneFields exist for this parent,\n+                    # prefer the one explicitly marked with parent_link=True; if\n+                    # none is so marked, fall back to the first declared field.\n+                    candidates = parent_links[base_key]\n+                    field = None\n+                    for cand in candidates:\n+                        if getattr(cand.remote_field, 'parent_link', False):\n+                            field = cand\n+                            break\n+                    if field is None:\n+                        field = candidates[0]\n                 elif not is_proxy:\n                     attr_name = '%s_ptr' % base._meta.model_name\n                     field = OneToOneField(\n"
  },
  "django__django-12406": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..61cb68a06d 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,7 +13,7 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    HiddenInput, MultipleHiddenInput, SelectMultiple, RadioSelect,\n )\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n@@ -1189,6 +1189,19 @@ class ModelChoiceField(ChoiceField):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n+        # RadioSelect widgets have an inherent unfilled state; when the field is\n+        # required (blank is False) don't provide an empty choice for radio\n+        # buttons to avoid rendering a misleading checked blank option.\n+        widget_arg = kwargs.get('widget', None)\n+        is_radio = False\n+        if widget_arg is not None:\n+            # widget can be a class or an instance\n+            if isinstance(widget_arg, type) and issubclass(widget_arg, RadioSelect):\n+                is_radio = True\n+            elif isinstance(widget_arg, RadioSelect):\n+                is_radio = True\n+        if required and is_radio:\n+            self.empty_label = None\n \n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n"
  },
  "django__django-12708": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12708",
    "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..b2cb04f934 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -407,13 +407,31 @@ class BaseDatabaseSchemaEditor:\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n-        if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n+        if len(constraint_names) == 0:\n+            raise ValueError(\"No matching constraints found for %s(%s)\" % (\n                 model._meta.db_table,\n                 \", \".join(columns),\n             ))\n-        self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n+        # If multiple constraints found (e.g. both a unique constraint and an index exist\n+        # for the same columns), try to pick the most appropriate one by name.\n+        chosen = None\n+        if len(constraint_names) > 1:\n+            # Prefer index-like names when deleting an index, unique-like names when deleting a unique.\n+            if getattr(self, 'sql_delete_index', None) and sql == self.sql_delete_index:\n+                for name in constraint_names:\n+                    if name.endswith('_idx') or name.endswith('idx'):\n+                        chosen = name\n+                        break\n+            if not chosen and getattr(self, 'sql_delete_unique', None) and sql == self.sql_delete_unique:\n+                for name in constraint_names:\n+                    if name.endswith('_uniq') or name.endswith('uniq'):\n+                        chosen = name\n+            # Fallback to first if no heuristic matched\n+            if not chosen:\n+                chosen = constraint_names[0]\n+        else:\n+            chosen = constraint_names[0]\n+        self.execute(self._delete_constraint_sql(sql, model, chosen))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n         \"\"\"Rename the table a model points to.\"\"\"\n"
  },
  "django__django-12713": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12713",
    "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..b3c4020f39 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -250,15 +250,16 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n         db = kwargs.get('using')\n \n         autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n-            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n-            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n-            kwargs['widget'] = widgets.FilteredSelectMultiple(\n-                db_field.verbose_name,\n-                db_field.name in self.filter_vertical\n-            )\n+        if 'widget' not in kwargs:\n+            if db_field.name in autocomplete_fields:\n+                kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in self.raw_id_fields:\n+                kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n+            elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+                kwargs['widget'] = widgets.FilteredSelectMultiple(\n+                    db_field.verbose_name,\n+                    db_field.name in self.filter_vertical\n+                )\n \n         if 'queryset' not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\n"
  },
  "django__django-12774": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12774",
    "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..8c752c9e7c 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -689,8 +689,22 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+        if field_name != 'pk':\n+            field = self.model._meta.get_field(field_name)\n+            is_unique = field.unique\n+            if not is_unique:\n+                # Accept fields that are unique by a UniqueConstraint(fields=[...]) with no condition.\n+                try:\n+                    from django.db.models import UniqueConstraint\n+                except Exception:\n+                    UniqueConstraint = None\n+                if UniqueConstraint is not None:\n+                    for constraint in getattr(self.model._meta, 'constraints', ()):\n+                        if isinstance(constraint, UniqueConstraint) and constraint.condition is None and tuple(constraint.fields) == (field_name,):\n+                            is_unique = True\n+                            break\n+            if not is_unique:\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n         if id_list is not None:\n             if not id_list:\n                 return {}\n"
  },
  "django__django-9296": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-9296",
    "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..c6ed25930d 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -106,6 +106,11 @@ class Paginator:\n         \"\"\"\n         return range(1, self.num_pages + 1)\n \n+    def __iter__(self):\n+        \"\"\"Iterate over pages, yielding Page objects for each page number.\"\"\"\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n+\n     def _check_object_list_is_ordered(self):\n         \"\"\"\n         Warn if self.object_list is unordered (typically a QuerySet).\n"
  },
  "sphinx-doc__sphinx-10323": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10323",
    "model_patch": "diff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..9437fe9a5 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -224,9 +224,9 @@ class LiteralIncludeReader:\n                        self.start_filter,\n                        self.end_filter,\n                        self.lines_filter,\n+                       self.dedent_filter,\n                        self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+                       self.append_filter]\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\n"
  },
  "sphinx-doc__sphinx-10435": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10435",
    "model_patch": "diff --git a/sphinx/writers/latex.py b/sphinx/writers/latex.py\nindex e0c7d56f8..acb6151c1 100644\n--- a/sphinx/writers/latex.py\n+++ b/sphinx/writers/latex.py\n@@ -721,10 +721,10 @@ class LaTeXTranslator(SphinxTranslator):\n         pass\n \n     def visit_desc_inline(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append('%' + CR + r'\\sphinxcode{\\sphinxupquote{')\n \n     def depart_desc_inline(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n \n     # Nodes for high-level structure in signatures\n     ##############################################\n@@ -734,15 +734,15 @@ class LaTeXTranslator(SphinxTranslator):\n         self.literal_whitespace += 1\n \n     def depart_desc_name(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n         self.literal_whitespace -= 1\n \n     def visit_desc_addname(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append('%' + CR + r'\\sphinxcode{\\sphinxupquote{')\n         self.literal_whitespace += 1\n \n     def depart_desc_addname(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n         self.literal_whitespace -= 1\n \n     def visit_desc_type(self, node: Element) -> None:\n@@ -788,7 +788,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxbfcode{\\sphinxupquote{')\n \n     def depart_desc_annotation(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n \n     ##############################################\n \n@@ -1621,7 +1621,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxstyleliteralemphasis{\\sphinxupquote{')\n \n     def depart_literal_emphasis(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n \n     def visit_strong(self, node: Element) -> None:\n         self.body.append(r'\\sphinxstylestrong{')\n@@ -1633,7 +1633,7 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append(r'\\sphinxstyleliteralstrong{\\sphinxupquote{')\n \n     def depart_literal_strong(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n \n     def visit_abbreviation(self, node: Element) -> None:\n         abbr = node.astext()\n@@ -1701,7 +1701,7 @@ class LaTeXTranslator(SphinxTranslator):\n             return\n         lang = node.get(\"language\", None)\n         if 'code' not in node['classes'] or not lang:\n-            self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+            self.body.append('%' + CR + r'\\sphinxcode{\\sphinxupquote{')\n             return\n \n         opts = self.config.highlight_options.get(lang, {})\n@@ -1714,11 +1714,11 @@ class LaTeXTranslator(SphinxTranslator):\n         # get consistent trailer\n         hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n         self.body.append(hlcode)\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n         raise nodes.SkipNode\n \n     def depart_literal(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%' + CR + '}}')\n \n     def visit_footnote_reference(self, node: Element) -> None:\n         raise nodes.SkipNode\n"
  },
  "sphinx-doc__sphinx-10466": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10466",
    "model_patch": "diff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..20d3a3afc 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -32,8 +32,17 @@ class Message:\n     \"\"\"An entry of translatable message.\"\"\"\n     def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n         self.text = text\n-        self.locations = locations\n-        self.uuids = uuids\n+        # remove duplicate locations while preserving order and keep corresponding uuids\n+        seen = set()\n+        unique_locations = []\n+        unique_uuids = []\n+        for loc, uid in zip(locations, uuids):\n+            if loc not in seen:\n+                seen.add(loc)\n+                unique_locations.append(loc)\n+                unique_uuids.append(uid)\n+        self.locations = unique_locations\n+        self.uuids = unique_uuids\n \n \n class Catalog:\n"
  },
  "sphinx-doc__sphinx-11510": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-11510",
    "model_patch": "diff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 19f7c0a8d..5f473ae7d 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -376,6 +376,38 @@ class Include(BaseInclude, SphinxDirective):\n         rel_filename, filename = self.env.relfn2path(self.arguments[0])\n         self.arguments[0] = filename\n         self.env.note_included(filename)\n+        # Emit 'source-read' for included files so extensions can modify their source\n+        try:\n+            # read included file content using document settings\n+            enc = self.state.document.settings.input_encoding\n+            ehandler = self.state.document.settings.input_encoding_error_handler\n+            with open(filename, 'r', encoding=enc, errors=ehandler) as f:\n+                included_text = f.read()\n+            # determine docname for the included file if possible\n+            try:\n+                docname = self.env.path2doc(filename) or self.env.docname\n+            except Exception:\n+                docname = getattr(self.env, 'docname', None)\n+            if docname is None:\n+                docname = self.env.docname\n+            arg = [included_text]\n+            try:\n+                self.env.events.emit('source-read', docname, arg)\n+                # write back modified content to a temp file if changed so docutils reads it\n+                if arg[0] != included_text:\n+                    # overwrite filename for this inclusion by creating a temporary file\n+                    import tempfile, os\n+                    tf = tempfile.NamedTemporaryFile(delete=False, suffix='.rst', mode='w', encoding=enc)\n+                    tf.write(arg[0])\n+                    tf.close()\n+                    # replace the argument so docutils.Include will read from temp file\n+                    self.arguments[0] = tf.name\n+                    # note: we don't call env.note_included for the temp file\n+            except Exception:\n+                pass\n+        except Exception:\n+            # ignore any IO errors and continue with normal include\n+            pass\n         return super().run()\n \n \n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/c.py b/sphinx/domains/c.py\nindex 8854d7941..b0ac2d649 100644\n--- a/sphinx/domains/c.py\n+++ b/sphinx/domains/c.py\n@@ -2080,9 +2080,18 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n-                while self.current_char in 'uUlLfF':\n-                    self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+                # accept builtin suffixes (u, U, l, L, f, F)\n+                    if self.current_char in 'uUlLfF':\n+                        while self.current_char in 'uUlLfF':\n+                            self.pos += 1\n+                    else:\n+                        # accept user-defined literal suffixes: identifiers possibly\n+                        # with namespace qualifiers (::), underscores and digits\n+                        if (self.current_char.isalpha() or self.current_char == '_' or self.current_char == ':'):\n+                            # consume identifier parts and namespace qualifiers\n+                            while not self.eof and (self.current_char.isalnum() or self.current_char in ['_', ':']):\n+                                self.pos += 1\n+                    return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n         if string is not None:\ndiff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..86ca4df8e 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4662,9 +4662,18 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n-                while self.current_char in 'uUlLfF':\n-                    self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+                # accept builtin suffixes (u, U, l, L, f, F)\n+                    if self.current_char in 'uUlLfF':\n+                        while self.current_char in 'uUlLfF':\n+                            self.pos += 1\n+                    else:\n+                        # accept user-defined literal suffixes: identifiers possibly\n+                        # with namespace qualifiers (::), underscores and digits\n+                        if (self.current_char.isalpha() or self.current_char == '_' or self.current_char == ':'):\n+                            # consume identifier parts and namespace qualifiers\n+                            while not self.eof and (self.current_char.isalnum() or self.current_char in ['_', ':']):\n+                                self.pos += 1\n+                    return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n         if string is not None:\n"
  },
  "sphinx-doc__sphinx-7748": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7748",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex f8e4be999..09b522955 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1049,24 +1049,37 @@ class DocstringSignatureMixin:\n             # no lines in docstring, no match\n             if not doclines:\n                 continue\n-            # match first line of docstring against signature RE\n-            match = py_ext_sig_re.match(doclines[0])\n-            if not match:\n+            # try to match as many leading signature lines as present\n+            args_list = []\n+            retann = None\n+            j = 0\n+            while j < len(doclines):\n+                line = doclines[j]\n+                match = py_ext_sig_re.match(line)\n+                if not match:\n+                    break\n+                exmod, path, base, args, this_retann = match.groups()\n+                # the base name must match ours\n+                valid_names = [self.objpath[-1]]  # type: ignore\n+                if isinstance(self, ClassDocumenter):\n+                    valid_names.append('__init__')\n+                    if hasattr(self.object, '__mro__'):\n+                        valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n+                if base not in valid_names:\n+                    break\n+                # collect this signature's args and remember return annotation from first\n+                args_list.append(args or '')\n+                if retann is None:\n+                    retann = this_retann\n+                j += 1\n+            if not args_list:\n                 continue\n-            exmod, path, base, args, retann = match.groups()\n-            # the base name must match ours\n-            valid_names = [self.objpath[-1]]  # type: ignore\n-            if isinstance(self, ClassDocumenter):\n-                valid_names.append('__init__')\n-                if hasattr(self.object, '__mro__'):\n-                    valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n-            if base not in valid_names:\n-                continue\n-            # re-prepare docstring to ignore more leading indentation\n+            # re-prepare docstring to ignore more leading indentation after all signature lines\n             tab_width = self.directive.state.document.settings.tab_width  # type: ignore\n-            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[1:]),\n+            self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[j:]),\n                                                         tabsize=tab_width)\n-            result = args, retann\n+            # combine multiple signatures into a single string separated by newlines\n+            result = ('\\n'.join(args_list), retann)\n             # don't look any further\n             break\n         return result\n"
  },
  "sphinx-doc__sphinx-7757": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7757",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 15f0d66e2..6b2f7d864 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -521,10 +521,20 @@ def signature_from_str(signature: str) -> inspect.Signature:\n     params = []\n \n     if hasattr(args, \"posonlyargs\"):\n-        for arg in args.posonlyargs:  # type: ignore\n+        # defaults for posonlyargs are included in args.defaults together with args.args\n+        total_pos = len(args.posonlyargs) + len(args.args)\n+        for i, arg in enumerate(args.posonlyargs):  # type: ignore\n+            # determine if this positional-only arg has a default\n+            defaults = args.defaults or []\n+            # position in the combined positional list\n+            pos_index = i\n+            if total_pos - pos_index <= len(defaults):\n+                default = ast_unparse(defaults[-total_pos + pos_index])\n+            else:\n+                default = Parameter.empty\n             annotation = ast_unparse(arg.annotation) or Parameter.empty\n             params.append(Parameter(arg.arg, Parameter.POSITIONAL_ONLY,\n-                                    annotation=annotation))\n+                                    default=default, annotation=annotation))\n \n     for i, arg in enumerate(args.args):\n         if len(args.args) - i <= len(args.defaults):\n"
  },
  "sphinx-doc__sphinx-7985": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7985",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..a20fe5c89 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -210,10 +210,43 @@ class CheckExternalLinksBuilder(Builder):\n \n         def check() -> Tuple[str, str, int]:\n             # check for various conditions without bothering the network\n-            if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n+            if len(uri) == 0 or uri.startswith(('mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n+            # anchors within the same page are unchecked\n+            elif uri.startswith('#'):\n+                return 'unchecked', '', 0\n+            # local/internal links (no http/https scheme)\n             elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+                # split off anchor if any\n+                if '#' in uri:\n+                    local_target, local_anchor = uri.split('#', 1)\n+                else:\n+                    local_target, local_anchor = uri, None\n+                # Normalize target docname (strip .html and leading/trailing slashes)\n+                if local_target.endswith('.html'):\n+                    local_target = local_target[:-5]\n+                local_target = local_target.strip('/')\n+                # empty local_target refers to current document -> unchecked\n+                if not local_target:\n+                    return 'unchecked', '', 0\n+                # check existence in environment\n+                if local_target in self.env.found_docs:\n+                    # if there's an anchor, try to verify it in the doctree\n+                    if local_anchor and self.app.config.linkcheck_anchors:\n+                        try:\n+                            doctree = self.env.get_doctree(local_target)\n+                            ids = getattr(doctree, 'ids', {})\n+                            names = getattr(doctree, 'names', {})\n+                            if local_anchor in ids or local_anchor in names:\n+                                return 'working', '', 0\n+                            else:\n+                                return 'broken', \"Anchor '%s' not found\" % local_anchor, 0\n+                        except Exception:\n+                            # if we can't get the doctree, assume working\n+                            return 'working', '', 0\n+                    return 'working', '', 0\n+                else:\n+                    return 'broken', 'local target not found', 0\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n"
  },
  "sphinx-doc__sphinx-8035": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8035",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 8c3509c3b..b39455c7d 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -649,14 +649,32 @@ class Documenter:\n             elif (namespace, membername) in attr_docs:\n                 if want_all and isprivate:\n                     # ignore members whose name starts with _ by default\n-                    keep = self.options.private_members\n+                    pm = self.options.private_members\n+                    if pm is ALL:\n+                        keep = True\n+                    elif pm in (None, False):\n+                        keep = False\n+                    else:\n+                        try:\n+                            keep = membername in pm\n+                        except Exception:\n+                            keep = False\n                 else:\n                     # keep documented attributes\n                     keep = True\n                 isattr = True\n             elif want_all and isprivate:\n                 # ignore members whose name starts with _ by default\n-                keep = self.options.private_members and \\\n+                pm = self.options.private_members\n+                if pm is ALL:\n+                    keep = True\n+                elif pm in (None, False):\n+                    keep = False\n+                else:\n+                    try:\n+                        keep = membername in pm\n+                    except Exception:\n+                        keep = False and \\\n                     (has_doc or self.options.undoc_members)\n             else:\n                 if self.options.members is ALL and is_filtered_inherited_member(membername):\n@@ -859,7 +877,7 @@ class ModuleDocumenter(Documenter):\n         'show-inheritance': bool_option, 'synopsis': identity,\n         'platform': identity, 'deprecated': bool_option,\n         'member-order': member_order_option, 'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n         'imported-members': bool_option, 'ignore-module-all': bool_option\n     }  # type: Dict[str, Callable]\n \n@@ -1279,7 +1297,7 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         'noindex': bool_option, 'inherited-members': inherited_members_option,\n         'show-inheritance': bool_option, 'member-order': member_order_option,\n         'exclude-members': members_set_option,\n-        'private-members': bool_option, 'special-members': members_option,\n+        'private-members': members_option, 'special-members': members_option,\n     }  # type: Dict[str, Callable]\n \n     _signature_class = None  # type: Any\n"
  },
  "sphinx-doc__sphinx-8056": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8056",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..d1c8d24fa 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -251,6 +251,14 @@ class GoogleDocstring:\n         before, colon, after = self._partition_field_on_colon(line)\n         _name, _type, _desc = before, '', after\n \n+        # If there is a colon and text after it, assume the portion after the\n+        # colon is a type specification (e.g. \"x1, x2 : array_like\"). This\n+        # allows multiple names to share a type. The description (if any)\n+        # will be taken from the subsequent indented block.\n+        if colon and after and parse_type:\n+            _type = after\n+            _desc = ''\n+\n         if parse_type:\n             match = _google_typed_arg_regex.match(before)\n             if match:\n@@ -273,7 +281,16 @@ class GoogleDocstring:\n         while not self._is_section_break():\n             _name, _type, _desc = self._consume_field(parse_type, prefer_type)\n             if _name or _type or _desc:\n-                fields.append((_name, _type, _desc,))\n+                # Split comma-separated names so that lines like\n+                # \"x1, x2 : array_like\" yield separate fields for x1 and x2\n+                # with the same type and description.\n+                if ',' in _name:\n+                    for nm in (_name.split(',')):\n+                        nm = nm.strip()\n+                        if nm:\n+                            fields.append((nm, _type, _desc,))\n+                else:\n+                    fields.append((_name, _type, _desc,))\n         return fields\n \n     def _consume_inline_attribute(self) -> Tuple[str, List[str]]:\n"
  },
  "sphinx-doc__sphinx-8265": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8265",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex 9bafff11c..34967be1b 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -172,10 +172,15 @@ class _UnparseVisitor(ast.NodeVisitor):\n         return \"%s %s\" % (self.visit(node.op), self.visit(node.operand))\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n-        if node.elts:\n-            return \", \".join(self.visit(e) for e in node.elts)\n-        else:\n+        # Parenthesize tuples so that defaults like (1, 1, 1) are rendered\n+        # correctly (and single-element tuples keep the trailing comma).\n+        if not node.elts:\n             return \"()\"\n+        elts = \", \".join(self.visit(e) for e in node.elts)\n+        if len(node.elts) == 1:\n+            # single-element tuple needs a trailing comma\n+            return f\"({elts},)\"\n+        return f\"({elts})\"\n \n     if sys.version_info >= (3, 6):\n         def visit_Constant(self, node: ast.Constant) -> str:\n"
  },
  "sphinx-doc__sphinx-8269": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8269",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..593beb723 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -166,6 +166,8 @@ class CheckExternalLinksBuilder(Builder):\n                     # Read the whole document and see if #anchor exists\n                     response = requests.get(req_url, stream=True, config=self.app.config,\n                                             auth=auth_info, **kwargs)\n+                    response.raise_for_status()\n+\n                     found = check_anchor(response, unquote(anchor))\n \n                     if not found:\n"
  },
  "sphinx-doc__sphinx-8475": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8475",
    "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..4104fe658 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -20,7 +20,7 @@ from urllib.parse import unquote, urlparse\n \n from docutils import nodes\n from docutils.nodes import Node\n-from requests.exceptions import HTTPError\n+from requests.exceptions import HTTPError, TooManyRedirects\n \n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -172,7 +172,7 @@ class CheckExternalLinksBuilder(Builder):\n                                                  config=self.app.config, auth=auth_info,\n                                                  **kwargs)\n                         response.raise_for_status()\n-                    except HTTPError:\n+                    except (HTTPError, TooManyRedirects):\n                         # retry with GET request if that fails, some servers\n                         # don't like HEAD requests.\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n"
  },
  "sphinx-doc__sphinx-8548": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8548",
    "model_patch": "diff --git a/sphinx/addnodes.py b/sphinx/addnodes.py\nindex 33503bb08..d2276609c 100644\n--- a/sphinx/addnodes.py\n+++ b/sphinx/addnodes.py\n@@ -412,7 +412,7 @@ def setup(app: \"Sphinx\") -> Dict[str, Any]:\n     app.add_node(start_of_file)\n     app.add_node(highlightlang)\n     app.add_node(tabular_col_spec)\n-    app.add_node(meta)\n+    app.add_node(meta, override=True)\n     app.add_node(pending_xref)\n     app.add_node(number_reference)\n     app.add_node(download_reference)\ndiff --git a/sphinx/addnodes.py.bak b/sphinx/addnodes.py.bak\nnew file mode 100644\nindex 000000000..33503bb08\n--- /dev/null\n+++ b/sphinx/addnodes.py.bak\n@@ -0,0 +1,427 @@\n+\"\"\"\n+    sphinx.addnodes\n+    ~~~~~~~~~~~~~~~\n+\n+    Additional docutils nodes.\n+\n+    :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.\n+    :license: BSD, see LICENSE for details.\n+\"\"\"\n+\n+import warnings\n+from typing import Any, Dict, List, Sequence\n+\n+from docutils import nodes\n+from docutils.nodes import Element, Node\n+\n+from sphinx.deprecation import RemovedInSphinx40Warning\n+\n+if False:\n+    # For type annotation\n+    from sphinx.application import Sphinx\n+\n+\n+class document(nodes.document):\n+    \"\"\"The document root element patched by Sphinx.\n+\n+    This fixes that document.set_id() does not support a node having multiple node Ids.\n+    see https://sourceforge.net/p/docutils/patches/167/\n+\n+    .. important:: This is only for Sphinx internal use.  Please don't use this\n+                   in your extensions.  It will be removed without deprecation period.\n+    \"\"\"\n+\n+    def set_id(self, node: Element, msgnode: Element = None,\n+               suggested_prefix: str = '') -> str:\n+        from sphinx.util import docutils\n+        if docutils.__version_info__ >= (0, 16):\n+            ret = super().set_id(node, msgnode, suggested_prefix)  # type: ignore\n+        else:\n+            ret = super().set_id(node, msgnode)\n+\n+        if docutils.__version_info__ < (0, 17):\n+            # register other node IDs forcedly\n+            for node_id in node['ids']:\n+                if node_id not in self.ids:\n+                    self.ids[node_id] = node\n+\n+        return ret\n+\n+\n+class translatable(nodes.Node):\n+    \"\"\"Node which supports translation.\n+\n+    The translation goes forward with following steps:\n+\n+    1. Preserve original translatable messages\n+    2. Apply translated messages from message catalog\n+    3. Extract preserved messages (for gettext builder)\n+\n+    The translatable nodes MUST preserve original messages.\n+    And these messages should not be overridden at applying step.\n+    Because they are used at final step; extraction.\n+    \"\"\"\n+\n+    def preserve_original_messages(self) -> None:\n+        \"\"\"Preserve original translatable messages.\"\"\"\n+        raise NotImplementedError\n+\n+    def apply_translated_message(self, original_message: str, translated_message: str) -> None:\n+        \"\"\"Apply translated message.\"\"\"\n+        raise NotImplementedError\n+\n+    def extract_original_messages(self) -> Sequence[str]:\n+        \"\"\"Extract translation messages.\n+\n+        :returns: list of extracted messages or messages generator\n+        \"\"\"\n+        raise NotImplementedError\n+\n+\n+class not_smartquotable:\n+    \"\"\"A node which does not support smart-quotes.\"\"\"\n+    support_smartquotes = False\n+\n+\n+class toctree(nodes.General, nodes.Element, translatable):\n+    \"\"\"Node for inserting a \"TOC tree\".\"\"\"\n+\n+    def preserve_original_messages(self) -> None:\n+        # toctree entries\n+        rawentries = self.setdefault('rawentries', [])\n+        for title, docname in self['entries']:\n+            if title:\n+                rawentries.append(title)\n+\n+        # :caption: option\n+        if self.get('caption'):\n+            self['rawcaption'] = self['caption']\n+\n+    def apply_translated_message(self, original_message: str, translated_message: str) -> None:\n+        # toctree entries\n+        for i, (title, docname) in enumerate(self['entries']):\n+            if title == original_message:\n+                self['entries'][i] = (translated_message, docname)\n+\n+        # :caption: option\n+        if self.get('rawcaption') == original_message:\n+            self['caption'] = translated_message\n+\n+    def extract_original_messages(self) -> List[str]:\n+        messages = []  # type: List[str]\n+\n+        # toctree entries\n+        messages.extend(self.get('rawentries', []))\n+\n+        # :caption: option\n+        if 'rawcaption' in self:\n+            messages.append(self['rawcaption'])\n+        return messages\n+\n+\n+# domain-specific object descriptions (class, function etc.)\n+\n+class desc(nodes.Admonition, nodes.Element):\n+    \"\"\"Node for object descriptions.\n+\n+    This node is similar to a \"definition list\" with one definition.  It\n+    contains one or more ``desc_signature`` and a ``desc_content``.\n+    \"\"\"\n+\n+\n+class desc_signature(nodes.Part, nodes.Inline, nodes.TextElement):\n+    \"\"\"Node for object signatures.\n+\n+    The \"term\" part of the custom Sphinx definition list.\n+\n+    As default the signature is a single line signature,\n+    but set ``is_multiline = True`` to describe a multi-line signature.\n+    In that case all child nodes must be ``desc_signature_line`` nodes.\n+    \"\"\"\n+\n+    @property\n+    def child_text_separator(self):\n+        if self.get('is_multiline'):\n+            return ' '\n+        else:\n+            return super().child_text_separator\n+\n+\n+class desc_signature_line(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for a line in a multi-line object signatures.\n+\n+    It should only be used in a ``desc_signature`` with ``is_multiline`` set.\n+    Set ``add_permalink = True`` for the line that should get the permalink.\n+    \"\"\"\n+    sphinx_line_type = ''\n+\n+\n+# nodes to use within a desc_signature or desc_signature_line\n+\n+class desc_addname(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for additional name parts (module name, class name).\"\"\"\n+\n+\n+# compatibility alias\n+desc_classname = desc_addname\n+\n+\n+class desc_type(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for return types or object type names.\"\"\"\n+\n+\n+class desc_returns(desc_type):\n+    \"\"\"Node for a \"returns\" annotation (a la -> in Python).\"\"\"\n+    def astext(self) -> str:\n+        return ' -> ' + super().astext()\n+\n+\n+class desc_name(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for the main object name.\"\"\"\n+\n+\n+class desc_parameterlist(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for a general parameter list.\"\"\"\n+    child_text_separator = ', '\n+\n+    def astext(self):\n+        return '({})'.format(super().astext())\n+\n+\n+class desc_parameter(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for a single parameter.\"\"\"\n+\n+\n+class desc_optional(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for marking optional parts of the parameter list.\"\"\"\n+    child_text_separator = ', '\n+\n+    def astext(self) -> str:\n+        return '[' + super().astext() + ']'\n+\n+\n+class desc_annotation(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for signature annotations (not Python 3-style annotations).\"\"\"\n+\n+\n+class desc_content(nodes.General, nodes.Element):\n+    \"\"\"Node for object description content.\n+\n+    This is the \"definition\" part of the custom Sphinx definition list.\n+    \"\"\"\n+\n+\n+class desc_sig_element(nodes.inline):\n+    \"\"\"Common parent class of nodes for inline text of a signature.\"\"\"\n+    classes = []  # type: List[str]\n+\n+    def __init__(self, rawsource: str = '', text: str = '',\n+                 *children: Element, **attributes: Any) -> None:\n+        super().__init__(rawsource, text, *children, **attributes)\n+        self['classes'].extend(self.classes)\n+\n+\n+class desc_sig_name(desc_sig_element):\n+    \"\"\"Node for a name in a signature.\"\"\"\n+    classes = [\"n\"]\n+\n+\n+class desc_sig_operator(desc_sig_element):\n+    \"\"\"Node for an operator in a signature.\"\"\"\n+    classes = [\"o\"]\n+\n+\n+class desc_sig_punctuation(desc_sig_element):\n+    \"\"\"Node for a punctuation in a signature.\"\"\"\n+    classes = [\"p\"]\n+\n+\n+# new admonition-like constructs\n+\n+class versionmodified(nodes.Admonition, nodes.TextElement):\n+    \"\"\"Node for version change entries.\n+\n+    Currently used for \"versionadded\", \"versionchanged\" and \"deprecated\"\n+    directives.\n+    \"\"\"\n+\n+\n+class seealso(nodes.Admonition, nodes.Element):\n+    \"\"\"Custom \"see also\" admonition.\"\"\"\n+\n+\n+class productionlist(nodes.Admonition, nodes.Element):\n+    \"\"\"Node for grammar production lists.\n+\n+    Contains ``production`` nodes.\n+    \"\"\"\n+\n+\n+class production(nodes.Part, nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for a single grammar production rule.\"\"\"\n+\n+\n+# other directive-level nodes\n+\n+class index(nodes.Invisible, nodes.Inline, nodes.TextElement):\n+    \"\"\"Node for index entries.\n+\n+    This node is created by the ``index`` directive and has one attribute,\n+    ``entries``.  Its value is a list of 5-tuples of ``(entrytype, entryname,\n+    target, ignored, key)``.\n+\n+    *entrytype* is one of \"single\", \"pair\", \"double\", \"triple\".\n+\n+    *key* is categorization characters (usually a single character) for\n+    general index page. For the details of this, please see also:\n+    :rst:dir:`glossary` and issue #2320.\n+    \"\"\"\n+\n+\n+class centered(nodes.Part, nodes.TextElement):\n+    \"\"\"Deprecated.\"\"\"\n+\n+\n+class acks(nodes.Element):\n+    \"\"\"Special node for \"acks\" lists.\"\"\"\n+\n+\n+class hlist(nodes.Element):\n+    \"\"\"Node for \"horizontal lists\", i.e. lists that should be compressed to\n+    take up less vertical space.\n+    \"\"\"\n+\n+\n+class hlistcol(nodes.Element):\n+    \"\"\"Node for one column in a horizontal list.\"\"\"\n+\n+\n+class compact_paragraph(nodes.paragraph):\n+    \"\"\"Node for a compact paragraph (which never makes a <p> node).\"\"\"\n+\n+\n+class glossary(nodes.Element):\n+    \"\"\"Node to insert a glossary.\"\"\"\n+\n+\n+class only(nodes.Element):\n+    \"\"\"Node for \"only\" directives (conditional inclusion based on tags).\"\"\"\n+\n+\n+# meta-information nodes\n+\n+class start_of_file(nodes.Element):\n+    \"\"\"Node to mark start of a new file, used in the LaTeX builder only.\"\"\"\n+\n+\n+class highlightlang(nodes.Element):\n+    \"\"\"Inserted to set the highlight language and line number options for\n+    subsequent code blocks.\n+    \"\"\"\n+\n+\n+class tabular_col_spec(nodes.Element):\n+    \"\"\"Node for specifying tabular columns, used for LaTeX output.\"\"\"\n+\n+\n+class meta(nodes.Special, nodes.PreBibliographic, nodes.Element):\n+    \"\"\"Node for meta directive -- same as docutils' standard meta node,\n+    but pickleable.\n+    \"\"\"\n+    rawcontent = None\n+\n+\n+# inline nodes\n+\n+class pending_xref(nodes.Inline, nodes.Element):\n+    \"\"\"Node for cross-references that cannot be resolved without complete\n+    information about all documents.\n+\n+    These nodes are resolved before writing output, in\n+    BuildEnvironment.resolve_references.\n+    \"\"\"\n+\n+\n+class number_reference(nodes.reference):\n+    \"\"\"Node for number references, similar to pending_xref.\"\"\"\n+\n+\n+class download_reference(nodes.reference):\n+    \"\"\"Node for download references, similar to pending_xref.\"\"\"\n+\n+\n+class literal_emphasis(nodes.emphasis, not_smartquotable):\n+    \"\"\"Node that behaves like `emphasis`, but further text processors are not\n+    applied (e.g. smartypants for HTML output).\n+    \"\"\"\n+\n+\n+class literal_strong(nodes.strong, not_smartquotable):\n+    \"\"\"Node that behaves like `strong`, but further text processors are not\n+    applied (e.g. smartypants for HTML output).\n+    \"\"\"\n+\n+\n+class abbreviation(nodes.abbreviation):\n+    \"\"\"Node for abbreviations with explanations.\n+\n+    .. deprecated:: 2.0\n+    \"\"\"\n+\n+    def __init__(self, rawsource: str = '', text: str = '',\n+                 *children: Node, **attributes: Any) -> None:\n+        warnings.warn(\"abbrevition node for Sphinx was replaced by docutils'.\",\n+                      RemovedInSphinx40Warning, stacklevel=2)\n+\n+        super().__init__(rawsource, text, *children, **attributes)\n+\n+\n+class manpage(nodes.Inline, nodes.FixedTextElement):\n+    \"\"\"Node for references to manpages.\"\"\"\n+\n+\n+def setup(app: \"Sphinx\") -> Dict[str, Any]:\n+    app.add_node(toctree)\n+    app.add_node(desc)\n+    app.add_node(desc_signature)\n+    app.add_node(desc_signature_line)\n+    app.add_node(desc_addname)\n+    app.add_node(desc_type)\n+    app.add_node(desc_returns)\n+    app.add_node(desc_name)\n+    app.add_node(desc_parameterlist)\n+    app.add_node(desc_parameter)\n+    app.add_node(desc_optional)\n+    app.add_node(desc_annotation)\n+    app.add_node(desc_content)\n+    app.add_node(desc_sig_name)\n+    app.add_node(desc_sig_operator)\n+    app.add_node(desc_sig_punctuation)\n+    app.add_node(versionmodified)\n+    app.add_node(seealso)\n+    app.add_node(productionlist)\n+    app.add_node(production)\n+    app.add_node(index)\n+    app.add_node(centered)\n+    app.add_node(acks)\n+    app.add_node(hlist)\n+    app.add_node(hlistcol)\n+    app.add_node(compact_paragraph)\n+    app.add_node(glossary)\n+    app.add_node(only)\n+    app.add_node(start_of_file)\n+    app.add_node(highlightlang)\n+    app.add_node(tabular_col_spec)\n+    app.add_node(meta)\n+    app.add_node(pending_xref)\n+    app.add_node(number_reference)\n+    app.add_node(download_reference)\n+    app.add_node(literal_emphasis)\n+    app.add_node(literal_strong)\n+    app.add_node(manpage)\n+\n+    return {\n+        'version': 'builtin',\n+        'parallel_read_safe': True,\n+        'parallel_write_safe': True,\n+    }\ndiff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex ddfd2b365..e2cdd7b2a 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -598,11 +598,38 @@ class Documenter:\n             attr_docs = self.analyzer.find_attr_docs()\n             if self.objpath:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n-                if key in attr_docs:\n+                doc = None\n+                try:\n+                    if key in attr_docs:\n+                        doc = list(attr_docs[key])\n+                except Exception:\n+                    doc = None\n+                if not doc:\n+                    try:\n+                        if inspect.isclass(self.object):\n+                            for cls in inspect.getmro(self.object):\n+                                if cls is self.object:\n+                                    continue\n+                                try:\n+                                    module = safe_getattr(cls, '__module__')\n+                                    qualname = safe_getattr(cls, '__qualname__')\n+                                    if not module or not qualname:\n+                                        continue\n+                                    analyzer2 = ModuleAnalyzer.for_module(module)\n+                                    analyzer2.analyze()\n+                                    key2 = (qualname, key[1])\n+                                    if key2 in analyzer2.attr_docs:\n+                                        doc = list(analyzer2.attr_docs[key2])\n+                                        break\n+                                except (AttributeError, PycodeError):\n+                                    continue\n+                    except Exception:\n+                        pass\n+                if doc:\n                     no_docstring = True\n                     # make a copy of docstring for attributes to avoid cache\n                     # the change of autodoc-process-docstring event.\n-                    docstrings = [list(attr_docs[key])]\n+                    docstrings = [list(doc)]\n \n                     for i, line in enumerate(self.process_doc(docstrings)):\n                         self.add_line(line, sourcename, i)\n@@ -717,6 +744,32 @@ class Documenter:\n                 doc = obj.docstring\n \n             has_doc = bool(doc)\n+            doc_from_attr = None\n+            try:\n+                if (namespace, membername) in attr_docs:\n+                    doc_from_attr = attr_docs[(namespace, membername)]\n+            except Exception:\n+                doc_from_attr = None\n+            if not doc_from_attr:\n+                try:\n+                    if inspect.isclass(self.object):\n+                        for cls in inspect.getmro(self.object):\n+                            if cls is self.object:\n+                                continue\n+                            try:\n+                                module = safe_getattr(cls, '__module__', None)\n+                                qualname = safe_getattr(cls, '__qualname__', None)\n+                                if not module or not qualname:\n+                                    continue\n+                                analyzer2 = ModuleAnalyzer.for_module(module)\n+                                analyzer2.analyze()\n+                                if (qualname, membername) in analyzer2.attr_docs:\n+                                    doc_from_attr = analyzer2.attr_docs[(qualname, membername)]\n+                                    break\n+                            except (AttributeError, PycodeError):\n+                                continue\n+                except Exception:\n+                    pass\n \n             metadata = extract_metadata(doc)\n             if 'private' in metadata:\n@@ -746,7 +799,7 @@ class Documenter:\n                         keep = has_doc or self.options.undoc_members\n                 else:\n                     keep = False\n-            elif (namespace, membername) in attr_docs:\n+            elif doc_from_attr:\n                 if want_all and isprivate:\n                     if self.options.private_members is None:\n                         keep = False\ndiff --git a/sphinx/ext/autodoc/__init__.py.bak b/sphinx/ext/autodoc/__init__.py.bak\nnew file mode 100644\nindex 000000000..ddfd2b365\n--- /dev/null\n+++ b/sphinx/ext/autodoc/__init__.py.bak\n@@ -0,0 +1,2499 @@\n+\"\"\"\n+    sphinx.ext.autodoc\n+    ~~~~~~~~~~~~~~~~~~\n+\n+    Automatically insert docstrings for functions, classes or whole modules into\n+    the doctree, thus avoiding duplication between docstrings and documentation\n+    for those who like elaborate docstrings.\n+\n+    :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.\n+    :license: BSD, see LICENSE for details.\n+\"\"\"\n+\n+import importlib\n+import re\n+import warnings\n+from inspect import Parameter, Signature\n+from types import ModuleType\n+from typing import (Any, Callable, Dict, Iterator, List, Optional, Sequence, Set, Tuple, Type,\n+                    TypeVar, Union)\n+\n+from docutils.statemachine import StringList\n+\n+import sphinx\n+from sphinx.application import Sphinx\n+from sphinx.config import ENUM, Config\n+from sphinx.deprecation import (RemovedInSphinx40Warning, RemovedInSphinx50Warning,\n+                                RemovedInSphinx60Warning)\n+from sphinx.environment import BuildEnvironment\n+from sphinx.ext.autodoc.importer import (get_class_members, get_module_members,\n+                                         get_object_members, import_object)\n+from sphinx.ext.autodoc.mock import mock\n+from sphinx.locale import _, __\n+from sphinx.pycode import ModuleAnalyzer, PycodeError\n+from sphinx.util import inspect, logging\n+from sphinx.util.docstrings import extract_metadata, prepare_docstring\n+from sphinx.util.inspect import (evaluate_signature, getdoc, object_description, safe_getattr,\n+                                 stringify_signature)\n+from sphinx.util.typing import get_type_hints, restify\n+from sphinx.util.typing import stringify as stringify_typehint\n+\n+if False:\n+    # For type annotation\n+    from typing import Type  # NOQA # for python3.5.1\n+\n+    from sphinx.ext.autodoc.directive import DocumenterBridge\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+# This type isn't exposed directly in any modules, but can be found\n+# here in most Python versions\n+MethodDescriptorType = type(type.__subclasses__)\n+\n+\n+#: extended signature RE: with explicit module name separated by ::\n+py_ext_sig_re = re.compile(\n+    r'''^ ([\\w.]+::)?            # explicit module name\n+          ([\\w.]+\\.)?            # module and/or class name(s)\n+          (\\w+)  \\s*             # thing name\n+          (?: \\((.*)\\)           # optional: arguments\n+           (?:\\s* -> \\s* (.*))?  #           return annotation\n+          )? $                   # and nothing more\n+          ''', re.VERBOSE)\n+special_member_re = re.compile(r'^__\\S+__$')\n+\n+\n+def identity(x: Any) -> Any:\n+    return x\n+\n+\n+class _All:\n+    \"\"\"A special value for :*-members: that matches to any member.\"\"\"\n+\n+    def __contains__(self, item: Any) -> bool:\n+        return True\n+\n+\n+class _Empty:\n+    \"\"\"A special value for :exclude-members: that never matches to any member.\"\"\"\n+\n+    def __contains__(self, item: Any) -> bool:\n+        return False\n+\n+\n+ALL = _All()\n+EMPTY = _Empty()\n+UNINITIALIZED_ATTR = object()\n+INSTANCEATTR = object()\n+SLOTSATTR = object()\n+\n+\n+def members_option(arg: Any) -> Union[object, List[str]]:\n+    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    if arg is None or arg is True:\n+        return ALL\n+    elif arg is False:\n+        return None\n+    else:\n+        return [x.strip() for x in arg.split(',') if x.strip()]\n+\n+\n+def members_set_option(arg: Any) -> Union[object, Set[str]]:\n+    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    warnings.warn(\"members_set_option() is deprecated.\",\n+                  RemovedInSphinx50Warning, stacklevel=2)\n+    if arg is None:\n+        return ALL\n+    return {x.strip() for x in arg.split(',') if x.strip()}\n+\n+\n+def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n+    \"\"\"Used to convert the :exclude-members: option.\"\"\"\n+    if arg is None:\n+        return EMPTY\n+    return {x.strip() for x in arg.split(',') if x.strip()}\n+\n+\n+def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n+    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    if arg is None:\n+        return 'object'\n+    else:\n+        return arg\n+\n+\n+def member_order_option(arg: Any) -> Optional[str]:\n+    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    if arg is None:\n+        return None\n+    elif arg in ('alphabetical', 'bysource', 'groupwise'):\n+        return arg\n+    else:\n+        raise ValueError(__('invalid value for member-order option: %s') % arg)\n+\n+\n+SUPPRESS = object()\n+\n+\n+def annotation_option(arg: Any) -> Any:\n+    if arg is None:\n+        # suppress showing the representation of the object\n+        return SUPPRESS\n+    else:\n+        return arg\n+\n+\n+def bool_option(arg: Any) -> bool:\n+    \"\"\"Used to convert flag options to auto directives.  (Instead of\n+    directives.flag(), which returns None).\n+    \"\"\"\n+    return True\n+\n+\n+def merge_special_members_option(options: Dict) -> None:\n+    \"\"\"Merge :special-members: option to :members: option.\"\"\"\n+    warnings.warn(\"merge_special_members_option() is deprecated.\",\n+                  RemovedInSphinx50Warning, stacklevel=2)\n+    if 'special-members' in options and options['special-members'] is not ALL:\n+        if options.get('members') is ALL:\n+            pass\n+        elif options.get('members'):\n+            for member in options['special-members']:\n+                if member not in options['members']:\n+                    options['members'].append(member)\n+        else:\n+            options['members'] = options['special-members']\n+\n+\n+def merge_members_option(options: Dict) -> None:\n+    \"\"\"Merge :*-members: option to the :members: option.\"\"\"\n+    if options.get('members') is ALL:\n+        # merging is not needed when members: ALL\n+        return\n+\n+    members = options.setdefault('members', [])\n+    for key in {'private-members', 'special-members'}:\n+        if key in options and options[key] not in (ALL, None):\n+            for member in options[key]:\n+                if member not in members:\n+                    members.append(member)\n+\n+\n+# Some useful event listener factories for autodoc-process-docstring.\n+\n+def cut_lines(pre: int, post: int = 0, what: str = None) -> Callable:\n+    \"\"\"Return a listener that removes the first *pre* and last *post*\n+    lines of every docstring.  If *what* is a sequence of strings,\n+    only docstrings of a type in *what* will be processed.\n+\n+    Use like this (e.g. in the ``setup()`` function of :file:`conf.py`)::\n+\n+       from sphinx.ext.autodoc import cut_lines\n+       app.connect('autodoc-process-docstring', cut_lines(4, what=['module']))\n+\n+    This can (and should) be used in place of :confval:`automodule_skip_lines`.\n+    \"\"\"\n+    def process(app: Sphinx, what_: str, name: str, obj: Any, options: Any, lines: List[str]\n+                ) -> None:\n+        if what and what_ not in what:\n+            return\n+        del lines[:pre]\n+        if post:\n+            # remove one trailing blank line.\n+            if lines and not lines[-1]:\n+                lines.pop(-1)\n+            del lines[-post:]\n+        # make sure there is a blank line at the end\n+        if lines and lines[-1]:\n+            lines.append('')\n+    return process\n+\n+\n+def between(marker: str, what: Sequence[str] = None, keepempty: bool = False,\n+            exclude: bool = False) -> Callable:\n+    \"\"\"Return a listener that either keeps, or if *exclude* is True excludes,\n+    lines between lines that match the *marker* regular expression.  If no line\n+    matches, the resulting docstring would be empty, so no change will be made\n+    unless *keepempty* is true.\n+\n+    If *what* is a sequence of strings, only docstrings of a type in *what* will\n+    be processed.\n+    \"\"\"\n+    marker_re = re.compile(marker)\n+\n+    def process(app: Sphinx, what_: str, name: str, obj: Any, options: Any, lines: List[str]\n+                ) -> None:\n+        if what and what_ not in what:\n+            return\n+        deleted = 0\n+        delete = not exclude\n+        orig_lines = lines[:]\n+        for i, line in enumerate(orig_lines):\n+            if delete:\n+                lines.pop(i - deleted)\n+                deleted += 1\n+            if marker_re.match(line):\n+                delete = not delete\n+                if delete:\n+                    lines.pop(i - deleted)\n+                    deleted += 1\n+        if not lines and not keepempty:\n+            lines[:] = orig_lines\n+        # make sure there is a blank line at the end\n+        if lines and lines[-1]:\n+            lines.append('')\n+    return process\n+\n+\n+# This class is used only in ``sphinx.ext.autodoc.directive``,\n+# But we define this class here to keep compatibility (see #4538)\n+class Options(dict):\n+    \"\"\"A dict/attribute hybrid that returns None on nonexisting keys.\"\"\"\n+    def __getattr__(self, name: str) -> Any:\n+        try:\n+            return self[name.replace('_', '-')]\n+        except KeyError:\n+            return None\n+\n+\n+class ObjectMember(tuple):\n+    \"\"\"A member of object.\n+\n+    This is used for the result of `Documenter.get_object_members()` to\n+    represent each member of the object.\n+\n+    .. Note::\n+\n+       An instance of this class behaves as a tuple of (name, object)\n+       for compatibility to old Sphinx.  The behavior will be dropped\n+       in the future.  Therefore extensions should not use the tuple\n+       interface.\n+    \"\"\"\n+\n+    def __new__(cls, name: str, obj: Any, **kwargs: Any) -> Any:\n+        return super().__new__(cls, (name, obj))  # type: ignore\n+\n+    def __init__(self, name: str, obj: Any, docstring: Optional[str] = None,\n+                 skipped: bool = False) -> None:\n+        self.__name__ = name\n+        self.object = obj\n+        self.docstring = docstring\n+        self.skipped = skipped\n+\n+\n+ObjectMembers = Union[List[ObjectMember], List[Tuple[str, Any]]]\n+\n+\n+class Documenter:\n+    \"\"\"\n+    A Documenter knows how to autodocument a single object type.  When\n+    registered with the AutoDirective, it will be used to document objects\n+    of that type when needed by autodoc.\n+\n+    Its *objtype* attribute selects what auto directive it is assigned to\n+    (the directive name is 'auto' + objtype), and what directive it generates\n+    by default, though that can be overridden by an attribute called\n+    *directivetype*.\n+\n+    A Documenter has an *option_spec* that works like a docutils directive's;\n+    in fact, it will be used to parse an auto directive's options that matches\n+    the documenter.\n+    \"\"\"\n+    #: name by which the directive is called (auto...) and the default\n+    #: generated directive name\n+    objtype = 'object'\n+    #: indentation by which to indent the directive content\n+    content_indent = '   '\n+    #: priority if multiple documenters return True from can_document_member\n+    priority = 0\n+    #: order if autodoc_member_order is set to 'groupwise'\n+    member_order = 0\n+    #: true if the generated content may contain titles\n+    titles_allowed = False\n+\n+    option_spec = {'noindex': bool_option}  # type: Dict[str, Callable]\n+\n+    def get_attr(self, obj: Any, name: str, *defargs: Any) -> Any:\n+        \"\"\"getattr() override for types such as Zope interfaces.\"\"\"\n+        return autodoc_attrgetter(self.env.app, obj, name, *defargs)\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        \"\"\"Called to see if a member can be documented by this documenter.\"\"\"\n+        raise NotImplementedError('must be implemented in subclasses')\n+\n+    def __init__(self, directive: \"DocumenterBridge\", name: str, indent: str = '') -> None:\n+        self.directive = directive\n+        self.config = directive.env.config\n+        self.env = directive.env    # type: BuildEnvironment\n+        self.options = directive.genopt\n+        self.name = name\n+        self.indent = indent\n+        # the module and object path within the module, and the fully\n+        # qualified name (all set after resolve_name succeeds)\n+        self.modname = None         # type: str\n+        self.module = None          # type: ModuleType\n+        self.objpath = None         # type: List[str]\n+        self.fullname = None        # type: str\n+        # extra signature items (arguments and return annotation,\n+        # also set after resolve_name succeeds)\n+        self.args = None            # type: str\n+        self.retann = None          # type: str\n+        # the object to document (set after import_object succeeds)\n+        self.object = None          # type: Any\n+        self.object_name = None     # type: str\n+        # the parent/owner of the object to document\n+        self.parent = None          # type: Any\n+        # the module analyzer to get at attribute docs, or None\n+        self.analyzer = None        # type: ModuleAnalyzer\n+\n+    @property\n+    def documenters(self) -> Dict[str, \"Type[Documenter]\"]:\n+        \"\"\"Returns registered Documenter classes\"\"\"\n+        return self.env.app.registry.documenters\n+\n+    def add_line(self, line: str, source: str, *lineno: int) -> None:\n+        \"\"\"Append one line of generated reST to the output.\"\"\"\n+        if line.strip():  # not a blank line\n+            self.directive.result.append(self.indent + line, source, *lineno)\n+        else:\n+            self.directive.result.append('', source, *lineno)\n+\n+    def resolve_name(self, modname: str, parents: Any, path: str, base: Any\n+                     ) -> Tuple[str, List[str]]:\n+        \"\"\"Resolve the module and name of the object to document given by the\n+        arguments and the current module/class.\n+\n+        Must return a pair of the module name and a chain of attributes; for\n+        example, it would return ``('zipfile', ['ZipFile', 'open'])`` for the\n+        ``zipfile.ZipFile.open`` method.\n+        \"\"\"\n+        raise NotImplementedError('must be implemented in subclasses')\n+\n+    def parse_name(self) -> bool:\n+        \"\"\"Determine what module to import and what attribute to document.\n+\n+        Returns True and sets *self.modname*, *self.objpath*, *self.fullname*,\n+        *self.args* and *self.retann* if parsing and resolving was successful.\n+        \"\"\"\n+        # first, parse the definition -- auto directives for classes and\n+        # functions can contain a signature which is then used instead of\n+        # an autogenerated one\n+        try:\n+            explicit_modname, path, base, args, retann = \\\n+                py_ext_sig_re.match(self.name).groups()\n+        except AttributeError:\n+            logger.warning(__('invalid signature for auto%s (%r)') % (self.objtype, self.name),\n+                           type='autodoc')\n+            return False\n+\n+        # support explicit module and class name separation via ::\n+        if explicit_modname is not None:\n+            modname = explicit_modname[:-2]\n+            parents = path.rstrip('.').split('.') if path else []\n+        else:\n+            modname = None\n+            parents = []\n+\n+        with mock(self.config.autodoc_mock_imports):\n+            self.modname, self.objpath = self.resolve_name(modname, parents, path, base)\n+\n+        if not self.modname:\n+            return False\n+\n+        self.args = args\n+        self.retann = retann\n+        self.fullname = (self.modname or '') + \\\n+                        ('.' + '.'.join(self.objpath) if self.objpath else '')\n+        return True\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        \"\"\"Import the object given by *self.modname* and *self.objpath* and set\n+        it as *self.object*.\n+\n+        Returns True if successful, False if an error occurred.\n+        \"\"\"\n+        with mock(self.config.autodoc_mock_imports):\n+            try:\n+                ret = import_object(self.modname, self.objpath, self.objtype,\n+                                    attrgetter=self.get_attr,\n+                                    warningiserror=self.config.autodoc_warningiserror)\n+                self.module, self.parent, self.object_name, self.object = ret\n+                return True\n+            except ImportError as exc:\n+                if raiseerror:\n+                    raise\n+                else:\n+                    logger.warning(exc.args[0], type='autodoc', subtype='import_object')\n+                    self.env.note_reread()\n+                    return False\n+\n+    def get_real_modname(self) -> str:\n+        \"\"\"Get the real module name of an object to document.\n+\n+        It can differ from the name of the module through which the object was\n+        imported.\n+        \"\"\"\n+        return self.get_attr(self.object, '__module__', None) or self.modname\n+\n+    def check_module(self) -> bool:\n+        \"\"\"Check if *self.object* is really defined in the module given by\n+        *self.modname*.\n+        \"\"\"\n+        if self.options.imported_members:\n+            return True\n+\n+        subject = inspect.unpartial(self.object)\n+        modname = self.get_attr(subject, '__module__', None)\n+        if modname and modname != self.modname:\n+            return False\n+        return True\n+\n+    def format_args(self, **kwargs: Any) -> str:\n+        \"\"\"Format the argument signature of *self.object*.\n+\n+        Should return None if the object does not have a signature.\n+        \"\"\"\n+        return None\n+\n+    def format_name(self) -> str:\n+        \"\"\"Format the name of *self.object*.\n+\n+        This normally should be something that can be parsed by the generated\n+        directive, but doesn't need to be (Sphinx will display it unparsed\n+        then).\n+        \"\"\"\n+        # normally the name doesn't contain the module (except for module\n+        # directives of course)\n+        return '.'.join(self.objpath) or self.modname\n+\n+    def _call_format_args(self, **kwargs: Any) -> str:\n+        if kwargs:\n+            try:\n+                return self.format_args(**kwargs)\n+            except TypeError:\n+                # avoid chaining exceptions, by putting nothing here\n+                pass\n+\n+        # retry without arguments for old documenters\n+        return self.format_args()\n+\n+    def format_signature(self, **kwargs: Any) -> str:\n+        \"\"\"Format the signature (arguments and return annotation) of the object.\n+\n+        Let the user process it via the ``autodoc-process-signature`` event.\n+        \"\"\"\n+        if self.args is not None:\n+            # signature given explicitly\n+            args = \"(%s)\" % self.args\n+            retann = self.retann\n+        else:\n+            # try to introspect the signature\n+            try:\n+                retann = None\n+                args = self._call_format_args(**kwargs)\n+                if args:\n+                    matched = re.match(r'^(\\(.*\\))\\s+->\\s+(.*)$', args)\n+                    if matched:\n+                        args = matched.group(1)\n+                        retann = matched.group(2)\n+            except Exception as exc:\n+                logger.warning(__('error while formatting arguments for %s: %s'),\n+                               self.fullname, exc, type='autodoc')\n+                args = None\n+\n+        result = self.env.events.emit_firstresult('autodoc-process-signature',\n+                                                  self.objtype, self.fullname,\n+                                                  self.object, self.options, args, retann)\n+        if result:\n+            args, retann = result\n+\n+        if args is not None:\n+            return args + ((' -> %s' % retann) if retann else '')\n+        else:\n+            return ''\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        \"\"\"Add the directive header and options to the generated content.\"\"\"\n+        domain = getattr(self, 'domain', 'py')\n+        directive = getattr(self, 'directivetype', self.objtype)\n+        name = self.format_name()\n+        sourcename = self.get_sourcename()\n+\n+        # one signature per line, indented by column\n+        prefix = '.. %s:%s:: ' % (domain, directive)\n+        for i, sig_line in enumerate(sig.split(\"\\n\")):\n+            self.add_line('%s%s%s' % (prefix, name, sig_line),\n+                          sourcename)\n+            if i == 0:\n+                prefix = \" \" * len(prefix)\n+\n+        if self.options.noindex:\n+            self.add_line('   :noindex:', sourcename)\n+        if self.objpath:\n+            # Be explicit about the module, this is necessary since .. class::\n+            # etc. don't support a prepended module name\n+            self.add_line('   :module: %s' % self.modname, sourcename)\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        \"\"\"Decode and return lines of the docstring(s) for the object.\"\"\"\n+        if encoding is not None:\n+            warnings.warn(\"The 'encoding' argument to autodoc.%s.get_doc() is deprecated.\"\n+                          % self.__class__.__name__,\n+                          RemovedInSphinx40Warning, stacklevel=2)\n+        if ignore is not None:\n+            warnings.warn(\"The 'ignore' argument to autodoc.%s.get_doc() is deprecated.\"\n+                          % self.__class__.__name__,\n+                          RemovedInSphinx50Warning, stacklevel=2)\n+        docstring = getdoc(self.object, self.get_attr, self.config.autodoc_inherit_docstrings,\n+                           self.parent, self.object_name)\n+        if docstring:\n+            tab_width = self.directive.state.document.settings.tab_width\n+            return [prepare_docstring(docstring, ignore, tab_width)]\n+        return []\n+\n+    def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]:\n+        \"\"\"Let the user process the docstrings before adding them.\"\"\"\n+        for docstringlines in docstrings:\n+            if self.env.app:\n+                # let extensions preprocess docstrings\n+                self.env.app.emit('autodoc-process-docstring',\n+                                  self.objtype, self.fullname, self.object,\n+                                  self.options, docstringlines)\n+\n+                if docstringlines and docstringlines[-1] != '':\n+                    # append a blank line to the end of the docstring\n+                    docstringlines.append('')\n+\n+            yield from docstringlines\n+\n+    def get_sourcename(self) -> str:\n+        if (getattr(self.object, '__module__', None) and\n+                getattr(self.object, '__qualname__', None)):\n+            # Get the correct location of docstring from self.object\n+            # to support inherited methods\n+            fullname = '%s.%s' % (self.object.__module__, self.object.__qualname__)\n+        else:\n+            fullname = self.fullname\n+\n+        if self.analyzer:\n+            return '%s:docstring of %s' % (self.analyzer.srcname, fullname)\n+        else:\n+            return 'docstring of %s' % fullname\n+\n+    def add_content(self, more_content: Optional[StringList], no_docstring: bool = False\n+                    ) -> None:\n+        \"\"\"Add content from docstrings, attribute documentation and user.\"\"\"\n+        if no_docstring:\n+            warnings.warn(\"The 'no_docstring' argument to %s.add_content() is deprecated.\"\n+                          % self.__class__.__name__,\n+                          RemovedInSphinx50Warning, stacklevel=2)\n+\n+        # set sourcename and add content from attribute documentation\n+        sourcename = self.get_sourcename()\n+        if self.analyzer:\n+            attr_docs = self.analyzer.find_attr_docs()\n+            if self.objpath:\n+                key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n+                if key in attr_docs:\n+                    no_docstring = True\n+                    # make a copy of docstring for attributes to avoid cache\n+                    # the change of autodoc-process-docstring event.\n+                    docstrings = [list(attr_docs[key])]\n+\n+                    for i, line in enumerate(self.process_doc(docstrings)):\n+                        self.add_line(line, sourcename, i)\n+\n+        # add content from docstrings\n+        if not no_docstring:\n+            docstrings = self.get_doc()\n+            if not docstrings:\n+                # append at least a dummy docstring, so that the event\n+                # autodoc-process-docstring is fired and can add some\n+                # content if desired\n+                docstrings.append([])\n+            for i, line in enumerate(self.process_doc(docstrings)):\n+                self.add_line(line, sourcename, i)\n+\n+        # add additional content (e.g. from document), if present\n+        if more_content:\n+            for line, src in zip(more_content.data, more_content.items):\n+                self.add_line(line, src[0], src[1])\n+\n+    def get_object_members(self, want_all: bool) -> Tuple[bool, ObjectMembers]:\n+        \"\"\"Return `(members_check_module, members)` where `members` is a\n+        list of `(membername, member)` pairs of the members of *self.object*.\n+\n+        If *want_all* is True, return all members.  Else, only return those\n+        members given by *self.options.members* (which may also be none).\n+        \"\"\"\n+        warnings.warn('The implementation of Documenter.get_object_members() will be '\n+                      'removed from Sphinx-6.0.', RemovedInSphinx60Warning)\n+        members = get_object_members(self.object, self.objpath, self.get_attr, self.analyzer)\n+        if not want_all:\n+            if not self.options.members:\n+                return False, []  # type: ignore\n+            # specific members given\n+            selected = []\n+            for name in self.options.members:  # type: str\n+                if name in members:\n+                    selected.append((name, members[name].value))\n+                else:\n+                    logger.warning(__('missing attribute %s in object %s') %\n+                                   (name, self.fullname), type='autodoc')\n+            return False, selected\n+        elif self.options.inherited_members:\n+            return False, [(m.name, m.value) for m in members.values()]\n+        else:\n+            return False, [(m.name, m.value) for m in members.values()\n+                           if m.directly_defined]\n+\n+    def filter_members(self, members: ObjectMembers, want_all: bool\n+                       ) -> List[Tuple[str, Any, bool]]:\n+        \"\"\"Filter the given member list.\n+\n+        Members are skipped if\n+\n+        - they are private (except if given explicitly or the private-members\n+          option is set)\n+        - they are special methods (except if given explicitly or the\n+          special-members option is set)\n+        - they are undocumented (except if the undoc-members option is set)\n+\n+        The user can override the skipping decision by connecting to the\n+        ``autodoc-skip-member`` event.\n+        \"\"\"\n+        def is_filtered_inherited_member(name: str) -> bool:\n+            if inspect.isclass(self.object):\n+                for cls in self.object.__mro__:\n+                    if cls.__name__ == self.options.inherited_members and cls != self.object:\n+                        # given member is a member of specified *super class*\n+                        return True\n+                    elif name in cls.__dict__:\n+                        return False\n+                    elif name in self.get_attr(cls, '__annotations__', {}):\n+                        return False\n+\n+            return False\n+\n+        ret = []\n+\n+        # search for members in source code too\n+        namespace = '.'.join(self.objpath)  # will be empty for modules\n+\n+        if self.analyzer:\n+            attr_docs = self.analyzer.find_attr_docs()\n+        else:\n+            attr_docs = {}\n+\n+        # process members and determine which to skip\n+        for obj in members:\n+            membername, member = obj\n+            # if isattr is True, the member is documented as an attribute\n+            if member is INSTANCEATTR:\n+                isattr = True\n+            else:\n+                isattr = False\n+\n+            doc = getdoc(member, self.get_attr, self.config.autodoc_inherit_docstrings,\n+                         self.parent, self.object_name)\n+            if not isinstance(doc, str):\n+                # Ignore non-string __doc__\n+                doc = None\n+\n+            # if the member __doc__ is the same as self's __doc__, it's just\n+            # inherited and therefore not the member's doc\n+            cls = self.get_attr(member, '__class__', None)\n+            if cls:\n+                cls_doc = self.get_attr(cls, '__doc__', None)\n+                if cls_doc == doc:\n+                    doc = None\n+\n+            if isinstance(obj, ObjectMember) and obj.docstring:\n+                # hack for ClassDocumenter to inject docstring via ObjectMember\n+                doc = obj.docstring\n+\n+            has_doc = bool(doc)\n+\n+            metadata = extract_metadata(doc)\n+            if 'private' in metadata:\n+                # consider a member private if docstring has \"private\" metadata\n+                isprivate = True\n+            elif 'public' in metadata:\n+                # consider a member public if docstring has \"public\" metadata\n+                isprivate = False\n+            else:\n+                isprivate = membername.startswith('_')\n+\n+            keep = False\n+            if safe_getattr(member, '__sphinx_mock__', None) is not None:\n+                # mocked module or object\n+                pass\n+            elif self.options.exclude_members and membername in self.options.exclude_members:\n+                # remove members given by exclude-members\n+                keep = False\n+            elif want_all and special_member_re.match(membername):\n+                # special __methods__\n+                if self.options.special_members and membername in self.options.special_members:\n+                    if membername == '__doc__':\n+                        keep = False\n+                    elif is_filtered_inherited_member(membername):\n+                        keep = False\n+                    else:\n+                        keep = has_doc or self.options.undoc_members\n+                else:\n+                    keep = False\n+            elif (namespace, membername) in attr_docs:\n+                if want_all and isprivate:\n+                    if self.options.private_members is None:\n+                        keep = False\n+                    else:\n+                        keep = membername in self.options.private_members\n+                else:\n+                    # keep documented attributes\n+                    keep = True\n+                isattr = True\n+            elif want_all and isprivate:\n+                if has_doc or self.options.undoc_members:\n+                    if self.options.private_members is None:\n+                        keep = False\n+                    elif is_filtered_inherited_member(membername):\n+                        keep = False\n+                    else:\n+                        keep = membername in self.options.private_members\n+                else:\n+                    keep = False\n+            else:\n+                if self.options.members is ALL and is_filtered_inherited_member(membername):\n+                    keep = False\n+                else:\n+                    # ignore undocumented members if :undoc-members: is not given\n+                    keep = has_doc or self.options.undoc_members\n+\n+            if isinstance(obj, ObjectMember) and obj.skipped:\n+                # forcedly skipped member (ex. a module attribute not defined in __all__)\n+                keep = False\n+\n+            # give the user a chance to decide whether this member\n+            # should be skipped\n+            if self.env.app:\n+                # let extensions preprocess docstrings\n+                try:\n+                    skip_user = self.env.app.emit_firstresult(\n+                        'autodoc-skip-member', self.objtype, membername, member,\n+                        not keep, self.options)\n+                    if skip_user is not None:\n+                        keep = not skip_user\n+                except Exception as exc:\n+                    logger.warning(__('autodoc: failed to determine %r to be documented, '\n+                                      'the following exception was raised:\\n%s'),\n+                                   member, exc, type='autodoc')\n+                    keep = False\n+\n+            if keep:\n+                ret.append((membername, member, isattr))\n+\n+        return ret\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        \"\"\"Generate reST for member documentation.\n+\n+        If *all_members* is True, do all members, else those given by\n+        *self.options.members*.\n+        \"\"\"\n+        # set current namespace for finding members\n+        self.env.temp_data['autodoc:module'] = self.modname\n+        if self.objpath:\n+            self.env.temp_data['autodoc:class'] = self.objpath[0]\n+\n+        want_all = all_members or self.options.inherited_members or \\\n+            self.options.members is ALL\n+        # find out which members are documentable\n+        members_check_module, members = self.get_object_members(want_all)\n+\n+        # document non-skipped members\n+        memberdocumenters = []  # type: List[Tuple[Documenter, bool]]\n+        for (mname, member, isattr) in self.filter_members(members, want_all):\n+            classes = [cls for cls in self.documenters.values()\n+                       if cls.can_document_member(member, mname, isattr, self)]\n+            if not classes:\n+                # don't know how to document this member\n+                continue\n+            # prefer the documenter with the highest priority\n+            classes.sort(key=lambda cls: cls.priority)\n+            # give explicitly separated module name, so that members\n+            # of inner classes can be documented\n+            full_mname = self.modname + '::' + \\\n+                '.'.join(self.objpath + [mname])\n+            documenter = classes[-1](self.directive, full_mname, self.indent)\n+            memberdocumenters.append((documenter, isattr))\n+\n+        member_order = self.options.member_order or self.config.autodoc_member_order\n+        memberdocumenters = self.sort_members(memberdocumenters, member_order)\n+\n+        for documenter, isattr in memberdocumenters:\n+            documenter.generate(\n+                all_members=True, real_modname=self.real_modname,\n+                check_module=members_check_module and not isattr)\n+\n+        # reset current objects\n+        self.env.temp_data['autodoc:module'] = None\n+        self.env.temp_data['autodoc:class'] = None\n+\n+    def sort_members(self, documenters: List[Tuple[\"Documenter\", bool]],\n+                     order: str) -> List[Tuple[\"Documenter\", bool]]:\n+        \"\"\"Sort the given member list.\"\"\"\n+        if order == 'groupwise':\n+            # sort by group; alphabetically within groups\n+            documenters.sort(key=lambda e: (e[0].member_order, e[0].name))\n+        elif order == 'bysource':\n+            if self.analyzer:\n+                # sort by source order, by virtue of the module analyzer\n+                tagorder = self.analyzer.tagorder\n+\n+                def keyfunc(entry: Tuple[Documenter, bool]) -> int:\n+                    fullname = entry[0].name.split('::')[1]\n+                    return tagorder.get(fullname, len(tagorder))\n+                documenters.sort(key=keyfunc)\n+            else:\n+                # Assume that member discovery order matches source order.\n+                # This is a reasonable assumption in Python 3.6 and up, where\n+                # module.__dict__ is insertion-ordered.\n+                pass\n+        else:  # alphabetical\n+            documenters.sort(key=lambda e: e[0].name)\n+\n+        return documenters\n+\n+    def generate(self, more_content: Optional[StringList] = None, real_modname: str = None,\n+                 check_module: bool = False, all_members: bool = False) -> None:\n+        \"\"\"Generate reST for the object given by *self.name*, and possibly for\n+        its members.\n+\n+        If *more_content* is given, include that content. If *real_modname* is\n+        given, use that module name to find attribute docs. If *check_module* is\n+        True, only generate if the object is defined in the module name it is\n+        imported from. If *all_members* is True, document all members.\n+        \"\"\"\n+        if not self.parse_name():\n+            # need a module to import\n+            logger.warning(\n+                __('don\\'t know which module to import for autodocumenting '\n+                   '%r (try placing a \"module\" or \"currentmodule\" directive '\n+                   'in the document, or giving an explicit module name)') %\n+                self.name, type='autodoc')\n+            return\n+\n+        # now, import the module and get object to document\n+        if not self.import_object():\n+            return\n+\n+        # If there is no real module defined, figure out which to use.\n+        # The real module is used in the module analyzer to look up the module\n+        # where the attribute documentation would actually be found in.\n+        # This is used for situations where you have a module that collects the\n+        # functions and classes of internal submodules.\n+        guess_modname = self.get_real_modname()\n+        self.real_modname = real_modname or guess_modname\n+\n+        # try to also get a source code analyzer for attribute docs\n+        try:\n+            self.analyzer = ModuleAnalyzer.for_module(self.real_modname)\n+            # parse right now, to get PycodeErrors on parsing (results will\n+            # be cached anyway)\n+            self.analyzer.find_attr_docs()\n+        except PycodeError as exc:\n+            logger.debug('[autodoc] module analyzer failed: %s', exc)\n+            # no source file -- e.g. for builtin and C modules\n+            self.analyzer = None\n+            # at least add the module.__file__ as a dependency\n+            if hasattr(self.module, '__file__') and self.module.__file__:\n+                self.directive.filename_set.add(self.module.__file__)\n+        else:\n+            self.directive.filename_set.add(self.analyzer.srcname)\n+\n+        if self.real_modname != guess_modname:\n+            # Add module to dependency list if target object is defined in other module.\n+            try:\n+                analyzer = ModuleAnalyzer.for_module(guess_modname)\n+                self.directive.filename_set.add(analyzer.srcname)\n+            except PycodeError:\n+                pass\n+\n+        # check __module__ of object (for members not given explicitly)\n+        if check_module:\n+            if not self.check_module():\n+                return\n+\n+        sourcename = self.get_sourcename()\n+\n+        # make sure that the result starts with an empty line.  This is\n+        # necessary for some situations where another directive preprocesses\n+        # reST and no starting newline is present\n+        self.add_line('', sourcename)\n+\n+        # format the object's signature, if any\n+        try:\n+            sig = self.format_signature()\n+        except Exception as exc:\n+            logger.warning(__('error while formatting signature for %s: %s'),\n+                           self.fullname, exc, type='autodoc')\n+            return\n+\n+        # generate the directive header and options, if applicable\n+        self.add_directive_header(sig)\n+        self.add_line('', sourcename)\n+\n+        # e.g. the module directive doesn't have content\n+        self.indent += self.content_indent\n+\n+        # add all content (from docstrings, attribute docs etc.)\n+        self.add_content(more_content)\n+\n+        # document members, if possible\n+        self.document_members(all_members)\n+\n+\n+class ModuleDocumenter(Documenter):\n+    \"\"\"\n+    Specialized Documenter subclass for modules.\n+    \"\"\"\n+    objtype = 'module'\n+    content_indent = ''\n+    titles_allowed = True\n+\n+    option_spec = {\n+        'members': members_option, 'undoc-members': bool_option,\n+        'noindex': bool_option, 'inherited-members': inherited_members_option,\n+        'show-inheritance': bool_option, 'synopsis': identity,\n+        'platform': identity, 'deprecated': bool_option,\n+        'member-order': member_order_option, 'exclude-members': exclude_members_option,\n+        'private-members': members_option, 'special-members': members_option,\n+        'imported-members': bool_option, 'ignore-module-all': bool_option\n+    }  # type: Dict[str, Callable]\n+\n+    def __init__(self, *args: Any) -> None:\n+        super().__init__(*args)\n+        merge_members_option(self.options)\n+        self.__all__ = None  # type: Optional[Sequence[str]]\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        # don't document submodules automatically\n+        return False\n+\n+    def resolve_name(self, modname: str, parents: Any, path: str, base: Any\n+                     ) -> Tuple[str, List[str]]:\n+        if modname is not None:\n+            logger.warning(__('\"::\" in automodule name doesn\\'t make sense'),\n+                           type='autodoc')\n+        return (path or '') + base, []\n+\n+    def parse_name(self) -> bool:\n+        ret = super().parse_name()\n+        if self.args or self.retann:\n+            logger.warning(__('signature arguments or return annotation '\n+                              'given for automodule %s') % self.fullname,\n+                           type='autodoc')\n+        return ret\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        ret = super().import_object(raiseerror)\n+\n+        try:\n+            if not self.options.ignore_module_all:\n+                self.__all__ = inspect.getall(self.object)\n+        except AttributeError as exc:\n+            # __all__ raises an error.\n+            logger.warning(__('%s.__all__ raises an error. Ignored: %r'),\n+                           (self.fullname, exc), type='autodoc')\n+        except ValueError as exc:\n+            # invalid __all__ found.\n+            logger.warning(__('__all__ should be a list of strings, not %r '\n+                              '(in module %s) -- ignoring __all__') %\n+                           (exc.args[0], self.fullname), type='autodoc')\n+\n+        return ret\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        Documenter.add_directive_header(self, sig)\n+\n+        sourcename = self.get_sourcename()\n+\n+        # add some module-specific options\n+        if self.options.synopsis:\n+            self.add_line('   :synopsis: ' + self.options.synopsis, sourcename)\n+        if self.options.platform:\n+            self.add_line('   :platform: ' + self.options.platform, sourcename)\n+        if self.options.deprecated:\n+            self.add_line('   :deprecated:', sourcename)\n+\n+    def get_object_members(self, want_all: bool) -> Tuple[bool, ObjectMembers]:\n+        if want_all:\n+            members = get_module_members(self.object)\n+            if not self.__all__:\n+                # for implicit module members, check __module__ to avoid\n+                # documenting imported objects\n+                return True, members\n+            else:\n+                ret = []\n+                for name, value in members:\n+                    if name in self.__all__:\n+                        ret.append(ObjectMember(name, value))\n+                    else:\n+                        ret.append(ObjectMember(name, value, skipped=True))\n+\n+                return False, ret\n+        else:\n+            memberlist = self.options.members or []\n+            ret = []\n+            for name in memberlist:\n+                try:\n+                    value = safe_getattr(self.object, name)\n+                    ret.append(ObjectMember(name, value))\n+                except AttributeError:\n+                    logger.warning(__('missing attribute mentioned in :members: option: '\n+                                      'module %s, attribute %s') %\n+                                   (safe_getattr(self.object, '__name__', '???'), name),\n+                                   type='autodoc')\n+            return False, ret\n+\n+    def sort_members(self, documenters: List[Tuple[\"Documenter\", bool]],\n+                     order: str) -> List[Tuple[\"Documenter\", bool]]:\n+        if order == 'bysource' and self.__all__:\n+            # Sort alphabetically first (for members not listed on the __all__)\n+            documenters.sort(key=lambda e: e[0].name)\n+\n+            # Sort by __all__\n+            def keyfunc(entry: Tuple[Documenter, bool]) -> int:\n+                name = entry[0].name.split('::')[1]\n+                if name in self.__all__:\n+                    return self.__all__.index(name)\n+                else:\n+                    return len(self.__all__)\n+            documenters.sort(key=keyfunc)\n+\n+            return documenters\n+        else:\n+            return super().sort_members(documenters, order)\n+\n+\n+class ModuleLevelDocumenter(Documenter):\n+    \"\"\"\n+    Specialized Documenter subclass for objects on module level (functions,\n+    classes, data/constants).\n+    \"\"\"\n+    def resolve_name(self, modname: str, parents: Any, path: str, base: Any\n+                     ) -> Tuple[str, List[str]]:\n+        if modname is None:\n+            if path:\n+                modname = path.rstrip('.')\n+            else:\n+                # if documenting a toplevel object without explicit module,\n+                # it can be contained in another auto directive ...\n+                modname = self.env.temp_data.get('autodoc:module')\n+                # ... or in the scope of a module directive\n+                if not modname:\n+                    modname = self.env.ref_context.get('py:module')\n+                # ... else, it stays None, which means invalid\n+        return modname, parents + [base]\n+\n+\n+class ClassLevelDocumenter(Documenter):\n+    \"\"\"\n+    Specialized Documenter subclass for objects on class level (methods,\n+    attributes).\n+    \"\"\"\n+    def resolve_name(self, modname: str, parents: Any, path: str, base: Any\n+                     ) -> Tuple[str, List[str]]:\n+        if modname is None:\n+            if path:\n+                mod_cls = path.rstrip('.')\n+            else:\n+                mod_cls = None\n+                # if documenting a class-level object without path,\n+                # there must be a current class, either from a parent\n+                # auto directive ...\n+                mod_cls = self.env.temp_data.get('autodoc:class')\n+                # ... or from a class directive\n+                if mod_cls is None:\n+                    mod_cls = self.env.ref_context.get('py:class')\n+                # ... if still None, there's no way to know\n+                if mod_cls is None:\n+                    return None, []\n+            modname, sep, cls = mod_cls.rpartition('.')\n+            parents = [cls]\n+            # if the module name is still missing, get it like above\n+            if not modname:\n+                modname = self.env.temp_data.get('autodoc:module')\n+            if not modname:\n+                modname = self.env.ref_context.get('py:module')\n+            # ... else, it stays None, which means invalid\n+        return modname, parents + [base]\n+\n+\n+class DocstringSignatureMixin:\n+    \"\"\"\n+    Mixin for FunctionDocumenter and MethodDocumenter to provide the\n+    feature of reading the signature from the docstring.\n+    \"\"\"\n+    _new_docstrings = None  # type: List[List[str]]\n+    _signatures = None      # type: List[str]\n+\n+    def _find_signature(self, encoding: str = None) -> Tuple[str, str]:\n+        if encoding is not None:\n+            warnings.warn(\"The 'encoding' argument to autodoc.%s._find_signature() is \"\n+                          \"deprecated.\" % self.__class__.__name__,\n+                          RemovedInSphinx40Warning, stacklevel=2)\n+\n+        # candidates of the object name\n+        valid_names = [self.objpath[-1]]  # type: ignore\n+        if isinstance(self, ClassDocumenter):\n+            valid_names.append('__init__')\n+            if hasattr(self.object, '__mro__'):\n+                valid_names.extend(cls.__name__ for cls in self.object.__mro__)\n+\n+        docstrings = self.get_doc()\n+        self._new_docstrings = docstrings[:]\n+        self._signatures = []\n+        result = None\n+        for i, doclines in enumerate(docstrings):\n+            for j, line in enumerate(doclines):\n+                if not line:\n+                    # no lines in docstring, no match\n+                    break\n+\n+                if line.endswith('\\\\'):\n+                    multiline = True\n+                    line = line.rstrip('\\\\').rstrip()\n+                else:\n+                    multiline = False\n+\n+                # match first line of docstring against signature RE\n+                match = py_ext_sig_re.match(line)\n+                if not match:\n+                    continue\n+                exmod, path, base, args, retann = match.groups()\n+\n+                # the base name must match ours\n+                if base not in valid_names:\n+                    continue\n+\n+                # re-prepare docstring to ignore more leading indentation\n+                tab_width = self.directive.state.document.settings.tab_width  # type: ignore\n+                self._new_docstrings[i] = prepare_docstring('\\n'.join(doclines[j + 1:]),\n+                                                            tabsize=tab_width)\n+\n+                if result is None:\n+                    # first signature\n+                    result = args, retann\n+                else:\n+                    # subsequent signatures\n+                    self._signatures.append(\"(%s) -> %s\" % (args, retann))\n+\n+                if multiline:\n+                    # the signature have multiple signatures on docstring\n+                    continue\n+                else:\n+                    # don't look any further\n+                    break\n+\n+            if result:\n+                # finish the loop when signature found\n+                break\n+\n+        return result\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if encoding is not None:\n+            warnings.warn(\"The 'encoding' argument to autodoc.%s.get_doc() is deprecated.\"\n+                          % self.__class__.__name__,\n+                          RemovedInSphinx40Warning, stacklevel=2)\n+        if self._new_docstrings is not None:\n+            return self._new_docstrings\n+        return super().get_doc(None, ignore)  # type: ignore\n+\n+    def format_signature(self, **kwargs: Any) -> str:\n+        if self.args is None and self.config.autodoc_docstring_signature:  # type: ignore\n+            # only act if a signature is not explicitly given already, and if\n+            # the feature is enabled\n+            result = self._find_signature()\n+            if result is not None:\n+                self.args, self.retann = result\n+        sig = super().format_signature(**kwargs)  # type: ignore\n+        if self._signatures:\n+            return \"\\n\".join([sig] + self._signatures)\n+        else:\n+            return sig\n+\n+\n+class DocstringStripSignatureMixin(DocstringSignatureMixin):\n+    \"\"\"\n+    Mixin for AttributeDocumenter to provide the\n+    feature of stripping any function signature from the docstring.\n+    \"\"\"\n+    def format_signature(self, **kwargs: Any) -> str:\n+        if self.args is None and self.config.autodoc_docstring_signature:  # type: ignore\n+            # only act if a signature is not explicitly given already, and if\n+            # the feature is enabled\n+            result = self._find_signature()\n+            if result is not None:\n+                # Discarding _args is a only difference with\n+                # DocstringSignatureMixin.format_signature.\n+                # Documenter.format_signature use self.args value to format.\n+                _args, self.retann = result\n+        return super().format_signature(**kwargs)\n+\n+\n+class FunctionDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type: ignore\n+    \"\"\"\n+    Specialized Documenter subclass for functions.\n+    \"\"\"\n+    objtype = 'function'\n+    member_order = 30\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        # supports functions, builtins and bound methods exported at the module level\n+        return (inspect.isfunction(member) or inspect.isbuiltin(member) or\n+                (inspect.isroutine(member) and isinstance(parent, ModuleDocumenter)))\n+\n+    def format_args(self, **kwargs: Any) -> str:\n+        if self.config.autodoc_typehints in ('none', 'description'):\n+            kwargs.setdefault('show_annotation', False)\n+\n+        try:\n+            self.env.app.emit('autodoc-before-process-signature', self.object, False)\n+            sig = inspect.signature(self.object, type_aliases=self.config.autodoc_type_aliases)\n+            args = stringify_signature(sig, **kwargs)\n+        except TypeError as exc:\n+            logger.warning(__(\"Failed to get a function signature for %s: %s\"),\n+                           self.fullname, exc)\n+            return None\n+        except ValueError:\n+            args = ''\n+\n+        if self.config.strip_signature_backslash:\n+            # escape backslashes for reST\n+            args = args.replace('\\\\', '\\\\\\\\')\n+        return args\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        pass\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        sourcename = self.get_sourcename()\n+        super().add_directive_header(sig)\n+\n+        if inspect.iscoroutinefunction(self.object):\n+            self.add_line('   :async:', sourcename)\n+\n+    def format_signature(self, **kwargs: Any) -> str:\n+        sigs = []\n+        if (self.analyzer and\n+                '.'.join(self.objpath) in self.analyzer.overloads and\n+                self.config.autodoc_typehints == 'signature'):\n+            # Use signatures for overloaded functions instead of the implementation function.\n+            overloaded = True\n+        else:\n+            overloaded = False\n+            sig = super().format_signature(**kwargs)\n+            sigs.append(sig)\n+\n+        if inspect.is_singledispatch_function(self.object):\n+            # append signature of singledispatch'ed functions\n+            for typ, func in self.object.registry.items():\n+                if typ is object:\n+                    pass  # default implementation. skipped.\n+                else:\n+                    self.annotate_to_first_argument(func, typ)\n+\n+                    documenter = FunctionDocumenter(self.directive, '')\n+                    documenter.object = func\n+                    documenter.objpath = [None]\n+                    sigs.append(documenter.format_signature())\n+        if overloaded:\n+            __globals__ = safe_getattr(self.object, '__globals__', {})\n+            for overload in self.analyzer.overloads.get('.'.join(self.objpath)):\n+                overload = evaluate_signature(overload, __globals__,\n+                                              self.config.autodoc_type_aliases)\n+\n+                sig = stringify_signature(overload, **kwargs)\n+                sigs.append(sig)\n+\n+        return \"\\n\".join(sigs)\n+\n+    def annotate_to_first_argument(self, func: Callable, typ: Type) -> None:\n+        \"\"\"Annotate type hint to the first argument of function if needed.\"\"\"\n+        try:\n+            sig = inspect.signature(func, type_aliases=self.config.autodoc_type_aliases)\n+        except TypeError as exc:\n+            logger.warning(__(\"Failed to get a function signature for %s: %s\"),\n+                           self.fullname, exc)\n+            return\n+        except ValueError:\n+            return\n+\n+        if len(sig.parameters) == 0:\n+            return\n+\n+        params = list(sig.parameters.values())\n+        if params[0].annotation is Parameter.empty:\n+            params[0] = params[0].replace(annotation=typ)\n+            try:\n+                func.__signature__ = sig.replace(parameters=params)  # type: ignore\n+            except TypeError:\n+                # failed to update signature (ex. built-in or extension types)\n+                return\n+\n+\n+class DecoratorDocumenter(FunctionDocumenter):\n+    \"\"\"\n+    Specialized Documenter subclass for decorator functions.\n+    \"\"\"\n+    objtype = 'decorator'\n+\n+    # must be lower than FunctionDocumenter\n+    priority = -1\n+\n+    def format_args(self, **kwargs: Any) -> Any:\n+        args = super().format_args(**kwargs)\n+        if ',' in args:\n+            return args\n+        else:\n+            return None\n+\n+\n+# Types which have confusing metaclass signatures it would be best not to show.\n+# These are listed by name, rather than storing the objects themselves, to avoid\n+# needing to import the modules.\n+_METACLASS_CALL_BLACKLIST = [\n+    'enum.EnumMeta.__call__',\n+]\n+\n+\n+# Types whose __new__ signature is a pass-thru.\n+_CLASS_NEW_BLACKLIST = [\n+    'typing.Generic.__new__',\n+]\n+\n+\n+class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type: ignore\n+    \"\"\"\n+    Specialized Documenter subclass for classes.\n+    \"\"\"\n+    objtype = 'class'\n+    member_order = 20\n+    option_spec = {\n+        'members': members_option, 'undoc-members': bool_option,\n+        'noindex': bool_option, 'inherited-members': inherited_members_option,\n+        'show-inheritance': bool_option, 'member-order': member_order_option,\n+        'exclude-members': exclude_members_option,\n+        'private-members': members_option, 'special-members': members_option,\n+    }  # type: Dict[str, Callable]\n+\n+    _signature_class = None  # type: Any\n+    _signature_method_name = None  # type: str\n+\n+    def __init__(self, *args: Any) -> None:\n+        super().__init__(*args)\n+        merge_members_option(self.options)\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return isinstance(member, type)\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        ret = super().import_object(raiseerror)\n+        # if the class is documented under another name, document it\n+        # as data/attribute\n+        if ret:\n+            if hasattr(self.object, '__name__'):\n+                self.doc_as_attr = (self.objpath[-1] != self.object.__name__)\n+            else:\n+                self.doc_as_attr = True\n+        return ret\n+\n+    def _get_signature(self) -> Tuple[Optional[Any], Optional[str], Optional[Signature]]:\n+        def get_user_defined_function_or_method(obj: Any, attr: str) -> Any:\n+            \"\"\" Get the `attr` function or method from `obj`, if it is user-defined. \"\"\"\n+            if inspect.is_builtin_class_method(obj, attr):\n+                return None\n+            attr = self.get_attr(obj, attr, None)\n+            if not (inspect.ismethod(attr) or inspect.isfunction(attr)):\n+                return None\n+            return attr\n+\n+        # This sequence is copied from inspect._signature_from_callable.\n+        # ValueError means that no signature could be found, so we keep going.\n+\n+        # First, we check the obj has a __signature__ attribute\n+        if (hasattr(self.object, '__signature__') and\n+                isinstance(self.object.__signature__, Signature)):\n+            return None, None, self.object.__signature__\n+\n+        # Next, let's see if it has an overloaded __call__ defined\n+        # in its metaclass\n+        call = get_user_defined_function_or_method(type(self.object), '__call__')\n+\n+        if call is not None:\n+            if \"{0.__module__}.{0.__qualname__}\".format(call) in _METACLASS_CALL_BLACKLIST:\n+                call = None\n+\n+        if call is not None:\n+            self.env.app.emit('autodoc-before-process-signature', call, True)\n+            try:\n+                sig = inspect.signature(call, bound_method=True,\n+                                        type_aliases=self.config.autodoc_type_aliases)\n+                return type(self.object), '__call__', sig\n+            except ValueError:\n+                pass\n+\n+        # Now we check if the 'obj' class has a '__new__' method\n+        new = get_user_defined_function_or_method(self.object, '__new__')\n+\n+        if new is not None:\n+            if \"{0.__module__}.{0.__qualname__}\".format(new) in _CLASS_NEW_BLACKLIST:\n+                new = None\n+\n+        if new is not None:\n+            self.env.app.emit('autodoc-before-process-signature', new, True)\n+            try:\n+                sig = inspect.signature(new, bound_method=True,\n+                                        type_aliases=self.config.autodoc_type_aliases)\n+                return self.object, '__new__', sig\n+            except ValueError:\n+                pass\n+\n+        # Finally, we should have at least __init__ implemented\n+        init = get_user_defined_function_or_method(self.object, '__init__')\n+        if init is not None:\n+            self.env.app.emit('autodoc-before-process-signature', init, True)\n+            try:\n+                sig = inspect.signature(init, bound_method=True,\n+                                        type_aliases=self.config.autodoc_type_aliases)\n+                return self.object, '__init__', sig\n+            except ValueError:\n+                pass\n+\n+        # None of the attributes are user-defined, so fall back to let inspect\n+        # handle it.\n+        # We don't know the exact method that inspect.signature will read\n+        # the signature from, so just pass the object itself to our hook.\n+        self.env.app.emit('autodoc-before-process-signature', self.object, False)\n+        try:\n+            sig = inspect.signature(self.object, bound_method=False,\n+                                    type_aliases=self.config.autodoc_type_aliases)\n+            return None, None, sig\n+        except ValueError:\n+            pass\n+\n+        # Still no signature: happens e.g. for old-style classes\n+        # with __init__ in C and no `__text_signature__`.\n+        return None, None, None\n+\n+    def format_args(self, **kwargs: Any) -> str:\n+        if self.config.autodoc_typehints in ('none', 'description'):\n+            kwargs.setdefault('show_annotation', False)\n+\n+        try:\n+            self._signature_class, self._signature_method_name, sig = self._get_signature()\n+        except TypeError as exc:\n+            # __signature__ attribute contained junk\n+            logger.warning(__(\"Failed to get a constructor signature for %s: %s\"),\n+                           self.fullname, exc)\n+            return None\n+\n+        if sig is None:\n+            return None\n+\n+        return stringify_signature(sig, show_return_annotation=False, **kwargs)\n+\n+    def format_signature(self, **kwargs: Any) -> str:\n+        if self.doc_as_attr:\n+            return ''\n+\n+        sig = super().format_signature()\n+        sigs = []\n+\n+        overloads = self.get_overloaded_signatures()\n+        if overloads and self.config.autodoc_typehints == 'signature':\n+            # Use signatures for overloaded methods instead of the implementation method.\n+            method = safe_getattr(self._signature_class, self._signature_method_name, None)\n+            __globals__ = safe_getattr(method, '__globals__', {})\n+            for overload in overloads:\n+                overload = evaluate_signature(overload, __globals__,\n+                                              self.config.autodoc_type_aliases)\n+\n+                parameters = list(overload.parameters.values())\n+                overload = overload.replace(parameters=parameters[1:],\n+                                            return_annotation=Parameter.empty)\n+                sig = stringify_signature(overload, **kwargs)\n+                sigs.append(sig)\n+        else:\n+            sigs.append(sig)\n+\n+        return \"\\n\".join(sigs)\n+\n+    def get_overloaded_signatures(self) -> List[Signature]:\n+        if self._signature_class and self._signature_method_name:\n+            for cls in self._signature_class.__mro__:\n+                try:\n+                    analyzer = ModuleAnalyzer.for_module(cls.__module__)\n+                    analyzer.analyze()\n+                    qualname = '.'.join([cls.__qualname__, self._signature_method_name])\n+                    if qualname in analyzer.overloads:\n+                        return analyzer.overloads.get(qualname)\n+                    elif qualname in analyzer.tagorder:\n+                        # the constructor is defined in the class, but not overrided.\n+                        return []\n+                except PycodeError:\n+                    pass\n+\n+        return []\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        sourcename = self.get_sourcename()\n+\n+        if self.doc_as_attr:\n+            self.directivetype = 'attribute'\n+        super().add_directive_header(sig)\n+\n+        if self.analyzer and '.'.join(self.objpath) in self.analyzer.finals:\n+            self.add_line('   :final:', sourcename)\n+\n+        # add inheritance info, if wanted\n+        if not self.doc_as_attr and self.options.show_inheritance:\n+            sourcename = self.get_sourcename()\n+            self.add_line('', sourcename)\n+\n+            if hasattr(self.object, '__orig_bases__') and len(self.object.__orig_bases__):\n+                # A subclass of generic types\n+                # refs: PEP-560 <https://www.python.org/dev/peps/pep-0560/>\n+                bases = [restify(cls) for cls in self.object.__orig_bases__]\n+                self.add_line('   ' + _('Bases: %s') % ', '.join(bases), sourcename)\n+            elif hasattr(self.object, '__bases__') and len(self.object.__bases__):\n+                # A normal class\n+                bases = [restify(cls) for cls in self.object.__bases__]\n+                self.add_line('   ' + _('Bases: %s') % ', '.join(bases), sourcename)\n+\n+    def get_object_members(self, want_all: bool) -> Tuple[bool, ObjectMembers]:\n+        members = get_class_members(self.object, self.objpath, self.get_attr, self.analyzer)\n+        if not want_all:\n+            if not self.options.members:\n+                return False, []  # type: ignore\n+            # specific members given\n+            selected = []\n+            for name in self.options.members:  # type: str\n+                if name in members:\n+                    selected.append(ObjectMember(name, members[name].value,\n+                                                 docstring=members[name].docstring))\n+                else:\n+                    logger.warning(__('missing attribute %s in object %s') %\n+                                   (name, self.fullname), type='autodoc')\n+            return False, selected\n+        elif self.options.inherited_members:\n+            return False, [ObjectMember(m.name, m.value, docstring=m.docstring)\n+                           for m in members.values()]\n+        else:\n+            return False, [ObjectMember(m.name, m.value, docstring=m.docstring)\n+                           for m in members.values() if m.class_ == self.object]\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if encoding is not None:\n+            warnings.warn(\"The 'encoding' argument to autodoc.%s.get_doc() is deprecated.\"\n+                          % self.__class__.__name__,\n+                          RemovedInSphinx40Warning, stacklevel=2)\n+        if self.doc_as_attr:\n+            # Don't show the docstring of the class when it is an alias.\n+            return []\n+\n+        lines = getattr(self, '_new_docstrings', None)\n+        if lines is not None:\n+            return lines\n+\n+        content = self.config.autoclass_content\n+\n+        docstrings = []\n+        attrdocstring = self.get_attr(self.object, '__doc__', None)\n+        if attrdocstring:\n+            docstrings.append(attrdocstring)\n+\n+        # for classes, what the \"docstring\" is can be controlled via a\n+        # config value; the default is only the class docstring\n+        if content in ('both', 'init'):\n+            __init__ = self.get_attr(self.object, '__init__', None)\n+            initdocstring = getdoc(__init__, self.get_attr,\n+                                   self.config.autodoc_inherit_docstrings,\n+                                   self.parent, self.object_name)\n+            # for new-style classes, no __init__ means default __init__\n+            if (initdocstring is not None and\n+                (initdocstring == object.__init__.__doc__ or  # for pypy\n+                 initdocstring.strip() == object.__init__.__doc__)):  # for !pypy\n+                initdocstring = None\n+            if not initdocstring:\n+                # try __new__\n+                __new__ = self.get_attr(self.object, '__new__', None)\n+                initdocstring = getdoc(__new__, self.get_attr,\n+                                       self.config.autodoc_inherit_docstrings,\n+                                       self.parent, self.object_name)\n+                # for new-style classes, no __new__ means default __new__\n+                if (initdocstring is not None and\n+                    (initdocstring == object.__new__.__doc__ or  # for pypy\n+                     initdocstring.strip() == object.__new__.__doc__)):  # for !pypy\n+                    initdocstring = None\n+            if initdocstring:\n+                if content == 'init':\n+                    docstrings = [initdocstring]\n+                else:\n+                    docstrings.append(initdocstring)\n+\n+        tab_width = self.directive.state.document.settings.tab_width\n+        return [prepare_docstring(docstring, ignore, tab_width) for docstring in docstrings]\n+\n+    def add_content(self, more_content: Optional[StringList], no_docstring: bool = False\n+                    ) -> None:\n+        if self.doc_as_attr:\n+            more_content = StringList([_('alias of %s') % restify(self.object)], source='')\n+\n+        super().add_content(more_content)\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        if self.doc_as_attr:\n+            return\n+        super().document_members(all_members)\n+\n+    def generate(self, more_content: Optional[StringList] = None, real_modname: str = None,\n+                 check_module: bool = False, all_members: bool = False) -> None:\n+        # Do not pass real_modname and use the name from the __module__\n+        # attribute of the class.\n+        # If a class gets imported into the module real_modname\n+        # the analyzer won't find the source of the class, if\n+        # it looks in real_modname.\n+        return super().generate(more_content=more_content,\n+                                check_module=check_module,\n+                                all_members=all_members)\n+\n+\n+class ExceptionDocumenter(ClassDocumenter):\n+    \"\"\"\n+    Specialized ClassDocumenter subclass for exceptions.\n+    \"\"\"\n+    objtype = 'exception'\n+    member_order = 10\n+\n+    # needs a higher priority than ClassDocumenter\n+    priority = 10\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return isinstance(member, type) and issubclass(member, BaseException)\n+\n+\n+class DataDocumenterMixinBase:\n+    # define types of instance variables\n+    config = None  # type: Config\n+    env = None  # type: BuildEnvironment\n+    modname = None  # type: str\n+    parent = None  # type: Any\n+    object = None  # type: Any\n+    objpath = None  # type: List[str]\n+\n+    def should_suppress_directive_header(self) -> bool:\n+        \"\"\"Check directive header should be suppressed.\"\"\"\n+        return False\n+\n+    def should_suppress_value_header(self) -> bool:\n+        \"\"\"Check :value: header should be suppressed.\"\"\"\n+        return False\n+\n+    def update_content(self, more_content: StringList) -> None:\n+        \"\"\"Update docstring for the NewType object.\"\"\"\n+        pass\n+\n+\n+class GenericAliasMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for DataDocumenter and AttributeDocumenter to provide the feature for\n+    supporting GenericAliases.\n+    \"\"\"\n+\n+    def should_suppress_directive_header(self) -> bool:\n+        return (inspect.isgenericalias(self.object) or\n+                super().should_suppress_directive_header())\n+\n+    def update_content(self, more_content: StringList) -> None:\n+        if inspect.isgenericalias(self.object):\n+            alias = stringify_typehint(self.object)\n+            more_content.append(_('alias of %s') % alias, '')\n+            more_content.append('', '')\n+\n+        super().update_content(more_content)\n+\n+\n+class NewTypeMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for DataDocumenter and AttributeDocumenter to provide the feature for\n+    supporting NewTypes.\n+    \"\"\"\n+\n+    def should_suppress_directive_header(self) -> bool:\n+        return (inspect.isNewType(self.object) or\n+                super().should_suppress_directive_header())\n+\n+    def update_content(self, more_content: StringList) -> None:\n+        if inspect.isNewType(self.object):\n+            supertype = restify(self.object.__supertype__)\n+            more_content.append(_('alias of %s') % supertype, '')\n+            more_content.append('', '')\n+\n+        super().update_content(more_content)\n+\n+\n+class TypeVarMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for DataDocumenter and AttributeDocumenter to provide the feature for\n+    supporting TypeVars.\n+    \"\"\"\n+\n+    def should_suppress_directive_header(self) -> bool:\n+        return (isinstance(self.object, TypeVar) or\n+                super().should_suppress_directive_header())\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if ignore is not None:\n+            warnings.warn(\"The 'ignore' argument to autodoc.%s.get_doc() is deprecated.\"\n+                          % self.__class__.__name__,\n+                          RemovedInSphinx50Warning, stacklevel=2)\n+\n+        if isinstance(self.object, TypeVar):\n+            if self.object.__doc__ != TypeVar.__doc__:\n+                return super().get_doc()  # type: ignore\n+            else:\n+                return []\n+        else:\n+            return super().get_doc()  # type: ignore\n+\n+    def update_content(self, more_content: StringList) -> None:\n+        if isinstance(self.object, TypeVar):\n+            attrs = [repr(self.object.__name__)]\n+            for constraint in self.object.__constraints__:\n+                attrs.append(stringify_typehint(constraint))\n+            if self.object.__covariant__:\n+                attrs.append(\"covariant=True\")\n+            if self.object.__contravariant__:\n+                attrs.append(\"contravariant=True\")\n+\n+            more_content.append(_('alias of TypeVar(%s)') % \", \".join(attrs), '')\n+            more_content.append('', '')\n+\n+        super().update_content(more_content)\n+\n+\n+class UninitializedGlobalVariableMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for DataDocumenter to provide the feature for supporting uninitialized\n+    (type annotation only) global variables.\n+    \"\"\"\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        try:\n+            return super().import_object(raiseerror=True)  # type: ignore\n+        except ImportError as exc:\n+            # annotation only instance variable (PEP-526)\n+            try:\n+                self.parent = importlib.import_module(self.modname)\n+                annotations = get_type_hints(self.parent, None,\n+                                             self.config.autodoc_type_aliases)\n+                if self.objpath[-1] in annotations:\n+                    self.object = UNINITIALIZED_ATTR\n+                    return True\n+            except ImportError:\n+                pass\n+\n+            if raiseerror:\n+                raise\n+            else:\n+                logger.warning(exc.args[0], type='autodoc', subtype='import_object')\n+                self.env.note_reread()\n+                return False\n+\n+    def should_suppress_value_header(self) -> bool:\n+        return (self.object == UNINITIALIZED_ATTR or\n+                super().should_suppress_value_header())\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if self.object is UNINITIALIZED_ATTR:\n+            return []\n+        else:\n+            return super().get_doc(encoding, ignore)  # type: ignore\n+\n+\n+class DataDocumenter(GenericAliasMixin, NewTypeMixin, TypeVarMixin,\n+                     UninitializedGlobalVariableMixin, ModuleLevelDocumenter):\n+    \"\"\"\n+    Specialized Documenter subclass for data items.\n+    \"\"\"\n+    objtype = 'data'\n+    member_order = 40\n+    priority = -10\n+    option_spec = dict(ModuleLevelDocumenter.option_spec)\n+    option_spec[\"annotation\"] = annotation_option\n+    option_spec[\"no-value\"] = bool_option\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return isinstance(parent, ModuleDocumenter) and isattr\n+\n+    def update_annotations(self, parent: Any) -> None:\n+        \"\"\"Update __annotations__ to support type_comment and so on.\"\"\"\n+        try:\n+            annotations = inspect.getannotations(parent)\n+\n+            analyzer = ModuleAnalyzer.for_module(self.modname)\n+            analyzer.analyze()\n+            for (classname, attrname), annotation in analyzer.annotations.items():\n+                if classname == '' and attrname not in annotations:\n+                    annotations[attrname] = annotation  # type: ignore\n+        except AttributeError:\n+            pass\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        ret = super().import_object(raiseerror)\n+        if self.parent:\n+            self.update_annotations(self.parent)\n+\n+        return ret\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        super().add_directive_header(sig)\n+        sourcename = self.get_sourcename()\n+        if self.options.annotation is SUPPRESS or self.should_suppress_directive_header():\n+            pass\n+        elif self.options.annotation:\n+            self.add_line('   :annotation: %s' % self.options.annotation,\n+                          sourcename)\n+        else:\n+            # obtain annotation for this data\n+            annotations = get_type_hints(self.parent, None, self.config.autodoc_type_aliases)\n+            if self.objpath[-1] in annotations:\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                self.add_line('   :type: ' + objrepr, sourcename)\n+\n+            try:\n+                if self.options.no_value or self.should_suppress_value_header():\n+                    pass\n+                else:\n+                    objrepr = object_description(self.object)\n+                    self.add_line('   :value: ' + objrepr, sourcename)\n+            except ValueError:\n+                pass\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        pass\n+\n+    def get_real_modname(self) -> str:\n+        return self.get_attr(self.parent or self.object, '__module__', None) \\\n+            or self.modname\n+\n+    def add_content(self, more_content: Optional[StringList], no_docstring: bool = False\n+                    ) -> None:\n+        if not more_content:\n+            more_content = StringList()\n+\n+        self.update_content(more_content)\n+        super().add_content(more_content, no_docstring=no_docstring)\n+\n+\n+class NewTypeDataDocumenter(DataDocumenter):\n+    \"\"\"\n+    Specialized Documenter subclass for NewTypes.\n+\n+    Note: This must be invoked before FunctionDocumenter because NewType is a kind of\n+    function object.\n+    \"\"\"\n+\n+    objtype = 'newtypedata'\n+    directivetype = 'data'\n+    priority = FunctionDocumenter.priority + 1\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return inspect.isNewType(member) and isattr\n+\n+\n+class MethodDocumenter(DocstringSignatureMixin, ClassLevelDocumenter):  # type: ignore\n+    \"\"\"\n+    Specialized Documenter subclass for methods (normal, static and class).\n+    \"\"\"\n+    objtype = 'method'\n+    directivetype = 'method'\n+    member_order = 50\n+    priority = 1  # must be more than FunctionDocumenter\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return inspect.isroutine(member) and \\\n+            not isinstance(parent, ModuleDocumenter)\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        ret = super().import_object(raiseerror)\n+        if not ret:\n+            return ret\n+\n+        # to distinguish classmethod/staticmethod\n+        obj = self.parent.__dict__.get(self.object_name)\n+        if obj is None:\n+            obj = self.object\n+\n+        if (inspect.isclassmethod(obj) or\n+                inspect.isstaticmethod(obj, cls=self.parent, name=self.object_name)):\n+            # document class and static members before ordinary ones\n+            self.member_order = self.member_order - 1\n+\n+        return ret\n+\n+    def format_args(self, **kwargs: Any) -> str:\n+        if self.config.autodoc_typehints in ('none', 'description'):\n+            kwargs.setdefault('show_annotation', False)\n+\n+        try:\n+            if self.object == object.__init__ and self.parent != object:\n+                # Classes not having own __init__() method are shown as no arguments.\n+                #\n+                # Note: The signature of object.__init__() is (self, /, *args, **kwargs).\n+                #       But it makes users confused.\n+                args = '()'\n+            else:\n+                if inspect.isstaticmethod(self.object, cls=self.parent, name=self.object_name):\n+                    self.env.app.emit('autodoc-before-process-signature', self.object, False)\n+                    sig = inspect.signature(self.object, bound_method=False,\n+                                            type_aliases=self.config.autodoc_type_aliases)\n+                else:\n+                    self.env.app.emit('autodoc-before-process-signature', self.object, True)\n+                    sig = inspect.signature(self.object, bound_method=True,\n+                                            type_aliases=self.config.autodoc_type_aliases)\n+                args = stringify_signature(sig, **kwargs)\n+        except TypeError as exc:\n+            logger.warning(__(\"Failed to get a method signature for %s: %s\"),\n+                           self.fullname, exc)\n+            return None\n+        except ValueError:\n+            args = ''\n+\n+        if self.config.strip_signature_backslash:\n+            # escape backslashes for reST\n+            args = args.replace('\\\\', '\\\\\\\\')\n+        return args\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        super().add_directive_header(sig)\n+\n+        sourcename = self.get_sourcename()\n+        obj = self.parent.__dict__.get(self.object_name, self.object)\n+        if inspect.isabstractmethod(obj):\n+            self.add_line('   :abstractmethod:', sourcename)\n+        if inspect.iscoroutinefunction(obj):\n+            self.add_line('   :async:', sourcename)\n+        if inspect.isclassmethod(obj):\n+            self.add_line('   :classmethod:', sourcename)\n+        if inspect.isstaticmethod(obj, cls=self.parent, name=self.object_name):\n+            self.add_line('   :staticmethod:', sourcename)\n+        if self.analyzer and '.'.join(self.objpath) in self.analyzer.finals:\n+            self.add_line('   :final:', sourcename)\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        pass\n+\n+    def format_signature(self, **kwargs: Any) -> str:\n+        sigs = []\n+        if (self.analyzer and\n+                '.'.join(self.objpath) in self.analyzer.overloads and\n+                self.config.autodoc_typehints == 'signature'):\n+            # Use signatures for overloaded methods instead of the implementation method.\n+            overloaded = True\n+        else:\n+            overloaded = False\n+            sig = super().format_signature(**kwargs)\n+            sigs.append(sig)\n+\n+        meth = self.parent.__dict__.get(self.objpath[-1])\n+        if inspect.is_singledispatch_method(meth):\n+            # append signature of singledispatch'ed functions\n+            for typ, func in meth.dispatcher.registry.items():\n+                if typ is object:\n+                    pass  # default implementation. skipped.\n+                else:\n+                    self.annotate_to_first_argument(func, typ)\n+\n+                    documenter = MethodDocumenter(self.directive, '')\n+                    documenter.parent = self.parent\n+                    documenter.object = func\n+                    documenter.objpath = [None]\n+                    sigs.append(documenter.format_signature())\n+        if overloaded:\n+            __globals__ = safe_getattr(self.object, '__globals__', {})\n+            for overload in self.analyzer.overloads.get('.'.join(self.objpath)):\n+                overload = evaluate_signature(overload, __globals__,\n+                                              self.config.autodoc_type_aliases)\n+\n+                if not inspect.isstaticmethod(self.object, cls=self.parent,\n+                                              name=self.object_name):\n+                    parameters = list(overload.parameters.values())\n+                    overload = overload.replace(parameters=parameters[1:])\n+                sig = stringify_signature(overload, **kwargs)\n+                sigs.append(sig)\n+\n+        return \"\\n\".join(sigs)\n+\n+    def annotate_to_first_argument(self, func: Callable, typ: Type) -> None:\n+        \"\"\"Annotate type hint to the first argument of function if needed.\"\"\"\n+        try:\n+            sig = inspect.signature(func, type_aliases=self.config.autodoc_type_aliases)\n+        except TypeError as exc:\n+            logger.warning(__(\"Failed to get a method signature for %s: %s\"),\n+                           self.fullname, exc)\n+            return\n+        except ValueError:\n+            return\n+        if len(sig.parameters) == 1:\n+            return\n+\n+        params = list(sig.parameters.values())\n+        if params[1].annotation is Parameter.empty:\n+            params[1] = params[1].replace(annotation=typ)\n+            try:\n+                func.__signature__ = sig.replace(parameters=params)  # type: ignore\n+            except TypeError:\n+                # failed to update signature (ex. built-in or extension types)\n+                return\n+\n+\n+class NonDataDescriptorMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for AttributeDocumenter to provide the feature for supporting non\n+    data-descriptors.\n+\n+    .. note:: This mix-in must be inherited after other mix-ins.  Otherwise, docstring\n+              and :value: header will be suppressed unexpectedly.\n+    \"\"\"\n+\n+    def should_suppress_value_header(self) -> bool:\n+        return (inspect.isattributedescriptor(self.object) or\n+                super().should_suppress_directive_header())\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if not inspect.isattributedescriptor(self.object):\n+            # the docstring of non datadescriptor is very probably the wrong thing\n+            # to display\n+            return []\n+        else:\n+            return super().get_doc(encoding, ignore)  # type: ignore\n+\n+\n+class SlotsMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for AttributeDocumenter to provide the feature for supporting __slots__.\n+    \"\"\"\n+\n+    def isslotsattribute(self) -> bool:\n+        \"\"\"Check the subject is an attribute in __slots__.\"\"\"\n+        try:\n+            __slots__ = inspect.getslots(self.parent)\n+            if __slots__ and self.objpath[-1] in __slots__:\n+                return True\n+            else:\n+                return False\n+        except (AttributeError, ValueError):\n+            return False\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        ret = super().import_object(raiseerror)  # type: ignore\n+        if self.isslotsattribute():\n+            self.object = SLOTSATTR\n+\n+        return ret\n+\n+    def should_suppress_directive_header(self) -> bool:\n+        if self.object is SLOTSATTR:\n+            self._datadescriptor = True\n+            return True\n+        else:\n+            return super().should_suppress_directive_header()\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if self.object is SLOTSATTR:\n+            try:\n+                __slots__ = inspect.getslots(self.parent)\n+                if __slots__ and __slots__.get(self.objpath[-1]):\n+                    docstring = prepare_docstring(__slots__[self.objpath[-1]])\n+                    return [docstring]\n+                else:\n+                    return []\n+            except (AttributeError, ValueError) as exc:\n+                logger.warning(__('Invalid __slots__ found on %s. Ignored.'),\n+                               (self.parent.__qualname__, exc), type='autodoc')\n+                return []\n+        else:\n+            return super().get_doc(encoding, ignore)  # type: ignore\n+\n+\n+class UninitializedInstanceAttributeMixin(DataDocumenterMixinBase):\n+    \"\"\"\n+    Mixin for AttributeDocumenter to provide the feature for supporting uninitialized\n+    instance attributes (that are defined in __init__() methods with doc-comments).\n+\n+    Example:\n+\n+        class Foo:\n+            def __init__(self):\n+                self.attr = None  #: This is a target of this mix-in.\n+    \"\"\"\n+\n+    def get_attribute_comment(self, parent: Any) -> Optional[List[str]]:\n+        try:\n+            for cls in inspect.getmro(parent):\n+                try:\n+                    module = safe_getattr(cls, '__module__')\n+                    qualname = safe_getattr(cls, '__qualname__')\n+\n+                    analyzer = ModuleAnalyzer.for_module(module)\n+                    analyzer.analyze()\n+                    if qualname and self.objpath:\n+                        key = (qualname, self.objpath[-1])\n+                        if key in analyzer.attr_docs:\n+                            return list(analyzer.attr_docs[key])\n+                except (AttributeError, PycodeError):\n+                    pass\n+        except (AttributeError, PycodeError):\n+            pass\n+\n+        return None\n+\n+    def is_uninitialized_instance_attribute(self, parent: Any) -> bool:\n+        \"\"\"Check the subject is an attribute defined in __init__().\"\"\"\n+        # An instance variable defined in __init__().\n+        if self.get_attribute_comment(parent):\n+            return True\n+        else:\n+            return False\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        \"\"\"Check the exisitence of uninitizlied instance attribute when failed to import\n+        the attribute.\n+        \"\"\"\n+        try:\n+            return super().import_object(raiseerror=True)  # type: ignore\n+        except ImportError as exc:\n+            try:\n+                ret = import_object(self.modname, self.objpath[:-1], 'class',\n+                                    attrgetter=self.get_attr,  # type: ignore\n+                                    warningiserror=self.config.autodoc_warningiserror)\n+                parent = ret[3]\n+                if self.is_uninitialized_instance_attribute(parent):\n+                    self.object = UNINITIALIZED_ATTR\n+                    self.parent = parent\n+                    return True\n+            except ImportError:\n+                pass\n+\n+            if raiseerror:\n+                raise\n+            else:\n+                logger.warning(exc.args[0], type='autodoc', subtype='import_object')\n+                self.env.note_reread()\n+                return False\n+\n+    def should_suppress_value_header(self) -> bool:\n+        return (self.object is UNINITIALIZED_ATTR or\n+                super().should_suppress_value_header())\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if self.object is UNINITIALIZED_ATTR:\n+            comment = self.get_attribute_comment(self.parent)\n+            if comment:\n+                return [comment]\n+\n+        return super().get_doc(encoding, ignore)  # type: ignore\n+\n+    def add_content(self, more_content: Optional[StringList], no_docstring: bool = False\n+                    ) -> None:\n+        if self.object is UNINITIALIZED_ATTR:\n+            self.analyzer = None\n+\n+        super().add_content(more_content, no_docstring=no_docstring)  # type: ignore\n+\n+\n+class AttributeDocumenter(GenericAliasMixin, NewTypeMixin, SlotsMixin,  # type: ignore\n+                          TypeVarMixin, UninitializedInstanceAttributeMixin,\n+                          NonDataDescriptorMixin, DocstringStripSignatureMixin,\n+                          ClassLevelDocumenter):\n+    \"\"\"\n+    Specialized Documenter subclass for attributes.\n+    \"\"\"\n+    objtype = 'attribute'\n+    member_order = 60\n+    option_spec = dict(ModuleLevelDocumenter.option_spec)\n+    option_spec[\"annotation\"] = annotation_option\n+    option_spec[\"no-value\"] = bool_option\n+\n+    # must be higher than the MethodDocumenter, else it will recognize\n+    # some non-data descriptors as methods\n+    priority = 10\n+\n+    @staticmethod\n+    def is_function_or_method(obj: Any) -> bool:\n+        return inspect.isfunction(obj) or inspect.isbuiltin(obj) or inspect.ismethod(obj)\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        if inspect.isattributedescriptor(member):\n+            return True\n+        elif (not isinstance(parent, ModuleDocumenter) and\n+              not inspect.isroutine(member) and\n+              not isinstance(member, type)):\n+            return True\n+        else:\n+            return False\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        pass\n+\n+    def isinstanceattribute(self) -> bool:\n+        \"\"\"Check the subject is an instance attribute.\"\"\"\n+        # uninitialized instance variable (PEP-526)\n+        with mock(self.config.autodoc_mock_imports):\n+            try:\n+                ret = import_object(self.modname, self.objpath[:-1], 'class',\n+                                    attrgetter=self.get_attr,\n+                                    warningiserror=self.config.autodoc_warningiserror)\n+                self.parent = ret[3]\n+                annotations = get_type_hints(self.parent, None,\n+                                             self.config.autodoc_type_aliases)\n+                if self.objpath[-1] in annotations:\n+                    self.object = UNINITIALIZED_ATTR\n+                    return True\n+            except ImportError:\n+                pass\n+\n+        return False\n+\n+    def update_annotations(self, parent: Any) -> None:\n+        \"\"\"Update __annotations__ to support type_comment and so on.\"\"\"\n+        try:\n+            annotations = inspect.getannotations(parent)\n+\n+            for cls in inspect.getmro(parent):\n+                try:\n+                    module = safe_getattr(cls, '__module__')\n+                    qualname = safe_getattr(cls, '__qualname__')\n+\n+                    analyzer = ModuleAnalyzer.for_module(module)\n+                    analyzer.analyze()\n+                    for (classname, attrname), annotation in analyzer.annotations.items():\n+                        if classname == qualname and attrname not in annotations:\n+                            annotations[attrname] = annotation  # type: ignore\n+                except (AttributeError, PycodeError):\n+                    pass\n+        except AttributeError:\n+            pass\n+\n+    def import_object(self, raiseerror: bool = False) -> bool:\n+        try:\n+            ret = super().import_object(raiseerror=True)\n+            if inspect.isenumattribute(self.object):\n+                self.object = self.object.value\n+        except ImportError as exc:\n+            if self.isinstanceattribute():\n+                self.object = INSTANCEATTR\n+                ret = True\n+            elif raiseerror:\n+                raise\n+            else:\n+                logger.warning(exc.args[0], type='autodoc', subtype='import_object')\n+                self.env.note_reread()\n+                ret = False\n+\n+        if self.parent:\n+            self.update_annotations(self.parent)\n+\n+        return ret\n+\n+    def get_real_modname(self) -> str:\n+        return self.get_attr(self.parent or self.object, '__module__', None) \\\n+            or self.modname\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        super().add_directive_header(sig)\n+        sourcename = self.get_sourcename()\n+        if self.options.annotation is SUPPRESS or self.should_suppress_directive_header():\n+            pass\n+        elif self.options.annotation:\n+            self.add_line('   :annotation: %s' % self.options.annotation, sourcename)\n+        else:\n+            # obtain type annotation for this attribute\n+            annotations = get_type_hints(self.parent, None, self.config.autodoc_type_aliases)\n+            if self.objpath[-1] in annotations:\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                self.add_line('   :type: ' + objrepr, sourcename)\n+\n+            try:\n+                if (self.object is INSTANCEATTR or self.options.no_value or\n+                        self.should_suppress_value_header()):\n+                    pass\n+                else:\n+                    objrepr = object_description(self.object)\n+                    self.add_line('   :value: ' + objrepr, sourcename)\n+            except ValueError:\n+                pass\n+\n+    def get_doc(self, encoding: str = None, ignore: int = None) -> List[List[str]]:\n+        if self.object is INSTANCEATTR:\n+            return []\n+\n+        try:\n+            # Disable `autodoc_inherit_docstring` temporarily to avoid to obtain\n+            # a docstring from the value which descriptor returns unexpectedly.\n+            # ref: https://github.com/sphinx-doc/sphinx/issues/7805\n+            orig = self.config.autodoc_inherit_docstrings\n+            self.config.autodoc_inherit_docstrings = False  # type: ignore\n+            return super().get_doc(encoding, ignore)\n+        finally:\n+            self.config.autodoc_inherit_docstrings = orig  # type: ignore\n+\n+    def add_content(self, more_content: Optional[StringList], no_docstring: bool = False\n+                    ) -> None:\n+        if more_content is None:\n+            more_content = StringList()\n+        self.update_content(more_content)\n+        super().add_content(more_content, no_docstring)\n+\n+\n+class PropertyDocumenter(DocstringStripSignatureMixin, ClassLevelDocumenter):  # type: ignore\n+    \"\"\"\n+    Specialized Documenter subclass for properties.\n+    \"\"\"\n+    objtype = 'property'\n+    directivetype = 'method'\n+    member_order = 60\n+\n+    # before AttributeDocumenter\n+    priority = AttributeDocumenter.priority + 1\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return inspect.isproperty(member) and isinstance(parent, ClassDocumenter)\n+\n+    def document_members(self, all_members: bool = False) -> None:\n+        pass\n+\n+    def get_real_modname(self) -> str:\n+        return self.get_attr(self.parent or self.object, '__module__', None) \\\n+            or self.modname\n+\n+    def add_directive_header(self, sig: str) -> None:\n+        super().add_directive_header(sig)\n+        sourcename = self.get_sourcename()\n+        if inspect.isabstractmethod(self.object):\n+            self.add_line('   :abstractmethod:', sourcename)\n+        self.add_line('   :property:', sourcename)\n+\n+\n+class NewTypeAttributeDocumenter(AttributeDocumenter):\n+    \"\"\"\n+    Specialized Documenter subclass for NewTypes.\n+\n+    Note: This must be invoked before MethodDocumenter because NewType is a kind of\n+    function object.\n+    \"\"\"\n+\n+    objtype = 'newvarattribute'\n+    directivetype = 'attribute'\n+    priority = MethodDocumenter.priority + 1\n+\n+    @classmethod\n+    def can_document_member(cls, member: Any, membername: str, isattr: bool, parent: Any\n+                            ) -> bool:\n+        return not isinstance(parent, ModuleDocumenter) and inspect.isNewType(member)\n+\n+\n+def get_documenters(app: Sphinx) -> Dict[str, \"Type[Documenter]\"]:\n+    \"\"\"Returns registered Documenter classes\"\"\"\n+    warnings.warn(\"get_documenters() is deprecated.\", RemovedInSphinx50Warning, stacklevel=2)\n+    return app.registry.documenters\n+\n+\n+def autodoc_attrgetter(app: Sphinx, obj: Any, name: str, *defargs: Any) -> Any:\n+    \"\"\"Alternative getattr() for types\"\"\"\n+    for typ, func in app.registry.autodoc_attrgettrs.items():\n+        if isinstance(obj, typ):\n+            return func(obj, name, *defargs)\n+\n+    return safe_getattr(obj, name, *defargs)\n+\n+\n+def migrate_autodoc_member_order(app: Sphinx, config: Config) -> None:\n+    if config.autodoc_member_order == 'alphabetic':\n+        # RemovedInSphinx50Warning\n+        logger.warning(__('autodoc_member_order now accepts \"alphabetical\" '\n+                          'instead of \"alphabetic\". Please update your setting.'))\n+        config.autodoc_member_order = 'alphabetical'  # type: ignore\n+\n+\n+# for compatibility\n+from sphinx.ext.autodoc.deprecated import DataDeclarationDocumenter  # NOQA\n+from sphinx.ext.autodoc.deprecated import GenericAliasDocumenter  # NOQA\n+from sphinx.ext.autodoc.deprecated import InstanceAttributeDocumenter  # NOQA\n+from sphinx.ext.autodoc.deprecated import SingledispatchFunctionDocumenter  # NOQA\n+from sphinx.ext.autodoc.deprecated import SingledispatchMethodDocumenter  # NOQA\n+from sphinx.ext.autodoc.deprecated import SlotsAttributeDocumenter  # NOQA\n+from sphinx.ext.autodoc.deprecated import TypeVarDocumenter  # NOQA\n+\n+\n+def setup(app: Sphinx) -> Dict[str, Any]:\n+    app.add_autodocumenter(ModuleDocumenter)\n+    app.add_autodocumenter(ClassDocumenter)\n+    app.add_autodocumenter(ExceptionDocumenter)\n+    app.add_autodocumenter(DataDocumenter)\n+    app.add_autodocumenter(NewTypeDataDocumenter)\n+    app.add_autodocumenter(FunctionDocumenter)\n+    app.add_autodocumenter(DecoratorDocumenter)\n+    app.add_autodocumenter(MethodDocumenter)\n+    app.add_autodocumenter(AttributeDocumenter)\n+    app.add_autodocumenter(PropertyDocumenter)\n+    app.add_autodocumenter(NewTypeAttributeDocumenter)\n+\n+    app.add_config_value('autoclass_content', 'class', True, ENUM('both', 'class', 'init'))\n+    app.add_config_value('autodoc_member_order', 'alphabetical', True,\n+                         ENUM('alphabetic', 'alphabetical', 'bysource', 'groupwise'))\n+    app.add_config_value('autodoc_default_options', {}, True)\n+    app.add_config_value('autodoc_docstring_signature', True, True)\n+    app.add_config_value('autodoc_mock_imports', [], True)\n+    app.add_config_value('autodoc_typehints', \"signature\", True,\n+                         ENUM(\"signature\", \"description\", \"none\"))\n+    app.add_config_value('autodoc_type_aliases', {}, True)\n+    app.add_config_value('autodoc_warningiserror', True, True)\n+    app.add_config_value('autodoc_inherit_docstrings', True, True)\n+    app.add_event('autodoc-before-process-signature')\n+    app.add_event('autodoc-process-docstring')\n+    app.add_event('autodoc-process-signature')\n+    app.add_event('autodoc-skip-member')\n+\n+    app.connect('config-inited', migrate_autodoc_member_order, priority=800)\n+\n+    app.setup_extension('sphinx.ext.autodoc.type_comment')\n+    app.setup_extension('sphinx.ext.autodoc.typehints')\n+\n+    return {'version': sphinx.__display_version__, 'parallel_read_safe': True}\n"
  },
  "sphinx-doc__sphinx-8551": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8551",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 79d7e4f46..fb518adf2 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1139,6 +1139,12 @@ class PythonModuleIndex(Index):\n \n \n class PythonDomain(Domain):\n+\n+    def process_field_xref(self, pnode: pending_xref) -> None:\n+        \"\"\"Process a pending_xref created in a doc field by attaching current\n+        reference context (py:module, py:class, etc.) so that field-generated\n+        cross-references resolve the same way as explicit xrefs.\"\"\"\n+        pnode.attributes.update(self.env.ref_context)\n     \"\"\"Python language domain.\"\"\"\n     name = 'py'\n     label = 'Python'\n"
  },
  "sphinx-doc__sphinx-8638": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8638",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 000e2e8d3..f227d9e9a 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1162,18 +1162,22 @@ class PythonDomain(Domain):\n                                    self.objects[oname].objtype in objtypes]\n         else:\n             # NOTE: searching for exact match, object type is not considered\n-            if name in self.objects:\n-                newname = name\n-            elif type == 'mod':\n+            # Prefer class- and module-qualified names before bare names to avoid\n+            # linking instance attributes to unrelated globals.\n+            if type == 'mod':\n                 # only exact matches allowed for modules\n-                return []\n+                if name in self.objects:\n+                    newname = name\n+                else:\n+                    return []\n             elif classname and classname + '.' + name in self.objects:\n                 newname = classname + '.' + name\n+            elif modname and classname and modname + '.' + classname + '.' + name in self.objects:\n+                newname = modname + '.' + classname + '.' + name\n             elif modname and modname + '.' + name in self.objects:\n                 newname = modname + '.' + name\n-            elif modname and classname and \\\n-                    modname + '.' + classname + '.' + name in self.objects:\n-                newname = modname + '.' + classname + '.' + name\n+            elif name in self.objects:\n+                newname = name\n         if newname is not None:\n             matches.append((newname, self.objects[newname]))\n         return matches\n"
  },
  "sphinx-doc__sphinx-8721": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-8721",
    "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..008dfc368 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -52,6 +52,8 @@ def _get_full_modname(app: Sphinx, modname: str, attribute: str) -> Optional[str\n \n def doctree_read(app: Sphinx, doctree: Node) -> None:\n     env = app.builder.env\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     if not hasattr(env, '_viewcode_modules'):\n         env._viewcode_modules = {}  # type: ignore\n     if app.builder.name == \"singlehtml\":\n@@ -180,6 +182,9 @@ def should_generate_module_page(app: Sphinx, modname: str) -> bool:\n \n def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], None, None]:\n     env = app.builder.env\n+    # Skip generating module pages for EPUB builders unless enabled\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     if not hasattr(env, '_viewcode_modules'):\n         return\n     highlighter = app.builder.highlighter  # type: ignore\n"
  },
  "sphinx-doc__sphinx-9229": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9229",
    "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 1f4c98284..687de73da 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1725,7 +1725,10 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n                     ) -> None:\n         if self.doc_as_attr:\n             try:\n-                more_content = StringList([_('alias of %s') % restify(self.object)], source='')\n+                if not more_content:\n+                    more_content = StringList()\n+                more_content.append(_('alias of %s') % restify(self.object), '')\n+                more_content.append('', '')\n             except AttributeError:\n                 pass  # Invalid class object is passed.\n \n"
  },
  "sphinx-doc__sphinx-9281": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9281",
    "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex a415a7074..9616784cf 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -457,6 +457,9 @@ def object_description(object: Any) -> str:\n         else:\n             return \"frozenset({%s})\" % \", \".join(object_description(x)\n                                                  for x in sorted_values)\n+    if isinstance(object, enum.Enum):\n+        return \"%s.%s\" % (object.__class__.__name__, object.name)\n+\n     try:\n         s = repr(object)\n     except Exception as exc:\n"
  },
  "sphinx-doc__sphinx-9320": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9320",
    "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..f1f158378 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -95,6 +95,13 @@ def is_path(x: str) -> str:\n     return x\n \n \n+def path_or_empty(x: str) -> str:\n+    \"\"\"Allow empty input (for exit) or validate path.\"\"\"\n+    if not x:\n+        return x\n+    return is_path(x)\n+\n+\n def allow_empty(x: str) -> str:\n     return x\n \n@@ -223,7 +230,7 @@ def ask_user(d: Dict) -> None:\n         print(__('sphinx-quickstart will not overwrite existing Sphinx projects.'))\n         print()\n         d['path'] = do_prompt(__('Please enter a new root path (or just Enter to exit)'),\n-                              '', is_path)\n+                              '', path_or_empty)\n         if not d['path']:\n             sys.exit(1)\n \n"
  },
  "sphinx-doc__sphinx-9367": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9367",
    "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..494dbc550 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -214,6 +214,9 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n+            # Preserve trailing comma for single-element tuples, e.g. (1,)\n+            if len(node.elts) == 1:\n+                return \"(\" + self.visit(node.elts[0]) + \",)\"\n             return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n"
  },
  "sphinx-doc__sphinx-9461": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9461",
    "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex 1a8ea0973..021048698 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -9,6 +9,7 @@\n \"\"\"\n \n import importlib\n+import inspect\n import traceback\n import warnings\n from typing import Any, Callable, Dict, List, NamedTuple, Optional, Tuple\n"
  },
  "sphinx-doc__sphinx-9698": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9698",
    "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..1a3bd60c7 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -796,7 +796,7 @@ class PyMethod(PyObject):\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n+            return _('%s (%s property)') % (methname, clsname)\n         elif 'staticmethod' in self.options:\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..b4d12726f 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -297,14 +297,30 @@ class DocFieldTransformer:\n \n             # also support syntax like ``:param type name:``\n             if typedesc.is_typed:\n-                try:\n-                    argtype, argname = fieldarg.split(None, 1)\n-                except ValueError:\n-                    pass\n-                else:\n-                    types.setdefault(typename, {})[argname] = \\\n-                        [nodes.Text(argtype)]\n+                # split into type and name, but avoid splitting on whitespace\n+                # inside nested delimiters like parentheses or brackets, e.g.\n+                # \"dict(str, str) name\" should be split into\n+                # (\"dict(str, str)\", \"name\").\n+                s_field = fieldarg\n+                nest = 0\n+                split_pos = None\n+                for i, ch in enumerate(s_field):\n+                    if ch in \"([{\":\n+                        nest += 1\n+                    elif ch in \")]}\":\n+                        if nest > 0:\n+                            nest -= 1\n+                    elif ch.isspace() and nest == 0:\n+                        split_pos = i\n+                        break\n+                if split_pos is not None:\n+                    argtype = s_field[:split_pos].strip()\n+                    argname = s_field[split_pos:].strip()\n+                    types.setdefault(typename, {})[argname] = [nodes.Text(argtype)]\n                     fieldarg = argname\n+                else:\n+                    # fallback: no split possible, leave as-is\n+                    pass\n \n             translatable_content = nodes.inline(field_body.rawsource,\n                                                 translatable=True)\ndiff --git a/sphinx/util/docfields.py.bak b/sphinx/util/docfields.py.bak\nnew file mode 100644\nindex 000000000..3a3367ebe\n--- /dev/null\n+++ b/sphinx/util/docfields.py.bak\n@@ -0,0 +1,344 @@\n+\"\"\"\n+    sphinx.util.docfields\n+    ~~~~~~~~~~~~~~~~~~~~~\n+\n+    \"Doc fields\" are reST field lists in object descriptions that will\n+    be domain-specifically transformed to a more appealing presentation.\n+\n+    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n+    :license: BSD, see LICENSE for details.\n+\"\"\"\n+\n+from typing import TYPE_CHECKING, Any, Dict, List, Tuple, Type, Union, cast\n+\n+from docutils import nodes\n+from docutils.nodes import Node\n+\n+from sphinx import addnodes\n+from sphinx.environment import BuildEnvironment\n+from sphinx.util.typing import TextlikeNode\n+\n+if TYPE_CHECKING:\n+    from sphinx.directive import ObjectDescription\n+\n+\n+def _is_single_paragraph(node: nodes.field_body) -> bool:\n+    \"\"\"True if the node only contains one paragraph (and system messages).\"\"\"\n+    if len(node) == 0:\n+        return False\n+    elif len(node) > 1:\n+        for subnode in node[1:]:  # type: Node\n+            if not isinstance(subnode, nodes.system_message):\n+                return False\n+    if isinstance(node[0], nodes.paragraph):\n+        return True\n+    return False\n+\n+\n+class Field:\n+    \"\"\"A doc field that is never grouped.  It can have an argument or not, the\n+    argument can be linked using a specified *rolename*.  Field should be used\n+    for doc fields that usually don't occur more than once.\n+\n+    The body can be linked using a specified *bodyrolename* if the content is\n+    just a single inline or text node.\n+\n+    Example::\n+\n+       :returns: description of the return value\n+       :rtype: description of the return type\n+    \"\"\"\n+    is_grouped = False\n+    is_typed = False\n+\n+    def __init__(self, name: str, names: Tuple[str, ...] = (), label: str = None,\n+                 has_arg: bool = True, rolename: str = None, bodyrolename: str = None) -> None:\n+        self.name = name\n+        self.names = names\n+        self.label = label\n+        self.has_arg = has_arg\n+        self.rolename = rolename\n+        self.bodyrolename = bodyrolename\n+\n+    def make_xref(self, rolename: str, domain: str, target: str,\n+                  innernode: Type[TextlikeNode] = addnodes.literal_emphasis,\n+                  contnode: Node = None, env: BuildEnvironment = None) -> Node:\n+        if not rolename:\n+            return contnode or innernode(target, target)\n+        refnode = addnodes.pending_xref('', refdomain=domain, refexplicit=False,\n+                                        reftype=rolename, reftarget=target)\n+        refnode += contnode or innernode(target, target)\n+        if env:\n+            env.get_domain(domain).process_field_xref(refnode)\n+        return refnode\n+\n+    def make_xrefs(self, rolename: str, domain: str, target: str,\n+                   innernode: Type[TextlikeNode] = addnodes.literal_emphasis,\n+                   contnode: Node = None, env: BuildEnvironment = None) -> List[Node]:\n+        return [self.make_xref(rolename, domain, target, innernode, contnode, env)]\n+\n+    def make_entry(self, fieldarg: str, content: List[Node]) -> Tuple[str, List[Node]]:\n+        return (fieldarg, content)\n+\n+    def make_field(self, types: Dict[str, List[Node]], domain: str,\n+                   item: Tuple, env: BuildEnvironment = None) -> nodes.field:\n+        fieldarg, content = item\n+        fieldname = nodes.field_name('', self.label)\n+        if fieldarg:\n+            fieldname += nodes.Text(' ')\n+            fieldname.extend(self.make_xrefs(self.rolename, domain,\n+                                             fieldarg, nodes.Text, env=env))\n+\n+        if len(content) == 1 and (\n+                isinstance(content[0], nodes.Text) or\n+                (isinstance(content[0], nodes.inline) and len(content[0]) == 1 and\n+                 isinstance(content[0][0], nodes.Text))):\n+            content = self.make_xrefs(self.bodyrolename, domain,\n+                                      content[0].astext(), contnode=content[0], env=env)\n+        fieldbody = nodes.field_body('', nodes.paragraph('', '', *content))\n+        return nodes.field('', fieldname, fieldbody)\n+\n+\n+class GroupedField(Field):\n+    \"\"\"\n+    A doc field that is grouped; i.e., all fields of that type will be\n+    transformed into one field with its body being a bulleted list.  It always\n+    has an argument.  The argument can be linked using the given *rolename*.\n+    GroupedField should be used for doc fields that can occur more than once.\n+    If *can_collapse* is true, this field will revert to a Field if only used\n+    once.\n+\n+    Example::\n+\n+       :raises ErrorClass: description when it is raised\n+    \"\"\"\n+    is_grouped = True\n+    list_type = nodes.bullet_list\n+\n+    def __init__(self, name: str, names: Tuple[str, ...] = (), label: str = None,\n+                 rolename: str = None, can_collapse: bool = False) -> None:\n+        super().__init__(name, names, label, True, rolename)\n+        self.can_collapse = can_collapse\n+\n+    def make_field(self, types: Dict[str, List[Node]], domain: str,\n+                   items: Tuple, env: BuildEnvironment = None) -> nodes.field:\n+        fieldname = nodes.field_name('', self.label)\n+        listnode = self.list_type()\n+        for fieldarg, content in items:\n+            par = nodes.paragraph()\n+            par.extend(self.make_xrefs(self.rolename, domain, fieldarg,\n+                                       addnodes.literal_strong, env=env))\n+            par += nodes.Text(' -- ')\n+            par += content\n+            listnode += nodes.list_item('', par)\n+\n+        if len(items) == 1 and self.can_collapse:\n+            list_item = cast(nodes.list_item, listnode[0])\n+            fieldbody = nodes.field_body('', list_item[0])\n+            return nodes.field('', fieldname, fieldbody)\n+\n+        fieldbody = nodes.field_body('', listnode)\n+        return nodes.field('', fieldname, fieldbody)\n+\n+\n+class TypedField(GroupedField):\n+    \"\"\"\n+    A doc field that is grouped and has type information for the arguments.  It\n+    always has an argument.  The argument can be linked using the given\n+    *rolename*, the type using the given *typerolename*.\n+\n+    Two uses are possible: either parameter and type description are given\n+    separately, using a field from *names* and one from *typenames*,\n+    respectively, or both are given using a field from *names*, see the example.\n+\n+    Example::\n+\n+       :param foo: description of parameter foo\n+       :type foo:  SomeClass\n+\n+       -- or --\n+\n+       :param SomeClass foo: description of parameter foo\n+    \"\"\"\n+    is_typed = True\n+\n+    def __init__(self, name: str, names: Tuple[str, ...] = (), typenames: Tuple[str, ...] = (),\n+                 label: str = None, rolename: str = None, typerolename: str = None,\n+                 can_collapse: bool = False) -> None:\n+        super().__init__(name, names, label, rolename, can_collapse)\n+        self.typenames = typenames\n+        self.typerolename = typerolename\n+\n+    def make_field(self, types: Dict[str, List[Node]], domain: str,\n+                   items: Tuple, env: BuildEnvironment = None) -> nodes.field:\n+        def handle_item(fieldarg: str, content: str) -> nodes.paragraph:\n+            par = nodes.paragraph()\n+            par.extend(self.make_xrefs(self.rolename, domain, fieldarg,\n+                                       addnodes.literal_strong, env=env))\n+            if fieldarg in types:\n+                par += nodes.Text(' (')\n+                # NOTE: using .pop() here to prevent a single type node to be\n+                # inserted twice into the doctree, which leads to\n+                # inconsistencies later when references are resolved\n+                fieldtype = types.pop(fieldarg)\n+                if len(fieldtype) == 1 and isinstance(fieldtype[0], nodes.Text):\n+                    typename = fieldtype[0].astext()\n+                    par.extend(self.make_xrefs(self.typerolename, domain, typename,\n+                                               addnodes.literal_emphasis, env=env))\n+                else:\n+                    par += fieldtype\n+                par += nodes.Text(')')\n+            par += nodes.Text(' -- ')\n+            par += content\n+            return par\n+\n+        fieldname = nodes.field_name('', self.label)\n+        if len(items) == 1 and self.can_collapse:\n+            fieldarg, content = items[0]\n+            bodynode: Node = handle_item(fieldarg, content)\n+        else:\n+            bodynode = self.list_type()\n+            for fieldarg, content in items:\n+                bodynode += nodes.list_item('', handle_item(fieldarg, content))\n+        fieldbody = nodes.field_body('', bodynode)\n+        return nodes.field('', fieldname, fieldbody)\n+\n+\n+class DocFieldTransformer:\n+    \"\"\"\n+    Transforms field lists in \"doc field\" syntax into better-looking\n+    equivalents, using the field type definitions given on a domain.\n+    \"\"\"\n+    typemap: Dict[str, Tuple[Field, bool]]\n+\n+    def __init__(self, directive: \"ObjectDescription\") -> None:\n+        self.directive = directive\n+\n+        self.typemap = directive.get_field_type_map()\n+\n+    def transform_all(self, node: addnodes.desc_content) -> None:\n+        \"\"\"Transform all field list children of a node.\"\"\"\n+        # don't traverse, only handle field lists that are immediate children\n+        for child in node:\n+            if isinstance(child, nodes.field_list):\n+                self.transform(child)\n+\n+    def transform(self, node: nodes.field_list) -> None:\n+        \"\"\"Transform a single field list *node*.\"\"\"\n+        typemap = self.typemap\n+\n+        entries: List[Union[nodes.field, Tuple[Field, Any]]] = []\n+        groupindices: Dict[str, int] = {}\n+        types: Dict[str, Dict] = {}\n+\n+        # step 1: traverse all fields and collect field types and content\n+        for field in cast(List[nodes.field], node):\n+            assert len(field) == 2\n+            field_name = cast(nodes.field_name, field[0])\n+            field_body = cast(nodes.field_body, field[1])\n+            try:\n+                # split into field type and argument\n+                fieldtype_name, fieldarg = field_name.astext().split(None, 1)\n+            except ValueError:\n+                # maybe an argument-less field type?\n+                fieldtype_name, fieldarg = field_name.astext(), ''\n+            typedesc, is_typefield = typemap.get(fieldtype_name, (None, None))\n+\n+            # collect the content, trying not to keep unnecessary paragraphs\n+            if _is_single_paragraph(field_body):\n+                paragraph = cast(nodes.paragraph, field_body[0])\n+                content = paragraph.children\n+            else:\n+                content = field_body.children\n+\n+            # sort out unknown fields\n+            if typedesc is None or typedesc.has_arg != bool(fieldarg):\n+                # either the field name is unknown, or the argument doesn't\n+                # match the spec; capitalize field name and be done with it\n+                new_fieldname = fieldtype_name[0:1].upper() + fieldtype_name[1:]\n+                if fieldarg:\n+                    new_fieldname += ' ' + fieldarg\n+                field_name[0] = nodes.Text(new_fieldname)\n+                entries.append(field)\n+\n+                # but if this has a type then we can at least link it\n+                if (typedesc and is_typefield and content and\n+                        len(content) == 1 and isinstance(content[0], nodes.Text)):\n+                    typed_field = cast(TypedField, typedesc)\n+                    target = content[0].astext()\n+                    xrefs = typed_field.make_xrefs(\n+                        typed_field.typerolename,\n+                        self.directive.domain,\n+                        target,\n+                        contnode=content[0],\n+                        env=self.directive.state.document.settings.env\n+                    )\n+                    if _is_single_paragraph(field_body):\n+                        paragraph = cast(nodes.paragraph, field_body[0])\n+                        paragraph.clear()\n+                        paragraph.extend(xrefs)\n+                    else:\n+                        field_body.clear()\n+                        field_body += nodes.paragraph('', '', *xrefs)\n+\n+                continue\n+\n+            typename = typedesc.name\n+\n+            # if the field specifies a type, put it in the types collection\n+            if is_typefield:\n+                # filter out only inline nodes; others will result in invalid\n+                # markup being written out\n+                content = [n for n in content if isinstance(n, nodes.Inline) or\n+                           isinstance(n, nodes.Text)]\n+                if content:\n+                    types.setdefault(typename, {})[fieldarg] = content\n+                continue\n+\n+            # also support syntax like ``:param type name:``\n+            if typedesc.is_typed:\n+                try:\n+                    argtype, argname = fieldarg.split(None, 1)\n+                except ValueError:\n+                    pass\n+                else:\n+                    types.setdefault(typename, {})[argname] = \\\n+                        [nodes.Text(argtype)]\n+                    fieldarg = argname\n+\n+            translatable_content = nodes.inline(field_body.rawsource,\n+                                                translatable=True)\n+            translatable_content.document = field_body.parent.document\n+            translatable_content.source = field_body.parent.source\n+            translatable_content.line = field_body.parent.line\n+            translatable_content += content\n+\n+            # grouped entries need to be collected in one entry, while others\n+            # get one entry per field\n+            if typedesc.is_grouped:\n+                if typename in groupindices:\n+                    group = cast(Tuple[Field, List], entries[groupindices[typename]])\n+                else:\n+                    groupindices[typename] = len(entries)\n+                    group = (typedesc, [])\n+                    entries.append(group)\n+                new_entry = typedesc.make_entry(fieldarg, [translatable_content])\n+                group[1].append(new_entry)\n+            else:\n+                new_entry = typedesc.make_entry(fieldarg, [translatable_content])\n+                entries.append((typedesc, new_entry))\n+\n+        # step 2: all entries are collected, construct the new field list\n+        new_list = nodes.field_list()\n+        for entry in entries:\n+            if isinstance(entry, nodes.field):\n+                # pass-through old field\n+                new_list += entry\n+            else:\n+                fieldtype, items = entry\n+                fieldtypes = types.get(fieldtype.name, {})\n+                env = self.directive.state.document.settings.env\n+                new_list += fieldtype.make_field(fieldtypes, self.directive.domain,\n+                                                 items, env=env)\n+\n+        node.replace_self(new_list)\n"
  },
  "sphinx-doc__sphinx-10673": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-10673",
    "model_patch": "diff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 35e16e623..4a7f35d61 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -118,6 +118,10 @@ class TocTree(SphinxDirective):\n                 docname = docname_join(self.env.docname, docname)\n                 if url_re.match(ref) or ref == 'self':\n                     toctree['entries'].append((title, ref))\n+                elif docname in ('genindex', 'modindex', 'search'):\n+                    # special generated pages: accept them as valid toctree targets\n+                    toctree['entries'].append((title, docname))\n+                    toctree['includefiles'].append(docname)\n                 elif docname not in self.env.found_docs:\n                     if excluded(self.env.doc2path(docname, False)):\n                         message = __('toctree contains reference to excluded document %r')\n"
  },
  "django__django-12193": {
    "model_name_or_path": "openai/gpt-5-mini",
    "instance_id": "django__django-12193",
    "model_patch": "diff --git a/django/contrib/postgres/forms/array.py b/django/contrib/postgres/forms/array.py\nindex 2e19cd574a..db8b5b70f3 100644\n--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -137,17 +137,21 @@ class SplitArrayWidget(forms.Widget):\n             self.widget.is_localized = self.is_localized\n         value = value or []\n         context['widget']['subwidgets'] = []\n-        final_attrs = self.build_attrs(attrs)\n-        id_ = final_attrs.get('id')\n+        base_final_attrs = self.build_attrs(attrs)\n+        id_ = base_final_attrs.get('id')\n         for i in range(max(len(value), self.size)):\n             try:\n                 widget_value = value[i]\n             except IndexError:\n                 widget_value = None\n+            # Use a fresh copy of the attributes for each subwidget because some\n+            # widgets (e.g. CheckboxInput) mutate the attrs dict passed into\n+            # their get_context(), which would affect subsequent widgets.\n+            widget_attrs = {**base_final_attrs}\n             if id_:\n-                final_attrs = {**final_attrs, 'id': '%s_%s' % (id_, i)}\n+                widget_attrs['id'] = '%s_%s' % (id_, i)\n             context['widget']['subwidgets'].append(\n-                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs)['widget']\n+                self.widget.get_context(name + '_%s' % i, widget_value, widget_attrs)['widget']\n             )\n         return context\n \n"
  }
}